doi,title,venue,publication_year,content_type,abstract,keywords,science gateway | scientific gateway,virtual laboratory | Vlab,virtual research environment,more than one
10.1109/GCE.2014.17,FACE-IT: A Science Gateway for Food Security Research,Gateway Computing Environments Workshop,2014,Conference Paper,"Understanding the potential impacts of climate change and the likely effectiveness of adaptation strategies is of crucial importance to the sustainability of both agriculture and natural ecosystems. Improvements in data availability and simulation model fidelity promises to enable significant improvements in knowledge. However, progress is hindered by the challenges inherent in creating and managing increasingly complex data acquisition, processing, simulation, post-processing, and intercomparison pipelines. To address these challenges, we are developing the Framework to Advance Climate, Economic, and Impact Investigations with Information Technology (FACE-IT) for crop and climate impact assessments. This integrated geospatial data processing, delivery, and simulation framework enables data ingest from diverse geospatial data archives; data regridding, aggregation, and other relevant processing required prior to simulation; large-scale climate impact simulation using a range of applications, including different agricultural models, and leveraging high-performance and cloud computing; and post-processing to produce aggregated yields and other output variables needed to enable model intercomparison and to connect biophysical model outputs to global and regional economic models and assessments. It leverages the capabilities of the Globus Galaxies platform to enable the capture of both workflows and simulation outputs in well-defined, reusable, and easily comparable forms. We describe FACE-IT and its application to studies within the Agricultural Model Intercomparison and Improvement Project.","Biological system modeling, computational modeling, Logic gates, Biomass, Supply chains, optimization, Data visualization",1,0,0,1
10.1145/2016741.2016787,A European Framework to Build Science Gateways: Architecture and Use Cases,TeraGrid Conference,2011,Conference Paper,"Science Gateways are playing an important role in scientific research performed using e-Infrastructures and their relevance will further increase with the development of more sophisticated user interfaces and easier access mechanism. Through the highly collaborative environment of a Science Gateway, users spread around the world and belonging to various Virtual Research Communities can easily cooperate to reach common goals and exploit all the resources of the cyber-infrastructure they are entitled to use.One of the major tasks of a Science Gateway is to supervise the user access to the available services, denying the use to those people who are not authorised. This activity has to comply with the role of users inside the VRC.Users operating in a Science Gateway can belong to different organisations having their own security policies and the Virtual Research Community has to comply with them. As a result, the security chain inside the Science Gateway has to allow each organisation to keep the control of their users hiding, at the same time, the complexity of the security mechanisms underneath the portal.In this work we present a general framework to build Science Gateways [1][2] and the customisations made to meet the requirements of a couple of use cases coming from different scientific communities: those of the European Union funded DECIDE (www.eu-decide.eu) and INDICATE (www.indicate-project.eu) projects.The goal of DECIDE project is to design, implement, and validate a Science Gateway for the computer-aided extraction of diagnostic markers from medical images for the early diagnosis of Alzheimer Disease and other forms of dementia. Using the same platform neurologists, physicians and scientists can store their images and data on grid and perform analysis and comparisons with a huge set of reference cases available on grid. The INDICATE project aims instead at demonstrating, with real-life examples, the advantages of the adoption of e-Infrastructures in the digital cultural heritage domain. The plugin developed enables INDICATE Science Gateway, and its digital cultural heritage community, to access two different e-Infrastructure repositories in an easy way with a friendly user interface but keeping the digital resources safe and the transactions private.The framework defined to support the above use cases is an extension of Liferay portal framework, which provides a whole set of web 2.0 tools and services for the development of generic portals. These have been integrated with a more flexible security workflow and a new set of portlets to access the Grid services. The final architecture of a Science Gateway consists of two part: a front-end building the graphical user interface, and a back-end providing the access to the grid services implemented.A major extension to Liferay is the security system. The new developed security system merges three different security mechanisms in a single workflow allowing users to access Grid resources based on the credentials provided by the organisations they belong to. The idea behind was to combine Shibboleth2 identities in the front-end with X.509 proxies generated by robot certificates in the back-end. The former enables the federation of organisations having different authentication policies while the latter allows users to access Grid resources, without needing any personal certificates whose request and management procedure is very often judged quite cumbersome by non-experts. The ""glue"" between the two layers is an LDAP server running in the back-end that implements a mechanism to map authorised users on Grid resources. Services managing user and grid credentials are not integrated in Liferay Portal but run in different hosts, in order to increase the reliability and security of the Science Gateway.Once the user is authenticated, the portlets developed provide the functionalities to manage the Grid credentials in order to access the e-Infrastructure behind. The portlet-based interface to Grid is built on the OGF-standard SAGA Java API and it is not bound to any particular middleware.Besides the interaction with the computational services of an e-Infrastructure, the proposed framework includes the possibility to easily build and manage data repositories interacting with the gLibrary framework [3] and to encrypt/decrypt sensible data with the Secure Storage System [4].","grid portal, e-collaboration, Liferay, grid computing, e-science, science gateways",1,0,0,1
10.1145/2110486.2110496,CyberSKA: An on-Line Collaborative Portal for Data-Intensive Radio Astronomy,ACM workshop on Gateway computing environments,2011,Conference Paper,"Managing the growing volume of data being output by radio telescopes is a significant challenge faced by radio astronomers today. This challenge will only be further compounded with future telescopes such as the Square Kilometre Array (SKA), which will be the world's largest radio telescope when completed and produce data at unprecedented rates. This paper introduces the CyberSKA collaborative portal which is aimed at addressing the current and future needs of data-intensive radio astronomy. A wide variety of tools and services that have been developed and integrated with the CyberSKA portal, including a distributed data management system, a data access tool, remote visualization tools and a third party application interface are described. Current international usage of CyberSKA focusing on several different SKA Pathfinder survey projects and how they make use of the portal are also highlighted.","data processing, visualization, social networking, data management, third party applications, scientific gateways",1,0,0,1
10.1145/2949550.2949556,BIC-LSU: Big Data Research Integration with Cyberinfrastructure for LSU,Conference on Extreme Science and Engineering Discovery Environment,2016,Conference Paper,"In recent years, big data analysis has been widely applied to many research fields including biology, physics, transportation, and material science. Even though the demands for big data migration and big data analysis are dramatically increasing in campus IT infrastructures, there are several technical challenges that need to be addressed. First of all, frequent big data transmission between storage systems in different research groups imposes heavy burdens on a regular campus network. Second, the current campus IT infrastructure is not designed to fully utilize the hardware capacity for big data migration and analysis. Last but not the least, running big data applications on top of large-scale high-performance computing facilities is not straightforward, especially for researchers and engineers in non-IT disciplines.","big data, software-deﬁned networking, task-aware network scheduling, science gateways, solid-state drive storage server",1,0,0,1
10.1145/3093338.3093356,GenApp Integrated with OpenStack Supports Elastic Computing on Jetstream,Practice and Experience in Advanced Research Computing,2017,Conference Paper,"GenApp is a universal and extensible tool for rapid deployment of applications. GenApp builds fully functioning science gateways and standalone GUI applications from collections of definition files and libraries of code fragments. Among the main features are the minimal technical expertise requirement for the end user and an open-end design ensuring sustainability of generated applications. Because of the conceptual simplicity of use, GenApp is ideally suited to scientists who are not professional developers, to disseminate their theoretical and experimental expertise as embodied in their code to their communities by rapidly deploying advanced applications. GenApp has an open extensible resource execution model. To support efficient elastic cloud computing on NSF Jetstream, GenApp has recently integrated OpenStack as a target resource with optional job-specific XSEDE project accounting.","OpenStack, Science gatweway, middleware, CASE tools, Elastic computing",1,0,0,1
10.1145/3503510,A Workflow Architecture for Cloud-Based Distributed Simulation,ACM Transactions on Modeling and Computer Simulation,2022,Article,"We develop a campus IT cyberinfrastructure for big data migration and analysis, called BIC-LSU, which consists of a task-aware Clos OpenFlow network, high-performance cache storage servers, customized high-performance transfer applications, a light-weight control framework to manipulate existing big data storage systems and job scheduling systems, and a comprehensive social networking-enabled web portal. BIC-LSU achieves 40Gb/s disk-to-disk big data transmission, maintains short average transmission task completion time, enables the convergence of control on commonly deployed storage and job scheduling systems, and enhances easiness of big data analysis with a universal user-friendly interface. BIC-LSU software requires minimum dependencies and has high extensibility. Other research institutes can easily customize and deploy BIC-LSU as an augmented service on their existing IT infrastructures.","Modeling & simulation, scientific workflows, distributed simulation, HLA, cloud computing, science gateways",1,0,0,1
10.4018/IJCMHS.2018010105,ArchaeoGRID Science Gateways for Easy Access to Distributed Computing Infrastructure for Large Data Storage and Analysis in Archaeology and History,International Journal of Computational Methods in Heritage Science,2018,Article,"This article describes how archaeological and historical research grew as a multidisciplinary and interdisciplinary activity due to availability of larger amount of data within the reconstruction of global historical and archaeological contexts at a global spatio-temporal scale. The increased information, also integrated with data from the Earth Sciences, has had an effect on the exponential increase of complex sets of data and of refined methods of analysis. For such purposes, this article discusses the ArchaeoGRID Science Gateway paradigm for accessing ArchaeoGRID Cyberinfrastructure (CI), a Distributed Computing Infrastructure (DCI), that can supply storage and computing resources for managing and analyzing large amount of archaeological and historical data. In fact, ArchaeoGRID Science Gateway is emerging as high-level web environment that makes easier the access, in a transparent way, to DCI, as local high-performance computing, Grids and Clouds, from no specialized Virtual Research Communities (VRC) of archaeologists and historians.","ArchaeoGRID Cyberinfrastructure (CI), ArchaeoGRID Science Gateway, Archaeological and Historical Heritage, Distributed Computing Infrastructure (DCI), Virtual Research Community (VRC), Spatial Data Infrastructure (SDI)",1,0,0,1
10.1109/CCGrid.2011.33,Social Networks of Researchers and Educators on nanoHUB.org,"IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing",2011,Conference Paper,"The science gateway nanoHUB.org is the world's largest nanotechnology user facility, serving 167, 196 users in 2010 with over 2,300 resources including 189 simulation programs. Surveys of nanoHUB users and automated usage analysis find widespread simulation use in formal classroom education, thereby connecting recent research more rapidly and closely to education. Analysis of 719 citations in the scientific literature by over 1,300 authors to nanoHUB.org resources documents use of simulation programs by new research collaborations, by researchers outside of the community originating the program, and by experimentalists. The publication and author networks reveal research collaborations and capacity building through knowledge transfer. Analysis of secondary citations documents the quality of the conducted research with an h-index of 30 after just 10 years of operation. Our analysis proves with quantitative metrics that impactful research can be conducted by an ever growing research community. We argue that HUBzeroTM technology and the user-focused design and operation of nanoHUB.org are keys to success that can be transferred to other science gateways. © 2011 IEEE.","citation network, cloud computing, grid computing, NanoHUB, nanotechnology, science gateways, simulations",1,0,0,1
10.1109/CCGrid.2011.43,Open Social Based Collaborative Science Gateways,"IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing",2011,Conference Paper,"In data-driven science projects, researchers distributed in different institutions often wish to easily team up for data and computing resource sharing to address challenging scientific problems. Typical VO based authorization schemes is not suitable for such a user organized scientific collaboration. Using the emerging OAuthprotocol, we introduce a novel group authorization scheme to support ad-hoc team formation and user controlled resource sharing. Integrating this group authorization scheme, we define an Open Social based scientific collaboration framework and develop a science gateway prototype named as Open Life Science Gateway (OLSGW) to verify and refine the framework. Our experience with development of the OLSGW shows that OAuth 2.0 based group authorization scheme is avery promising approach to resource sharing in Cloud environments, and the Open Social based framework can facilitate science gateway developers to create domain-specific collaborative applications in a very flexible way. © 2011 IEEE.","authorization, collaboration, OpenSocial, science gateways",1,0,0,1
10.1109/CCGrid.2014.95,A Credential Store for Multi-tenant Science Gateways,"International Symposium on Cluster, Cloud and Grid Computing",2014,Conference Paper,"Science Gateways bridge multiple computational grids and clouds, acting as overlay cyber infrastructure. Gateways have three logical tiers: a user interfacing tier, a resource tier and a bridging middleware tier. Different groups may operate these tiers. This introduces three security challenges. First, the gateway middleware must manage multiple types of credentials associated with different resource providers. Second, the separation of the user interface and middleware layers means that security credentials must be securely delegated from the user interface to the middleware. Third, the same middleware may serve multiple gateways, so the middleware must correctly isolate user credentials associated with different gateways. We examine each of these three scenarios, concentrating on the requirements and implementation of the middleware layer. We propose and investigate the use of a Credential Store to solve the three security challenges. © 2014 IEEE.","apache airavata, Credential Store, OA4MP, science gateways, security",1,0,0,1
10.1109/CCGrid.2014.98,Towards Generic Metadata Management in Distributed Science Gateway Infrastructures,"IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing",2014,Conference Paper,"Scientific data life cycles are becoming more and more demanding. Data amounts are seen to be ever increasing while at the same time advanced IT infrastructures become more common resulting in a much broader user group demanding a high usability. These challenges are met with a distributed science gateway infrastructure, which in turn is complex in nature. In this situation a main part is missing, a generic metadata management concept. The approach and architecture of such a concept, the current status, an evaluation, and an outlook will be described in this publication. The main goals are to enable scientists to easily manage and use large amounts of data and provide a generic way to enable the fast transfers to a multitude of scientific use cases. © 2014 IEEE.","distributed infrastructures, metadata management, science gateways",1,0,0,1
10.1109/CCGrid.2016.110,The Latin American Giant Observatory: A Successful Collaboration in Latin America Based on Cosmic Rays and Computer Science Domains,"IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing",2016,Conference Paper,"In this work the strategy of the Latin American Giant Observatory (LAGO) to build a Latin American collaboration is presented. Installing Cosmic Rays detectors settled all around the Continent, from Mexico to the Antarctica, this collaboration is forming a community that embraces both high energy physicist and computer scientists. This is so because the data that are measured must be analytical processed and due to the fact that a priori and a posteriori simulations representing the effects of the radiation must be performed. To perform the calculi, customized codes have been implemented by the collaboration. With regard to the huge amount of data emerging from this network of sensors and from the computational simulations performed in a diversity of computing architectures and e-infrastructures, an effort is being carried out to catalog and preserve a vast amount of data produced by the water-Cherenkov Detector network and the complete LAGO simulation workflow that characterize each site. Metadata, Permanent Identifiers and the facilities from the LAGO Data Repository are described in this work jointly with the simulation codes used. These initiatives allow researchers to produce and find data and to directly use them in a code running by means of a Science Gateway that provides access to different clusters, Grid and Cloud infrastructures worldwide. © 2016 IEEE.","big data, Corsika, Cosmic rays, HPC, LAGO",1,0,0,1
10.1109/CCGRID.2019.00082,Towards a Science Gateway for Bioinformatics: Experiences in the Brazilian System of High Performance Computing,"IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing",2019,Conference Paper,"Science gateways bring out the possibility of reproducible science as they are integrated into reusable techniques, data and workflow management systems, security mechanisms, and high performance computing (HPC). We introduce BioinfoPortal, a science gateway that integrates a suite of different bioinformatics applications using HPC and data management resources provided by the Brazilian National HPC System (SINAPAD). BioinfoPortal follows the Software as a Service (SaaS) model and the web server is freely available for academic use. The goal of this paper is to describe the science gateway and its usage, addressing challenges of designing a multiuser computational platform for parallel/distributed executions of large-scale bioinformatics applications using the Brazilian HPC resources. We also present a study of performance and scalability of some bioinformatics applications executed in the HPC environments and perform machine learning analyses for predicting features for the HPC allocation/usage that could better perform the bioinformatics applications via BioinfoPortal. © 2019 IEEE.","bioinformatics, high-performance computing, science gateways",1,0,0,1
10.1109/CLUSTER.2013.6702693,"Globus Nexus: An identity, profile, and group management platform for science gateways and other collaborative science applications",IEEE International Conference on Cluster Computing,2013,Conference Paper,"Globus Nexus is a flexible and powerful Platform-as-a-Service to which developers can outsource identity, group, and profile management needs. By providing these frequently important but always challenging capabilities as a service, accessible over the network, Globus Nexus streamlines web application development and makes it easy for individuals, teams, and institutions to create collaborative web applications such as science gateways for the science community. We introduce the capabilities of this platform and review representative applications. © 2013 IEEE.","authentication, authorization, group, identity, platform, profile, science gateways",1,0,0,1
10.1109/CLUSTER.2013.6702694,CyberGIS Gateway for enabling data-rich geospatial research and education,IEEE International Conference on Cluster Computing,2013,Conference Paper,"This paper describes CyberGIS Gateway, an online problem-solving environment, for multiple science communities to conduct data-rich geospatial research and education. © 2013 IEEE.","CyberGIS, cyberinfrastructures, science gateways, spatial analysis",1,0,0,1
10.1109/CLUSTER.2013.6702695,Cyberinfrastructure: The key to building successful science gateways,IEEE International Conference on Cluster Computing,2013,Conference Paper,"The VectorBase Bioinformatics Resource Center (BRC) is a science gateway, funded by the National Institute of Allergies and Infectious Diseases (NIAID), entering its 10 years of service to the scientific community on invertebrate vectors that transmit human diseases. This abstract describes three key factors contributing to the success of this science gateway: virtual organization, data and services integration, and community involvement and outreach. The role each plays in how they are impacted by the development of cyberinfrastructure is discussed. © 2013 IEEE.","Arthropod Vectors, Bioinformatics Resource Center, cyberinfrastructures, Infectious Diseases, NIAID, science gateways",1,0,0,1
10.1109/CLUSTER.2013.6702699,Structured Participation Toolkit: An enabler for knowledge production in Science Gateway,IEEE International Conference on Cluster Computing,2013,Conference Paper,"While shared access to common pool CI resources is requisite for high-performance collaboration, it does not ensure shared and transparent knowledge production in the scientific problem solving process. Participatory, structured analytic-deliberation is key to deepening shared understanding, particularly as problem complexity increases, and should be integrated with analysis tools. The Structured Participation Toolkit (SPT) enables structured participation methods to be seamlessly integrated into analytical environments, such as Science Gateways, to support large-scale, asynchronous participation; structured analytic-deliberation; consensus-building and decision-making; as well as to provide an open, transparent decision repository and participation metrics. © 2013 IEEE.","analytic-deliberative, CyberGIS, enabling technologies, high-performance collaboration, structured participation",1,0,0,1
10.1109/CLUSTER.2013.6702701,Enabling multi-task computation on Galaxy-based gateways using swift,IEEE International Conference on Cluster Computing,2013,Conference Paper,"The Galaxy science portal is a popular gateway to data analysis and computational tools for a broad range of life sciences communities. While Galaxy enables users to overcome the complexities of integrating diverse tools into unified workflows, it has only limited capabilities to execute those tools on the parallel and often distributed high-performance resources that the life sciences fields increasingly requires. We outline here an approach to meet this pressing requirement with the Swift parallel scripting language and its distributed runtime system. Swift's model of computation - implicitly parallel functional dataflow - is an elemental abstraction to which the core computing model of Galaxy maps very closely. We describe an integration between Galaxy and Swift that is transforming Galaxy into a much more powerful science gateway, retaining its user-friendly nature while extending its power to execute highly scalable workflows on diverse parallel environments. © 2013 IEEE.","Logic gates, computational modeling, Lead, history, servers, computers",1,0,0,1
10.1109/DS-RT.2016.20,Investigating a Science Gateway for an Agent-Based Simulation Application Using REPAST,IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications,2016,Conference Paper,"The benefits of using e-Infrastructure environments, such as cloud, grid, and high performance computing, for performing scientific experiments could be quite significant. In particular, modeling and simulation, which can serve as a key decision making and system analysis tool, could benefit immensely from such environments ranging from issues of how a community of practice could access a simulation to how it could be run quickly. However, the access and use of these e-Infrastructure environments may present a completely different set of challenges, most especially for non Information and Communications Technology (ICT) users. Science Gateways (SG), which are digital interfaces to advanced technologies, can be used to overcome the challenges of running many simulations on e-Infrastructures in a reasonable amount of time. In this work, we developed a SG, based on the Liferay portal framework and the Catania grid and cloud engine. We show how an Agent-Based infection simulation, which has been implemented using the Recursive Porous Agent Simulation Toolkit (REPAST) Simphony, can be ported to a Science Gateway and deployed on distributed computing infrastructures. This demonstration illustrates how this technology can be used easily to allow multiple users across the world to access a simulation and to execute their applications in an e-Infrastructures environment. © 2016 IEEE.","agent-based modelling and simulation, Catania Science Gateway Framework, e-infrastructures, infection model, liferay portal framework, repast, science gateways",1,0,0,1
10.1109/ELINFOCOM.2016.7562923,Problem solving environment for water-supply systems,"International Conference on Electronics, Information, and Communications ",2016,Conference Paper,"This paper describes the collaboration of modern technologies based on mathematical modeling with the aim to simulate behaviors of water-supply system in a big city. The core contains an instrumental tool for hydraulics simulation executed on high-performance computing infrastructure. The simulation process collaborates with the GIS environment in order to correct and prepare input data and visualize the simulation output. The novelty is also scientific gateway which enables hydraulic domain experts to interact comfortably with the HPC capacity from various multiple platforms including local cluster, Grid and Cloud. © 2016 IEEE.","cloud computing, environmental domain, high-performance computing, hydraulic simulations, water-supply system",1,0,0,1
10.1109/eScience.2011.16,Creating a Cloud-based Life Science Gateway,International Conference on e-Science,2011,Conference Paper,"Cloud computing is increasingly becoming a popular solution to massive data analysis in life science community. To completely harness the power of Cloud computing, scientists need science gateways to efficiently manage their virtual machines, share Cloud resources, and run high-throughput sequence analysis with bioinformatics software tools. This paper introduces the development and use of Open Life Science Gateway, which manages computational jobs on top of Hadoop streaming, and supports user-customized runtime environment with virtual machine images. Moreover, it facilitates researchers to team up on solving challenging computing problems by sharing Cloud based data sources and software tools. This gateway has been used for investigating better B-cell epitope prediction. © 2011 IEEE.","cloud computing, science gateways",1,0,0,1
10.1109/eScience.2014.22,eScience Gateway Stimulating Collaboration in Rock Physics and Volcanology,International Conference on e-Science,2014,Conference Paper,"Earth scientist observe many facets of the planet's crust and integrate their resulting data to better understand the processes at work. We report on a new data-intensive science gateway designed to bring rock physicists and volcanologists into a collaborative framework that enables them to accelerate their research and integrate well with other Earth scientists. The science gateway supports three major functions: 1) sharing data from laboratories and observatories, experimental facilities and computational model runs, 2) sharing computational model sand methods for analysing experimental and observational data, and 3) supporting recurrent tasks, such as data collection and running application in real time. Our prototype gateway has worked with two exemplar projects giving experience of data gathering, model sharing and data analysis. The geoscientists found that the gateway accelerated their work, triggered new practices and provided a good platform for long-term collaboration. © 2014 IEEE.","Code Testing, data sharing, Earth Sciences, HPC, metadata and storage, science gateways",1,0,0,1
10.1109/eScience.2015.72,Managing Complexity in Distributed Data Life Cycles Enhancing Scientific Discovery,International Conference on e-Science,2015,Conference Paper,"Distributed data life cycles consist of data sources, data and computing components as well as data sinks and user facing elements. The complexity of the underlying systems is ever rising with the increasing heterogeneity and distribution of components and environments. Researchers would like to focus on their specific research topic without the need to learn these systems in detail. Accessible data life cycles enable scientists to do better science more efficiently and obtain results, which would not have been possible without these advanced technologies. For this objective, abstraction to hide complexity and automation to avoid manual tasks are a necessity. These are embodied in the three conceptual data life cycle challenges, namely data, computing and utilization. Concepts and technologies to manage these challenges are explored and exemplified on the basis of the general data life cycle and MoSGrid (Molecular Simulation Grid) science gateway. In this context, we especially focus on teaching in drug design and quantum chemistry research use cases. Further cases are presented elucidating various challenges in adapting the concepts and technologies to wind energy data analysis and the XSEDE research infrastructure. © 2015 IEEE.","Complexity management, Distributed data life cycles, Scientific discovery",1,0,0,1
10.1109/eScience.2019.00035,"Social Media Intelligence and Learning Environment: an Open Source Framework for Social Media Data Collection, Analysis and Curation",International Conference on e-Science,2019,Conference Paper,"Social Media Intelligence and Learning Environment (SMILE) is an open source framework bringing cutting-edge computational models on social media data to social science researchers and students with any level of programming and computation expertise. Many existing social media analysis tools require programming knowledge, a fee, or are closed source, making it challenging for social science researchers to apply existing and new methods to social media data. SMILE provides a user-friendly web interface, through which researchers can perform a wide spectrum of research tasks, ranging from social media data collection, natural language processing, text classification, social network analysis, and generating human readable outputs and visualizations. SMILE has adopted several technologies to support its needs. The data service of SMILE leverages the GraphQL language to provide an efficient and succinct API for client to communicate with a heterogeneous collection of social media APIs, including Twitter and Reddit. SMILE implements a microservices design and utilizes Amazon AWS services, such as Lambda and Batch for computation, S3 for data storage, and Elasticsearch for a Twitter streaming database, which makes it more portable, economic, and resilient. Analysis outputs can be shared with the larger community using Clowder, an open source data management system to support data curation of long tail data and metadata. SMILE is one of the main applications deployed as a standalone tool within the Social Media Macroscope (SMM), a science gateway based on the HUBzero platform. Over 200 users have used SMILE since its first release in 2018. © 2019 IEEE.","cloud computing, data management, Research computing infrastructure, scientific gateways, Text mining",1,0,0,1
10.1109/eScience.2019.00085,Accelerating Scientific Discovery with SCAIGATE Science Gateway,International Conference on e-Science,2019,Conference Paper,"The demand for computational accelerators (GPUs, FPGAs, ASICs, etc.) is growing due to the widening variety of datacenter applications fueled by recent scientific breakthroughs that leverage artificial intelligence (AI). As much as these applications (e.g., cosmology, physics, etc.) have continued to witness record-breaking accuracy in predictive capabilities due to AI widespread influence, the infrastructure and workflow to take these applications out of research labs into production and business use-cases continues to lag. To address these important infrastructural challenges, we present SCAIGATE, a prototype science gateway with a simplified workflow aimed at facilitating model building/validation workflows in large-scale scientific applications. © 2019 IEEE.","Accelerators, artificial intelligence, Programming environment, scientific computing, workflows",1,0,0,1
10.1109/eScience.2019.00097,HUBzero© Goes OneSciencePlace: The Next Community-Driven Steps for Providing Software-as-a-Service,International Conference on e-Science,2019,Conference Paper,"HUBzero © is a well-used science gateway framework actively developed for over a decade. The needs of its community are one of the primary driving forces guiding the team behind HUBzero©. For example, requirements in the community led to the integration of JupyterHub, RStudio and the provision of Docker containers for the tool submission environment. Besides its community driven requirements, the team behind HUBzero© continuously analyzes the existing science gateway landscape, the usage of instances of HUBzero© as well as trends in the usage of computational platforms in general to keep HUBzero© robust, scalable, and sustainable. HUBzero© has begun development of a science gateway platform called Open Science Place (OSP). OSP is a SaaS-based (Softwareas-A-Service) solution to give researchers a way to execute, share, and archive their research in a publically accessible venue. The poster goes into detail for the different aspects of sustainability addressed in OSP such as a community-hosting concept, flexible financing models, interoperability and scalability of tools. © 2019 IEEE.","HUBzero, OneSciencePlace, science gateways, software-as-a-service, Software-sustainability",1,0,0,1
10.1109/GCE.2010.5676120,An on-line collaborative data management system,Gateway Computing Environments Workshop,2010,Conference Paper,"Scientific data continues to grow in volume making the tasks of managing, accessing and sharing such data more challenging. Providing data to scientists via scientific gateways or collaborative portals can aid scientists in achieving these tasks. This paper presents a general data management system that has been built on top of Elgg, an open source social networking platform. The tool enables scientists to upload, browse, view and share a wide variety of scientific data, as well as define and evolve meta data standards in a collaborative manner. The data management system is currently being used as part of GeoChronos, a scientific gateway for Earth observation scientists, for creating and sharing collections of spectral and satellite data.","data management, scientific gateways, social networking",1,0,0,1
10.1109/GCE.2010.5676127,Domain-specific web services for scientific application developers,Gateway Computing Environments Workshop,2010,Conference Paper,"Many scientists today routinely conduct simulations and run models using high performance computing (HPC) resources provided by national, regional and campus grid infrastructures, either directly logging into such resources or indirectly via web portals and other application client software, i.e. science gateways. Science gateways have proven to be an effective way of bringing HPC resources to a much larger user base. However, developing a new gateway demands substantial effort, requiring both cyberinfrastructure and domain expertise. This paper describes an approach by core software developers to provide domain specific web services (DomWS) to science gateway and application developers. The core developers deliver a set of web services that understand domain specific semantics and translate domain application requests into computational and other tasks that are dispatched onto the distributed high end resources. This approach allows gateway and application developers to easily create customized application services and focus on the gateway functions and interfaces, such as gadgets and desktop clients, that serve their user community. The DomWS approach is not a generic solution for all simulation services. Our aim is to help application developers apply this framework with ease to their specific models and simulations with a small degree of code modification. DomWS also provides reusable modules and templates for common tasks needed by the targeted user community. This paper describes a set of web services that have been developed for Community Climate System Model (CCSM) version 4 using this approach.","Domain specific web services, HPC, Online simulation, science gateways, Service framework's",1,0,0,1
10.1109/GCE.2010.5676129,Creating the CIPRES Science Gateway for inference of large phylogenetic trees,Gateway Computing Environments Workshop,2010,Conference Paper,"Understanding the evolutionary history of living organisms is a central problem in biology. Until recently the ability to infer evolutionary relationships was limited by the amount of DNA sequence data available, but new DNA sequencing technologies have largely removed this limitation. As a result, DNA sequence data are readily available or obtainable for a wide spectrum of organisms, thus creating an unprecedented opportunity to explore evolutionary relationships broadly and deeply across the Tree of Life. Unfortunately, the algorithms used to infer evolutionary relationships are NP-hard, so the dramatic increase in available DNA sequence data has created a commensurate increase in the need for access to powerful computational resources. Local laptop or desktop machines are no longer viable for analysis of the larger data sets available today, and progress in the field relies upon access to large, scalable high-performance computing resources. This paper describes development of the CIPRES Science Gateway, a web portal designed to provide researchers with transparent access to the fastest available community codes for inference of phylogenetic relationships, and implementation of these codes on scalable computational resources. Meeting the needs of the community has included developing infrastructure to provide access, working with the community to improve existing community codes, developing infrastructure to insure the portal is scalable to the entire systematics community, and adopting strategies that make the project sustainable by the community. The CIPRES Science Gateway has allowed more than 1800 unique users to run jobs that required 2.5 million Service Units since its release in December 2009. (A Service Unit is a CPU-hour at unit priority).","CIPRES, cyberinfrastructures, phylogenetics, science gateways, Systematics, TeraGrid",1,0,0,1
10.1109/GCE.2014.11,Who Cares about Science Gateways? A Large-Scale Survey of Community Use and Needs,Gateway Computing Environments Workshop,2014,Conference Paper,"With the rise of science gateway use in recent years, we anticipate there are additional opportunities for growth, but the field is currently fragmented. We describe our efforts to measure the extent and characteristics of the gateway community through a large-scale survey. Our goal was to understand what type of support services might be provided to the gateway community. © 2014 IEEE.","cyberinfrastructures, high-performance computing, Science/engineering gateways/portals, software development, web interfaces",1,0,0,1
10.1109/GCE.2014.12,GenApp Module Execution and Airavata Integration,Gateway Computing Environments Workshop,2014,Conference Paper,"A new framework (GenApp) for rapid generation of scientific applications running on a variety of systems including science gateways has recently been developed. This framework builds a user interface for a variety of target environments on a collection of executable modules. The method for execution of the modules is unrestricted by the framework. Initial implementation supports direct execution, and not queue managed submission, on a user's workstation, a web server, or a compute resource accessible from the web server. After a successful workshop, it was discovered that long running jobs would sometimes fail, due to the loss of a TCP connection. This precipitated an improvement to the execution method with the bonus of easily allowing multiple web clients to attach to the running job. Finally, to support a diversity of queue managed compute resources, a Google Summer of Code project was completed to integrate the Apache Airavata middleware as an additional execution model within the GenApp framework. © 2014 IEEE.","CASE tools, middleware, science gateways",1,0,0,1
10.1109/GCE.2014.15,The Apache Airavata Application Programming Interface: Overview and Evaluation with the UltraScan Science Gateway,Gateway Computing Environments Workshop,2014,Conference Paper,"We present an overview of the Apache Airavata Application Programming Interface (API), describe the design choices and implementation details, and describe how API methods map to the UltraScan Science Gateway use case. The Airavata API is designed to standardize access to Airavata services that provide gateways with scientific application metadata and execution management. The API also represents an important milestone in the development of Science Gateway Platform as a Service (SciGaP), a hosted, multi-tenanted gateway service based on open source Airavata software. The UltraScan gateway is a production XSEDE gateway that has been using Airavata services for over three years through customized interfaces and represents a stringent test of the API design and implementation. © 2014 IEEE.","Application programming interface design, cloud computing, cyberinfrastructures, science gateways",1,0,0,1
10.1109/GCE.2014.6,WorkWays: Interacting with Scientific Workflows,"Gateway Computing Environments Workshop, The International Conference for High Performance Computing, Networking, Storage and Analysis",2014,Conference Paper,"This paper presents WorkWays, a workflow-based science gateway that supports human-in-the-loop workflows. The computational steering capability of WorkWays has been used to solve a number of problems in which it is useful for users to study intermediate results and steer the computation. Two of those use cases are discussed in this paper. © 2014 IEEE.","human-in-the-loop workflows, interactive workflow-based science gateways, science gateways, scientific workflows",1,0,0,1
10.1109/GCE.2014.7,PDACS - A Portal for Data Analysis Services for Cosmological Simulations,Gateway Computing Environments Workshop,2014,Conference Paper,"Accessing and analyzing data from cosmological simulations is a major challenge due to the prohibitive size of cosmological datasets and the diversity of the associated large-scale analysis tasks. Analysis of the simulated models requires direct access to the datasets, considerable compute infrastructure, and storage capacity for the results. Resource limitations can become serious obstacles to performing research on the most advanced cosmological simulations. The Portal for Data Analysis services for Cosmological Simulations (PDACS) is a web-based workflow service and scientific gateway for cosmology. The PDACS platform provides access to shared repositories for datasets, analytical tools, cosmological workflows, and the infrastructure required to perform a wide variety of analyses. PDACS is a repurposed implementation of the Galaxy workflow engine and supports a rich collection of cosmology-specific datatypes and tools. The platform leverages high-performance computing infrastructure at the National Energy Research Scientific Computing Center (NERSC) and Argonne National Laboratory (ANL), enabling researchers to deploy computationally intensive workflows. In this paper we present PDACS and discuss the process and challenges of developing a research platform for cosmological research. © 2014 IEEE.","Analytical models, computational modeling, Handheld computers, Logic gates, data models, Communities, Genomics",1,0,0,1
10.1109/HPCSim.2014.6903707,Towards a big data exploration framework for astronomical archives,International Conference on High Performance Computing & Simulation,2014,Conference Paper,"Exploiting big data astronomical archives is a mandatory and challenging activity due to dramatically increasing sizes and high complexity of datasets coming from radio telescopes or space missions. Visual exploration and discovery can be invaluable tools providing prompt and intuitive insights into the intrinsic data characteristics, enabling scientists to rapidly identify interesting areas within which to apply computationally expensive algorithms or to discover correlations in data patterns. The paper outlines a new approach for creating a user-friendly, integrated and cross-platform framework to facilitate big data access, visualization and exploration, thus empowering astrophysicists to focus on pitching new ideas for scientific advances. We present a flexible distributed architecture striking a balance between local interactive exploration tools and remote services responsible for hiding data complexity. Remote services communicate with advanced distributed computing infrastructures presenting a meaningful lightweight version of the archive dataset obtained by mining or noise filtering methods. They are interfaced with science gateway technologies in order to allow collaborative activity between users and to provide customization and scalability of data analysis/processing workflows hiding underlying technicalities. Local tools enable interactive visualization optimized for ubiquitous computing environments, intuitively controlling the resulting visualisation. The motivations behind such a framework are envisaged to meet the requirements of the exploitation of the Gaia mission outcomes and are shown in the paper by a number of case studies. The presented framework can potentially have a profound impact on astronomical and astrophysical communities in the big data era, allowing to quickly understand datasets, thus aiding in adopting novel ways for scientific discovery. © 2014 IEEE.","big data, data analysis, science gateways, scientific visualization, service-oriented architecture, Software Services",1,0,0,1
10.1109/HPCSim.2015.7237017,Science gateways - leveraging modeling and simulations in HPC infrastructures via increased usability,International Conference on High Performance Computing & Simulation,2015,Conference Paper,"Modeling and simulations, which necessitate HPC infrastructures, are often based on complex scientific theories and involve interdisciplinary research teams. IT specialists support with the efficient access to HPC infrastructures. They design, implement and configure the simulations and models reflecting the sophisticated theoretical models and approaches developed and applied by domain researchers. Roles in such interdisciplinary teams may overlap dependent on the knowledge and experience with computational resources and/or the research domain. Bioinformaticians, for example, are in general trained to act as IT specialists, while having also a good knowledge about biology and chemistry to support the user community competently. Domain researchers are mainly not IT specialists and the requirement to employ HPC infrastructures via command line often forms a huge hurdle for them. Thus, there is the need to increase the usability of simulations and models on HPC infrastructures for the uptake by the user community. Science gateways form a solution, which offer a graphical user interface tailored to a specific research domain with a single point of entry for job and data management hiding the underlying infrastructure. In the last 10 years quite a few web development frameworks, science gateway frameworks and APIs with different foci and strengths have evolved to support the developers of science gateways in implementing an intuitive solution for a target research domain. The selection of a suitable technology for a specific use case is essential and helps reducing the effort in implementing the science gateway by re-using existing software or frameworks. Thus, a solution for a user community can be provided more efficiently. This paper goes into detail for science gateway concepts as well as information resources, gives examples for successful technologies and proposes criteria for choosing a technology for a use case. © 2015 IEEE.","Applications, Applied Modeling and Simulation, Clouds Computing, e-science, Internet and Web Computing, Large Scale Scientific Computing, Large Scale Systems for Computational Sciences",1,0,0,1
10.1109/HUSTProtools51951.2020.00010,Integrating Science Gateways with Secure Cloud Computing Resources: An Examination of Two Deployment Patterns and Their Requirements,IEEE/ACM International Workshop on HPC User Support Tools  and Workshop on Programming and Performance Visualization Tools,2020,Conference Paper,"This paper examines scenarios in which science gateways can facilitate access to cloud computing resources to support scientific research using regulated or protected data stored on clouds. Specifically, we discuss the use of science gateways to access Controlled Unclassified Information (CUI), a US regulatory standard that covers a broad range of US federal government-owned or regulated data, and that also provides a useful proxy for other types of sensitive data, such as private sector intellectual property. We focus on the impact of CUI requirements on science gateway platforms that can be used to create and manage science gateway instances. Gateway platforms are centrally operated by gateway platform providers who create and control gateway instances on behalf of gateway providers. Broadly, platforms operate following either a multi-tenant or else a multi-instance pattern. Multi-tenanted science gateway platforms are designed to support multiple science gateways simultaneously, with each gateway as a tenant to a single operational instance of the platform middleware. Multi-instance platforms, on the other hand, provide and manage an entire instance of the science gateway software for each gateway. This paper reviews these two scenarios from the perspective of the Science Gateways Platform as a service (SciGaP), a multitenanted gateway platform based on the open-source Apache Airavata software. We examine requirements for providing multitenanted platforms for CUI gateways and also the requirements for providing the same software as a multi-instance platform. In both cases, we assume the use of CUI-compatible resources from commercial cloud providers. Both approaches are technically feasible but have trade-offs that must be considered. © 2020 IEEE.","cloud computing, Controlled Unclassified Information, cyberinfrastructures, cybersecurity, distributed systems, protected data, science gateways",1,0,0,1
10.1109/ICCCBDA51879.2021.9442514,A Cloud-Enabled Collaborative Hub for Analysis of Geospatial Big Data,IEEE International Conference on Cloud Computing and Big Data Analytics,2021,Conference Paper,"Geospatial big data are analyzed for addressing a specific research or management problem on global scale, and science gateways or Hub, have been widely adopted in recent years as an effective platform for an entry to computational resources, research collaboration, dissemination of data, applications and publications, and community engagement. However, replicating deployment and setup is a non-trivial task. Cloud computing provides an attractive alternative, simplifying resource provision and enabling reliable and scalable replication. This paper describes ongoing efforts to a cloud-enabled Geospatial Hub hosting general-purpose software building blocks, which provides geospatial data access, processing, analysis, and visualization capabilities. The technologies underlying these components, the automation of deployment and configuration on cloud with the Elastic Compute Service (ECS) and Object Storage Service (OBS) are described. This work builds geospatial big data analysis capabilities into web-based Hub platform and empower it by cloud computing. This will open a way for easy development of a variety of online tools for probing and presenting geospatial big data and digital information. © 2021 IEEE.","clouds, geospatial data, HUBzero, science gateways, web platform",1,0,0,1
10.1109/ICICT.2017.8320171,Enabling scientific workflow and gateways using the standards-based XSEDE architecture,International Conference on Information and Communication Technologies,2017,Conference Paper,"The XSEDE project seeks to provide 'a single virtual system that scientists can use to interactively share computing resources, data and experience.' The potential compute resources in XSEDE are diverse in many dimensions, node architectures, interconnects, memory, local queue management systems, and authentication policies to name a few. The diversity is particularly rich when one considers the NSF funded service providers and the many campuses that wish to participate via campus bridging activities. Resource diversity presents challenges to both application developers and application platform developers (e.g., developers of gateways, portals, and workflow engines). The XSEDE Execution Management Services (EMS) architecture is an instance of the Open Grid Services Architecture EMS and is used by higher level services such as gateways and workflow engines to provide end users with execution services that meet their needs. The contribution of this paper is to provide a concise explanation and concrete examples of how the EMS works, how it can be used to support scientific gateways and workflow engines, and how the XSEDE EMS and other OGSA EMS architectures can be used by applications developers to securely access heterogeneous distributed computing and data resources. © 2017 IEEE.","architecture, distributed computing, gateways, scientific computing, workflows, XSEDE",1,0,0,1
10.1109/ICWS.2010.107,A Web 2.0-Based Scientific Application Framework,IEEE International Conference on Web Services,2010,Conference Paper,"A significant obstacle to building usable, web-based interfaces for computational science in a Grid environment is how to deploy scientific applications on computational resources and expose these applications as web services. To streamline the development of these interfaces, we propose a new application framework that can deliver user-defined scientific workflows as both web services and OpenSocial gadgets. Through this application framework, scientists can focus on defining computational workflows using domainspecific applications and can use the software tools in the framework to quickly generate gadgets for running the applications and visualizing the output from workflow executions. By assembling these domain-specific gadgets and some common gadgets predefined in the framework for workflow management, scientists can easily set up a customized computational workspace to meet their requirements. © 2010 IEEE.","OpenSocial, science gateways, web2.0, workflows",1,0,0,1
10.1109/ISTAFRICA.2016.7530650,The African Data Intensive Research Cloud,IST-Africa Week Conference,2016,Conference Paper,"The African Data Intensive Research Cloud project aims to establish resources to support data intensive radio astronomy research among collaborating partners in South Africa and African Square Kilometre Array telescope partner countries. Infrastructure as a Service cloud instances using the OpenStack middleware have been deployed at three sites in South Africa as a proof of concept for the future larger scale deployments. By supporting common software, knowledge can be shared amongst the partners leading to faster resolution of problems, thus providing better support to the research community. The project will deploy a mix of scales of systems, with users bursting to the larger facilities as needed. Software to support data distribution, analysis and visualisation of astronomy data through scientific gateways is being deployed. Providing training of computing support teams, astronomers and data scientists at the partner organisations is key to the success of the project. © 2016 IIMC.","cloud computing, MeerKAT, OpenStack, radio astronomy, SKA",1,0,0,1
10.1109/IWSG.2014.11,A Grid-Enabled Virtual Screening Gateway,International Workshop on Science Gateways,2014,Conference Paper,"In computer-aided drug design, software tools are used to narrow down possible drug candidates, therefore reducing the amount of expensive in vitro research by a process called virtual screening. However, searching for drug candidates among a huge number of alternatives requires extensive computation. In this paper, we describe a science gateway for virtual screening that has been tailored to the specific needs of our local users. By reusing the generic architecture and code of a previously developed science gateway for another scientific discipline, it took us only two months from early requirements analysis to obtain a running gateway. The early empirical results show (1) considerable speed-ups, thanks to usage of grid infrastructure, and, (2) user satisfaction, thanks to the user-centred design of the web interface and automated data management. © 2014 IEEE.","Logic gates, Libraries, Drugs, user interfaces, software, Computer architecture, portals",1,0,0,1
10.1109/IWSG.2014.15,Apache Airavata: Design and Directions of a Science Gateway Framework,International Workshop on Science Gateways,2014,Conference Paper,"This paper provides an overview of the Apache Airavata software system for science gateways. Gateways use Airavata to manage application and workflow executions on a range of backend resources (grids, computing clouds, and local clusters). Airavata's design goal is to provide component abstractions for major tasks required to provide gateway application management. Components are not directly accessed but are instead exposed through a client Application Programming Interface. This design allows gateway developers to take full advantage of Airavata's capabilities, and Airavata developers (including those interested in middleware research) to modify Airavata's implementations and behavior. This is particularly important as Airavata evolves to become a scalable, elastic ""platform as a service"" for science gateways. We illustrate the capabilities of Airavata through the discussion of usage vignettes. As an Apache Software Foundation project, Airavata's open community governance model is as important as its software base. We discuss how this works within Airavata and how it may be applicable to other distributed computing infrastructure and cyber infrastructure efforts. © 2014 IEEE.","cyberinfrastructures, distributed computing infrastructures, open source software, science gateways",1,0,0,1
10.1109/IWSG.2014.16,ACID: An Interactive Desktop for CTA Science Gateway,International Workshop on Science Gateways,2014,Conference Paper,"The Astronomical & Physics Cloud Interactive Desktop (ACID) has been developed for the prototype of CTA Science Gateway in Catania, Italy. ACID is based on a web environment that, avoiding any installation on a local PC, allows the use of plenty of software packages for both on-line and off-line analysis of astrophysical data. The users are able to exploit, if applicable, the native Graphical User Interface (GUI) of the tools available in the ACID environment. The ACID environment exploited by the Science Gateway offers two modes of usage: interactively to perform an on-line analysis through the VNC desktop and the native GUIs or shell environment of the programs, Distributed Computing Infrastructure (DCI) to perform an off-line analysis through a workflow submission. For the interactive usage of the remote software, ACID exploits an ad hoc VNC-based User Interface (VUI). Each type of analysis can be exploited through the CTA Science Gateway based on Life ray and WS-PGRADE/gUSE. Data file sharing is ensured by own Cloud technology. All of these functionalities can be also used through iOS and Android devices. © 2014 IEEE.","Applications, clouds, collaborative environments, DCIs, graphical user interfaces, GUI, VNC",1,0,0,1
10.1109/IWSG.2014.17,IMP Science Gateway: From the Portal to the Hub of Virtual Experimental Labs in Materials Science,International Workshop on Science Gateways,2014,Conference Paper,"""Science gateway"" (SG) ideology means a user-friendly intuitive interface between scientists (or scientific communities) and different software components + various distributed computing infrastructures (DCIs) (like grids, clouds, clusters), where researchers can focus on their scientific goals and less on peculiarities of software/DCI. ""IMP Science Gateway Portal"" (http://scigate.imp.kiev.ua) for complex workflow management and integration of distributed computing resources (like clusters, service grids, desktop grids, clouds) is presented. It is created on the basis of WS-PGRADE and gUSE technologies, where WS-PGRADE is designed for science workflow operation and gUSE - for smooth integration of available resources for parallel and distributed computing in various heterogeneous distributed computing infrastructures (DCI). The typical scientific workflows with possible scenarios of its preparation and usage are presented. Several typical use cases for these science applications (scientific workflows) are considered for molecular dynamics (MD) simulations of complex behavior of various nanostructures (nanoindentation of graphene layers, defect system relaxation in metal nanocrystals, thermal stability of boron nitride nanotubes, etc.). The user experience is analyzed in the context of its practical applications for MD simulations in materials science, physics and nanotechnologies with available heterogeneous DCIs. In conclusion, the ""science gateway"" approach - workflow manager (like WS-PGRADE) + DCI resources manager (like gUSE)-gives opportunity to use the SG portal (like ""IMP Science Gateway Portal"") in a very promising way, namely, as a hub of various virtual experimental labs (different software components + various requirements to resources) in the context of practical MD applications in materials science, physics, and nanotechnologies. © 2014 IEEE.","clusters, computational physics, desktop grid, distributed computing, grid computing, materials science, molecular dynamics, nanotechnologies, physics, science gateways, service grid",1,0,0,1
10.1109/IWSG.2014.18,Expansion of Quantum Chemical Metadata for Workflows in the MoSGrid Science Gateway,International Workshop on Science Gateways,2014,Conference Paper,"The science gateway MoSGrid (Molecular Simulation Grid) is a valuable and user-friendly tool to submit and process molecular simulation studies on a large scale. With regard to the needs of the users, we focus on the comparability of simulations using two prominent quantum chemical codes, Gaussian09 and NWChem. At first sight, the definition of functionals and basis sets seems to be sufficient to evoke the same type of calculation in both codes using the quantum chemical workflows in MoSGrid. In the very detail, this is not true and more aspects such as integration grids, convergence criteria, basis set dimensions etc. Have to be defined in order to obtain a trustful comparability between quantum chemical codes. Up to now, these details have not been defined in the MSML (Molecular Simulation Mark up Language) implementation within MoSGrid. After the present investigation, all these details can be integrated to extend the quantum chemical workflows in MoSGrid. © 2014 IEEE.","Basis sets, Functionals, QC codes, quantum chemistry, science gateways, workflows",1,0,0,1
10.1109/IWSG.2014.9,Developing a Mobile Application Connected to a Science Gateway,International Workshop on Science Gateways,2014,Conference Paper,"Nowadays collaborative applications are valuable tools for scientists to share their studies and experiences, e.g. By interacting simultaneously with their data and outcomes giving feedback to other colleagues on how the data are processed. This paper presents a mobile application connected to a workflow-enabled framework to perform visualization and data filtering of large-scale, multidimensional datasets on Distributed Computing Infrastructures (DCIs). In particular the usage of workflow-driven applications allow the scientist to perform heavy data exploration tasks in a transparent user-friendly way. © 2014 IEEE.","astrophysics, collaborative environments, DCIs, large-scale datasets, mobile application, science gateways, visualization, workflow systems",1,0,0,1
10.1109/IWSG.2015.10,Challenges and Modifications for Creating a MoSGrid Science Gateway for US and European Infrastructures,International Workshop on Science Gateways,2015,Conference Paper,"The established German MoSGrid science gateway serves the computational chemistry community in the areas of quantum chemistry, molecular dynamics and docking with intuitive user interfaces for jobs, workflows and data as well as metadata management. It is designed independent of the underlying infrastructure and developed on top of gUSE/WS-PGRADE, which is capable of connecting to diverse grid, cloud and batch infrastructures. However, quite a few of its user-friendly features and pre-configured workflows are dependent on the service-oriented grid middleware UNICORE and on installed computational chemistry tools on the target resources. Furthermore, the security mechanisms rely on SAML assertions to provide single sign-on to the different available resources. This paper gives an overview on the challenges and modifications, which have been necessary to provide an international MoSGrid science gateway exploiting XSEDE and PRACE infrastructures. This work was part of the XSEDE-PRACE interoperability project, which selected three use cases out of US-and European-wide applications. © 2015 IEEE.","data management, international infrastructures, science gateways, security, workflows",1,0,0,1
10.1109/IWSG.2015.11,TraceRep: Gateway for Sharing and Collecting Traces in HPC Systems,International Workshop on Science Gateways,2015,Conference Paper,"Traces of parallel programs are a valuable resource for users of HPC systems because they provide insight about the efficiency of the execution of their applications, allowing to improve the code. Additionally, for computer scientists they are useful as an input to simulation tools to guide the development of high performance computing (HPC) systems. Unfortunately, the limited access to these systems, the knowledge required to use the trace extraction tools, and the huge volume that traces can reach, makes the collection and sharing of traces hard. Trace Rep is a computer science gateway designed in the University of Cantabria designed to solve this problems. Its web interface and automated cluster access hides the complexity of collecting traces, and its public repository section simplifies sharing traces, including mechanisms to licence the data and guarantee authorship. TraceRep is available at: http://tracerep.unican.es. © 2015 IEEE.","HPC architectures, scientific gateways, Trace Rep, traces of parallel applications",1,0,0,1
10.1109/IWSG.2015.15,Extending Scientific Workflow Systems to Support MapReduce Based Applications in the Cloud,International Workshop on Science Gateways,2015,Conference Paper,"Cloud Computing has gained a lot of popularity in recent years because of the flexibility that it offers. In addition, there seems to be a rising interest in combining Parallel Computing, Cloud Computing and Big Data to create large scale scientific applications. WS-PGRADE is a gateway framework that allows users to create such applications by defining them as scientific workflows. This paper investigates how workflow systems and science gateways, such as WS-PGRADE, can be extended with data processing capabilities of Hadoop based on the MapReduce paradigm in the cloud. Analysis shows the methods described to integrate Hadoop with workflows and science gateways work well in different scenarios and can be used to create massively parallel applications for scientific analysis of Big Data. © 2015 IEEE.","cloud computing, Hadoop, science gateways, workflow systems",1,0,0,1
10.1109/IWSG.2015.17,The Digital Repository of Ireland,International Workshop on Science Gateways,2015,Conference Paper,"The Digital Repository of Ireland is a trusted digital repository that contributes to a national digital infrastructure for the humanities and social sciences in Ireland. Although trusted digital repositories are not mainstream application in the domain of science gateways and the social sciences are not the usual domain for a science gateway we argue in this paper that DRI has many of the principal characteristics of a science gateway and that the domain of social science will benefit in the future from the same advantages that other more numerical-based disciplines reap from science gateways. In addition to offering tools to ingest vast amounts of heterogeneous data sets, a trusted digital repository must offer specific functionalities regarding persistence and trustworthiness of the stored data sets. Trusted digital repositories must maintain the information for a long period and this entails precise and at times difficult choices in the architecture and implementation details. Another facet in which DRI (and most TDRs) differ from mainstream science gateways is the relationship between data and metadata, in many science gateways, metadata is created from the automated analysis of data sets, while in DRI much of the metadata is manually defined by specialised users. Furthermore, as the data sets are heterogeneous in nature, the metadata used for their description is of crucial importance. In this paper we argue that TDRs such as DRI, will play an increasingly important role in the future of the social science community and that they constitute the modern equivalent of the great libraries of the past, places in which knowledge was kept and preserved to be available to researchers of the present and the future. Furthermore, although DRI is far from being the only Trusted Digital Repository available, we argue that certaing design decision such as the support of multiple metadata standards and its modular nature, make it an interesting example of a flexible TDR. © 2015 IEEE.","Digital Repository of Ireland, Distributed Storage, Social Sciences, Trusted Digital Repository",1,0,0,1
10.1109/IWSG.2015.20,Connecting Workflow-Oriented Science Gateways to Multi-cloud Systems,International Workshop on Science Gateways,2015,Conference Paper,"In this paper we investigate solutions to cloud-enable workflow-oriented science gateways. The integration mechanism described in the paper is a generic method that can be followed by other gateway developers. The paper describes the principles and the concrete ways how to integrate science gateways with multi-cloud systems. The concrete example to demonstrate the integration principles builds on the integration of WS-PGRADE/gUSE and the Cloud Broker Platform (CBP). The integration of WS-PGRADE/gUSE and Cloud Broker offers a complete cloud-enabled science gateway platform for a diverse set of use-cases and user communities, with the availability to use mainstream cloud middleware types and services (Amazon EC2/S3, IBM, Open Stack, Open Nebula, Rados S3). The advantage of the integrated WS-PGRADE/gUSE/CBP system is that if a domain-specific science gateway is customized from WS-PGRADE/gUSE gateway framework it immediately inherits this cloud access flexibility, i.e. The user community of that gateway can access all the cloud types enabled by the integrated WS-PGRADE/gUSE/CBP system. © 2015 IEEE.","cloud computing, distributed infrastructures, workflows",1,0,0,1
10.1109/IWSG.2015.7,Web Services as Building Blocks for Science Gateways in Astrophysics,International Workshop on Science Gateways,2015,Conference Paper,"An efficient exploitation of the Distributed Computing Infrastructures (DCIs) is specially needed to deal with the data deluge that the scientific community, in particular the Astrophysics one, is facing. This requires a good understanding of the underlying DCIs. Science Gateways (SGs) provide the users with an environment that eases the interaction with the DCIs. As a previous step, IT skilled users should populate the SGs with friendly but advanced tools (e.g. Workflows, visualization tools) that not only support the scientists to build their own experiments but also adapt them in an optimal way to the infrastructures. In Astronomy, the Virtual Observatory provides the community with services and tools for data access and sharing. However, state of the art telescopes and the coming Square Kilometre Array (SKA), able to reach data rates in the exa-scale domain, will also require advanced tools for data analysis and visualization that should be run on DCIs as well as shared on SGs. In the here presented work, we have selected as exemplar a set of analysis tasks of interest for some SKA use cases. These analysis tasks have been implemented as web services that use the COMPSs programming model in order to achieve a more efficient use of the DCIs. At the same time, the nature of the web services turns them into blocks that the astronomers can combine with VO services to build their own workflows. The web services and the workflows built upon them form a two-level workflow system that hides the technical details of the DCIs and exploits them efficiently. This approach is used for the first time in analytical tasks of interest for the SKA that benefits from the capabilities of the DCIs. © 2015 IEEE.","Astronomy, distributed computing infrastructures, science gateways, virtual observatory, web services, workflows",1,0,0,1
10.1109/IWSG.2015.8,Towards an Industry Data Gateway: An Integrated Platform for the Analysis of Wind Turbine Data,International Workshop on Science Gateways,2015,Conference Paper,"The increasing amount of data produced in many scientific and engineering domains creates as many new challenges for an efficient data analysis, as possibilities for its application. In this paper, we present one of the use-cases of the project VAVID, namely the condition monitoring of sensor information from wind turbines, and how a data gateway can help to increase the usability and security of the proposed system. Starting by briefly introducing the project, the paper presents the problem of handling and processing large amount of sensor data using existing tools in the context of wind turbines. It goes on to describe the innovative approach used in VAVID to meet this challenge, covering the main goals, numerical methods used for analysis, the storage concept, and architectural design. It concludes by offering a rational for the use of a data gateway as the main entry point to the system and how this is being implemented in VAVID. © 2015 IEEE.","big data, HPC, science gateways, VAVID, wind turbine",1,0,0,1
10.1109/MIPRO.2015.7160260,Science gateway for distributed multiscale course management in e-Science and e-Learning — Use case for study and investigation of functionalized nanomaterials,"International Convention on Information and Communication Technology, Electronics and Microelectronics",2015,Conference Paper,"The current tendency of human learning and teaching is targeted to development and integration of digital technologies (like cloud solutions, mobile technology, learning analytics, big data, augmented reality, natural interaction technologies, etc.). Our Science Gateway (http://scigate.imp.kiev.ua) in collaboration with High Performance Computing Center (http://hpcc.kpi.ua) is aimed on the close cooperation among the main actors in learning and researching world (teachers, students, scientists, supporting personnel, volunteers, etc.) with industry and academia to propose the new frameworks and interoperability requirements for the building blocks of a digital ecosystem for learning (including informal learning) that develops and integrates the current and new tools and systems. It is the portal for management of distributed courses (workflows), tools, resources, and users, which is constructed on the basis of the Liferay framework and gUSE/WS-PGRADE technology. It is based on development of multi-level approach (as to methods/algorithms) for effective study and research through flexible selection and combination of unified modules ('gaming' with modules as with LEGO-bricks). It allows us to provide the flexible and adjustable framework with direct involvement in real-world and scientific use cases motivated by the educational aims of students and real scientific aims in labs. © 2015 MIPRO.","Metals, Nanocrystals, Nanomaterials, portals, Electronic learning, Logic gates",1,0,0,1
10.1109/NANO.2011.6144581,NanoHUB.org - the ABACUS tool suite as a framework for semiconductor education courses,IEEE International Conference on Nanotechnology,2011,Conference Paper,"More than 170,000 users annually in 172 countries use nanoHUB.org for web-based access to simulation programs as well as a vast selection of related content, including online presentations and lectures, teaching materials, curated topic pages, podcasts, and downloads. With over 2500 resources including over 200 simulation tools, the science gateway nanoHUB.org is the world's largest nanotechnology user facility. Over 10,000 research and educational users utilized nanoHUB simulation programs to run over 364,000 simulations last year. In academic year 2009-10, nanoHUB.org content was used in 150 undergraduate and graduate courses at 97 institutions. From the time of its inception through the beginning of 2011, nanoHUB.org has been cited 719 times in the literature. A detailed analysis of these citations indicates a dual use of nanoHUB content in both education and research, with educational tool usage by researchers and research tools migrating into the classroom. By leveraging existing capabilities, we have developed the Assembly of Basic Applications for Coordinated Understanding of Semiconductors (ABACUS) suite of simulation tools and supporting educational content that can serve as an aid to an introductory semiconductor course. ABACUS serves as a one-stop-shop for students and teachers to enable rapid access to the critical elements needed in the introduction to semiconductor devices. © 2011 IEEE.","engineering education, NanoHUB, nanotechnology, science gateways, simulations",1,0,0,1
10.1109/NANO.2013.6721012,nanoHUB-U: A science gateway ventures into structured online education,IEEE Conference on Nanotechnology,2013,Conference Paper,"nanoHUB.org is arguably the largest online nanotechnology user facility in the world. From an initial user base of about 1,000 users, nanoHUB has grown to support over 250,000 users annually. nanoHUB supports users in 172 countries with materials for research and education, along with a wide variety of simulation tools covering many nano-related areas. Preliminary assessments of user behavior patterns have shown that nanoHUB's open access approach enables published resources to be integrated directly into classrooms. However, there is an increasing demand for pedagogically sound, workforce-ready, advanced courses that allow users to gain depth in topical areas related to nanotechnology. This paper explores an initial case study where an evolving cyber environment, based on the powerful HUBzero platform, begins to offer structured online courses to its massive audience through an experiment known as nanoHUB-U. This paper describes the impetus for this new offering and discusses how new and cutting-edge content formats are being combined with online simulations in significant ways. Further, it explores in-depth the outcomes related to one of the most popular courses offered to date. © 2013 IEEE.","Materials, Educational institutions, Nanoscale devices, computational modeling, Communities",1,0,0,1
10.1109/NMDC.2011.6155316,Network for Computational Nanotechnology - a strategic plan for global knowledge transfer in research and education,IEEE Nanotechnology Materials and Devices Conference,2011,Conference Paper,"The Network for Computational Nanotechnology (NCN) manages the science gateway nanoHUB.org, recognized as the world's largest nanotechnology user facility, with over 2800 research and teaching resources in use by over 180,000 users annually. Resources consist of 220 simulation tools and nearly 2600 other content items ranging from podcasts of lectures to first time user guides for simulation tools to complete sets of university course materials. Simulation tools developed for research have been found to be used in the classroom and simple classroom tools are being used by researchers. With a global community spread across 172 countries, nanoHUB.org facilitates fast knowledge transfer across countries, disciplines, and communities. NCN follows a carefully planned strategy to lower barriers to this knowledge transfer and the growth and success of the site validates this strategy. © 2011 IEEE.","Lead, Random access memory, Logic gates, computational modeling, Organizations, Industries",1,0,0,1
10.1109/PDP.2013.31,VisIVO Workflow-Oriented Science Gateway for Astrophysical Visualization,"Euromicro International Conference on Parallel, Distributed, and Network-Based Processing",2013,Conference Paper,"Nowadays visualization-based knowledge discovery can play an important role in astrophysics. Collaborative visualization can enable multiple users to share visualization experiences, e.g. by interacting simultaneously with astrophysical datasets giving feedback on what other participants are doing/seeing. Further, workflow-driven applications allow reproduction of specific visualization results, a challenging task as selecting suitable visualization parameters may not be a straightforward process. This paper presents VisIVO Science Gateway, a web-based workflow-enabled framework integrating large-scale, multidimensional datasets and applications for visualization and data filtering on Distributed Computing Infrastructures (DCIs). Advanced users are able to create, change, invoke, and monitor workflows while standard users are provided with easy-to-use customised web interfaces hiding all technical aspects of the visualization algorithms and DCI configurations. © 2013 IEEE.","Collaborative Tools, grid computing, scientific gateways, scientific visualization, workflow systems",1,0,0,1
10.1109/SACI.2016.7507364,Supporting health smart system applications in Scientific Gateway environment,IEEE International Conference on Cluster Computing,2016,Conference Paper,"Smart system applications are spreading worldwide, specifically health monitoring has gained outstanding interest and importance over the last years. Data captured from sensors arrive continuously and only efficient large scale data handling using data stream processing can cope with the transport requirements. Stream processing means that without intermediate storage the data should be processed as they are received from the sensors. In this paper we have developed a simulation environment and we have investigated the influencing factors of the time needed to execute the jobs. Our goal was to optimize the overall time needed to submit the smart system application. With the help of statistical tools we have also performed computations and in case of different middlewares and storages we have carried out measurements. The results show that the job submission time is minimal for applications that use Direct Cloud access in Pgrade/gUSE/DCI-Bridge environment. We have also investigated the effects of the parallelization degree on the system efficiency and the results show that until a certain degree the parallelization also positively effects the system's throughput. © 2016 IEEE.","direct cloud, execution optimization, execution time minimization, smart system application",1,0,0,1
10.1109/SOSE.2014.73,Customizing Scientific Data Analytic Platforms via SaaS Approach,IEEE International Symposium on Service-Oriented System Engineering,2014,Conference Paper,"At the era of data driven science discovery, it is essential to provide customizable scientific data analytic platforms for researchers to conduct their personalized data intensive analysis. Science Gateway has been a viable solution to enabling scientists to run scientific simulations, data analysis, and visualization through their web browsers. But most science gateway frameworks are designed for integrating commonly used software tools and datasets in a specific science domain, thus requiring significant effort to implement the essential variability in lab-specific data processing workflows. In this paper we introduce a multitenancy architecture (MTA) based customization framework that can greatly accelerate the customization cycle of science gateway systems. Each tenant has his own workspace that assembles the software stack and tools to meet the software requirements of his specific data analytics tasks. Through this framework, developers can import their domain-specific analysis pipeline scripts and mashup relevant templates including GUI templates, tool recipes and workspace templates to generate both workspace and web interface for running these application workflows and visualizing the output from workflow executions without writing extra wrapping code. © 2014 IEEE.","clouds, software-as-a-service, science gateways, workflows",1,0,0,1
10.1109/UCC.2011.46,Practical Considerations in Cloud Utilization for the Science Gateway nanoHUB.org,IEEE International Conference on Utility and Cloud Computing,2011,Conference Paper,"nanoHUB.org is arguably the largest online nanotechnology user facility in the world. Just between July 2010 and June 2011 it served 177,823 users. 10,477 users ran 393,648 simulation jobs on a variety of computational resources ranging from HUB zero-based virtual execution hosts for rapid, interactive runs as well as grid-based resources for computationally-intense runs. We believe that as such our users experience a fully operational scientific ""cloud""-based infrastructure even though it is not using ""standard"" computational cloud infrastructures such as EC2. In this paper we explore the use of standard computational cloud-based resources to determine whether they can deliver satisfactory outcomes for our users without requiring high personnel costs for configuration. In a science gateway environment, the assignment of jobs to the appropriate computational resource is not trivial. Resource availability, wait time, time to completion, and likelihood of job success must all be considered in order to transparently deliver an acceptable level of service to our users. In this paper, we present preliminary results examining the benefits and drawbacks of utilizing standard computational cloud resources as one potential venue for nano HUB computational runs. In summary we find that cloud resources performed competitively with other grid resources in terms of wait time, CPU usage, and success in a multiple job submission strategy. © 2011 IEEE.","cloud computing, cyber-environments, grid computing, HUBzero, NanoHUB, nanotechnology, performance monitoring, science gateways",1,0,0,1
10.1109/VAST.2010.5650854,ALIDA: Using machine learning for intent discernment in visual analytics interfaces,IEEE Symposium on Visual Analytics Science and Technology,2010,Conference Paper,"In this paper, we introduce ALIDA, an Active Learning Intent Discerning Agent for visual analytics interfaces. As users interact with and explore data in a visual analytics environment they are each developing their own unique analytic process. The goal of ALIDA is to observe and record the human-computer interactions and utilize these observations as a means of supporting user exploration; ALIDA does this by using interaction to make decision about user interest. As such, ALIDA is designed to track the decision history (interactions) of a user. This history is then utilized to enhance the user's decision-making process by allowing the user to return to previously visited search states, as well as providing suggestions of other search states that may be of interest based on past exploration modalities. The agent passes these suggestions (or decisions) back to an interactive visualization prototype, and these suggestions are used to guide the user, either by suggesting searches or changes to the visualization view. Current work has tested ALIDA under the exploration of homonyms for users wishing to explore word linkages within a dictionary. Ongoing work includes using ALIDA to guide users in transfer function design for volume rendering within scientific gateways. ©2010 IEEE.","artificial intelligence, Cognition, Intent discernment, Volume rendering",1,0,0,1
10.1109/WSC.2017.8247813,Open science: Approaches and benefits for modeling &amp; simulation,Winter Simulation Conference,2017,Conference Paper,"Open Science is the practice of making scientific research accessible to all. It promotes open access to the artefacts of research, the software, data, results and the scientific articles in which they appear, so that others can validate, use and collaborate. Open Science is also being mandated by many funding bodies. The concept of Open Science is new to many Modelling & Simulation (M&S) researchers. To introduce Open Science to our field, this paper unpacks Open Science to understand some of its approaches and benefits. Good practice in the reporting of simulation studies is discussed and the Strengthening the Reporting of Empirical Simulation Studies (STRESS) standardized checklist approach is presented. A case study shows how Digital Object Identifiers, Researcher Registries, Open Access Data Repositories and Scientific Gateways can support Open Science practices for M&S research. The article concludes with a set of guidelines for adopting Open Science for M&S. © 2017 IEEE.","Open Access, Licenses, Object recognition, Gold, computational modeling, Logic gates",1,0,0,1
10.1109/WSC40007.2019.9004845,Building Global Research Capacity in Public Health: The Case of a Science Gateway for Physical Activity Lifelong Modelling and Simulation,Proceedings - Winter Simulation Conference,2019,Conference Paper,"Physical inactivity is a major risk factor for non-communicable disease and has a negative impact on quality of life in both high and low- and middle- income countries (LMICs). Increasing levels of physical activity is recognized as a strategic pathway to achieving the UN's 2030 Sustainable Development Goals. Research can support policy makers in evaluating strategies for achieving this goal. Barriers limit the capacity of researchers in LMICs. We discuss how global research capacity might be developed in public health by supporting collaboration via Open Science approaches and technologies such as Science Gateways and Open Access Repositories. The paper reports on how we are contributing to research capacity building in Ghana using a Science Gateway for our PALMS (Physical Activity Lifelong Modelling Simulation) agent-based micro-simulation that we developed in the UK, and how we use an Open Access Repository to share the outputs of the research. © 2019 IEEE.","Sociology, statistics, Open Access, Logic gates, Diabetes, computational modeling, Buildings",1,0,0,1
10.23919/URSIGASS51995.2021.9560265,The INAF Radio Data Archive: towards a modern Science Gateway,General Assembly and Scientific Symposium of the International Union of Radio Science,2021,Conference Paper,"In the Big Data era, the amount and complexity of astronomical data more and more often prevents the scientist from locally store and process her/his data. As a consequence, the geographically distributed approach to data archiving and processing is rapidly becoming a requisite. To fulfill this need, we are realizing a prototype of Science Gateway (SG) for the Italian radio telescopes. The huge amount of significantly complex and resource-demanding datasets delivered by the Italian radio telescopes and the variety of use cases from the different observing modes represent an ideal test bed for the implementation and verification of a SG environment where the scientists can exploit, manage and analyse data. To this aim, we are exploiting our previous experience in the realization of a geographically-distributed radio data archive and processing tools as well as in the design of SG prototypes. Such a coordinated approach and harmonization of resources will maximize the return for the Italian observing facilities and, moreover, will match the requirements of the international community for a state-of-the-art, highly-performant environment in which to conduct successful science. © 2021 URSI.","radio astronomy, Prototypes, Distributed databases, Logic gates, Tools, big data, Complexity theory",1,0,0,1
10.1002/0471250953.bi0122s42,Using the iplant collaborative discovery environment,Current Protocols in Bioinformatics,2013,Article,"The iPlant Collaborative is an academic consortium whose mission is to develop an informatics and social infrastructure to address the ""grand challenges"" in plant biology. Its cyberinfrastructure supports the computational needs of the research community and facilitates solving major challenges in plant science. The Discovery Environment provides a powerful and rich graphical interface to the iPlant Collaborative cyberinfrastructure by creating an accessible virtual workbench that enables all levels of expertise, ranging from students to traditional biology researchers and computational experts, to explore, analyze, and share their data. By providing access to iPlant's robust data-management system and high-performance computing resources, the Discovery Environment also creates a unified space in which researchers can access scalable tools. Researchers can use available Applications (Apps) to execute analyses on their data, as well as customize or integrate their own tools to better meet the specific needs of their research. These Apps can also be used in workflows that automate more complicated analyses. This module describes how to use the main features of the Discovery Environment, using bioinformatics workflows for high-throughput sequence data as examples. © 2013 by John Wiley & Sons, Inc.","bioinformatics, Computational biology, cyberinfrastructures, Plant biology, Plant sciences, RNA-Seq, science gateways",1,0,0,1
10.1002/cpe.1654,P-GRADE portal family for grid infrastructures,Concurrency and Computation: Practice and Experience,2011,Article,"P-GRADE portal is one of the most widely used general-purpose grid portal in Europe. The paper summarizes the most advanced features of P-GRADE, such as parameter sweep workflow execution, multi-grid workflow execution and integration with the DSpace workflow repository. It also shows the NGS P-GRADE portal that extends P-GRADE with the GEMLCA legacy code execution support in Grid systems, as well as with coarse-grain workflow interoperability services. Next, the paper introduces the second generation P-GRADE portal called WS-PGRADE that merges the advanced features of the first generation P-GRADE portals and extends them with new workflow and architecture concepts. Finally, the application-specific science gateway of the CancerGrid project is briefly described to demonstrate that application-specific portals can easily be developed on top of the general-purpose WS-PGRADE portal. Copyright © 2010 John Wiley & Sons, Ltd.","grid, interoperability, portals, portal framework, repository, science gateways, workflows",1,0,0,1
10.1002/cpe.1664,Generating web-based user interfaces for computational science,Concurrency and Computation: Practice and Experience,2011,Article,"Scientific gateways in the form of web portals are becoming the popular approach to share knowledge and resources around a topic in a community of researchers. Unfortunately, the development of web portals is expensive and requires specialists skills. Commercial and more generic web portals have a much larger user base and can afford this kind of development. Here we present two solutions that address this problem in the area of portals for scientific computing; both take the same approach. The whole process of designing, delivering and maintaining a portal can be made more cost-effective by generating a portal from a description rather than programming in the traditional sense. We show four successful use cases to show how this process works and the results it can deliver. Copyright © 2010 John Wiley & Sons, Ltd.","computational science, life sciences, portal development, portals",1,0,0,1
10.1002/cpe.3049,A Web 2.0-based science gateway for massive remote sensing image processing,Concurrency and Computation: Practice and Experience,2015,Article,"With the incessant expansion of applications and the frequent update of the software, Science Gateway for Massive Remote Sensing Image Processing (SGMRSIP), developed by client/server model or traditional browser/server model, has received more and more challenges. Fortunately, the Web 2.0 technologies, proposed in recent years, bring us a new user experience (UE) that has a fast response speed and a good interface. In particular, the remote sensing image can be processed smoothly in the absence of client software by Web 2.0 technologies. Hence, a Web 2.0-based browser/server model is designed for SGMRSIP to enhance the UE in this paper. Firstly, functions of a parallel remote sensing image processing portal, based on high performance cluster and client/server model, are summarized. And then, a Web 2.0-based interaction model is built, and all these functions are accomplished again on the basis of this model. Finally, the Web 2.0-based Science Gateway is achieved. In addition, we design different workflows for different satellite data, and all the processing tasks are finished successfully to verify the feasibility of this Science Gateway. The experimental results showed that the software scalability and interaction were improved and a better UE was achieved, compared with the existing SGMRSIP. Copyright © 2013 John Wiley & Sons, Ltd.","parallel remote sensing image processing, science gateways, web2.0",1,0,0,1
10.1002/cpe.3234,Batchsubmit: A high-volume batch submission system for earthquake engineering simulation,Concurrency and Computation: Practice and Experience,2014,Article,"Network for Earthquake Engineering Simulation (NEES) is a network of 14 earthquake engineering labs distributed across the USA. As a part of the NEES effort NEESComm operates a comprehensive cyberinfrastructure that consists of the NEEShub and the NEES Project Warehouse. NEESComm provides consistent access to several high performance computing (HPC) venues. These venues include Extreme Science and Engineering Discovery Environment, the Open Science Grid, Purdue Supercomputers, and NEEShub servers. In this paper, we describe the system we developed, batchsubmit, which allows NEES researchers to make use of all these venues through the NEEShub science gateway. Copyright © 2014 John Wiley and Sons, Ltd.","earthquake engineering, high-performance computing, simulations",1,0,0,1
10.1002/cpe.3251,Advancements of the UltraScan scientific gateway for open standards-based cyberinfrastructures,Concurrency and Computation: Practice and Experience,2014,Article,"The UltraScan data analysis application is a software package that is able to take advantage of computational resources in order to support the interpretation of analytical ultracentrifugation experiments. Since 2006, the UltraScan scientific gateway has been used with Web browsers in TeraGrid by scientists studying the solution properties of biological and synthetic molecules. UltraScan supports its users with a scientific gateway in order to leverage the power of supercomputing. In this contribution, we will focus on several advancements of the UltraScan scientific gateway architecture with a standardized job management while retaining its lightweight design and end user interaction experience. This paper also presents insights into a production deployment of UltraScan in Europe. The approach is based on open standards with respect to job management and submissions to the Extreme Science and Engineering Discovery Environment in the USA and to similar infrastructures in Europe such as the European Grid Infrastructure or the Partnership for Advanced Computing in Europe (PRACE). Our implementation takes advantage of the Apache Airavata framework for scientific gateways that lays the foundation for easy integration into several other scientific gateways. Copyright © 2014 John Wiley & Sons, Ltd.","apache airavata, scientific gateways, standards, Ultrascan, UNICORE",1,0,0,1
10.1002/cpe.3255,Science gateway technologies for the astrophysics community,Concurrency and Computation: Practice and Experience,2015,Article,"SummaryThe availability of large-scale digital surveys offers tremendous opportunities for advancing scientific knowledge in the astrophysics community. Nevertheless, the analysis of these data often requires very powerful computational resources. Science gateway technologies offer Web-based environments to run applications with little concern for learning and managing the underlying infrastructures that execute them. This paper focuses on the issues related to the development of a science gateway customized for the needs of the astrophysics community. The VisIVO Science Gateway is wrapped around a WS-PGRADE/grid User Support Environment portal integrating services for processing and visualizing large-scale multidimensional astrophysical data sets on distributed computing infrastructures. We discuss the core tools and services supported including an application for mobile access to the gateway. We report our experiences in supporting specialized astrophysical communities requiring development of complex workflows for visualization and numerical simulations. Further, available platforms are discussed for sharing workflows in collaborative environments. Finally, we outline our vision for creating a federation of science gateways to benefit astrophysical communities by sharing a set of services for authentication, computing infrastructure access and data/workflow repositories. Copyright © 2014 John Wiley & Sons, Ltd. Copyright © 2014 John Wiley & Sons, Ltd.","astrophysics, collaborative environments, DCIs, large-scale datasets, science gateways, visualization, workflow systems",1,0,0,1
10.1002/cpe.3256,CyberGIS Gateway for enabling data-rich geospatial research and education,Concurrency and Computation: Practice and Experience,2015,Article,"SummaryThis paper describes CyberGIS Gateway as an online problem-solving environment for multiple science communities to conduct data-rich geospatial research and education. CyberGIS Gateway is a key modality in the CyberGIS software environment. Scalable gateway application integration has been the focus of CyberGIS Gateway in order to efficiently develop highly interactive online geographic information systems (GIS) user interface components and couple a rich collection of heterogeneous and distributed geospatial data and analytical services for advanced cyberGIS capabilities on advanced cyberinfrastructure. An open mashup and service API approach is developed to address the integration challenges in CyberGIS Gateway application development. This approach is applied and evaluated in developing several representative cyberGIS data and analytical applications. The experience gained from the integration practice is shared. The education and outreach activities in CyberGIS Gateway are presented to illustrate the impact of CyberGIS Gateway in GIScience communities and the effective collaboration within the science gateway community. Copyright © 2014 John Wiley & Sons, Ltd. Copyright © 2014 John Wiley & Sons, Ltd.","CyberGIS, cyberinfrastructures, geospatial problem solving, science gateways, spatial analysis",1,0,0,1
10.1002/cpe.3257,HUBzero and Pegasus: Integrating scientific workflows into science gateways,Concurrency and Computation: Practice and Experience,2015,Article,"Summary In this paper, we described the benefits and the challenges of integrating existing scientific workflow technologies into science gateways. Scientific workflow managers are powerful tools for handling large computational tasks. Domain scientists find it difficult to create new workflows, so many tasks that could benefit from workflow automation are often avoided or performed by hand. Two technologies have come together to bring the benefits of workflow to the masses. The Pegasus Workflow Management System can manage workflows comprised of millions of tasks, all the while recording data about the execution and intermediate results so that the provenance of the final result is clear. The HUBzero platform for scientific collaboration provides a venue for building and delivering tools to researchers and educators. With the press of a button, these tools can launch Pegasus workflows on national computing infrastructures and bring results back for plotting and visualization. As a result, the combination of Pegasus and HUBzero is bringing high-throughput computing to a much wider audience. Copyright © 2014 John Wiley & Sons, Ltd. Copyright © 2014 John Wiley & Sons, Ltd.","automation, collaboratories, computation, user interfaces, workflows",1,0,0,1
10.1002/cpe.3258,Experiences of the Brazilian national high-performance computing network on the rapid prototyping of science gateways,Concurrency and Computation: Practice and Experience,2015,Article,"SummaryArguably, an important amount of scientific software development time is likely to be employed on user interfaces. In particular, science gateways have gained increasing interest from the e-Science community. These gateways allow hiding the complexity of the underlying resources that give support to the management of scientific data and to the execution of scientific applications. Based on our previous experience with the development of science gateways for diverse application domains in the Brazilian national high-performance computing network (SINAPAD), we have devised a rapid prototyping strategy to lower the barrier for scientific application developers to launch new science gateways. This strategy is based on two main tools. The first tool implements a gateway engine that can be configured by a small set of XML files. Such files completely define the desired functionality of a specific science gateway in the gateway engine. The gateway engine also offers other features not commonly found in related technologies, such as file sharing, data provenance tracking, and restricted anonymous access to underlying computational resources. The second tool implements both an editor and a packager for the aforementioned engine. This tool allows the developer to rapidly deploy and launch a new science gateway in ordinary Web application containers. In this paper, we present our results with the use of both tools in the SINAPAD network. We also discuss about the current limitations of both tools, as well as how we have been dealing with such limitations to provide a more comprehensive toolset to developers. Copyright © 2014 John Wiley & Sons, Ltd. Copyright © 2014 John Wiley & Sons, Ltd.","e-science, high-performance computing, science gateways",1,0,0,1
10.1002/cpe.3262,Globus platform-as-a-service for collaborative science applications,Concurrency and Computation: Practice and Experience,2015,Article,"Summary Globus, developed as software-as-a-service for research data management, also provides APIs that constitute a flexible and powerful platform-as-a-service to which developers can outsource data management activities such as transfer and sharing, as well as identity, profile, and group management. By providing these frequently important but always challenging capabilities as a service, accessible over the network, Globus platform-as-a-service streamlines Web application development and makes it easy for individuals, teams, and institutions to create collaborative applications such as science gateways for science communities. We introduce the capabilities of this platform and review representative applications. Copyright © 2014 John Wiley & Sons, Ltd. Copyright © 2014 John Wiley & Sons, Ltd.","authentication, authorization, clouds, collaboration, group, identity, platform-as-a-service, profile, science gateways, sharing, transfer",1,0,0,1
10.1002/cpe.3268,A GEANT4 web-based application to support Intra-Operative Electron Radiotherapy using the European grid infrastructure,Concurrency and Computation: Practice and Experience,2015,Article,"Summary Radiotherapy techniques deliver ionizing radiations (X-rays, photons, electrons, protons, etc.) inside cancerous tissues to kill the abnormal cells. Radiotherapy-related activities such as the optimization of the therapeutic radiation dose to patients, workers' radioprotection, linear accelerator commissioning, quality assurance processes and technical innovations of linear accelerators are strongly based on the ability to predict the dose distribution. Monte Carlo based simulations are so far the most accurate tool for the calculation of dosimetric parameters, with the drawback of requiring extensive computing resources to achieve statistically meaningful results in a reasonable time frame. In the last years, advanced cancer treatment clinical and research communities have used e-Infrastructures to support their activities. The present paper reports on the development of a computing facility for helping clinical researchers in using modern R&E networking and distributed computing and storage resources for a new radiotherapy technique: the Intra-Operative Electron Radiotherapy. The web application developed addresses some technical and clinical needs as the design of linear accelerators' collimation systems and the optimization of the patient therapeutic dose distribution. Copyright © 2014 John Wiley & Sons, Ltd. Copyright © 2014 John Wiley & Sons, Ltd.","Catania Science Gateway Framework, distributed computing, GEANT4, grid computing, IOERT, Monte Carlo method",1,0,0,1
10.1002/cpe.3281,"A data-centric neuroscience gateway: Design, implementation, and experiences",Concurrency and Computation: Practice and Experience,2015,Article,"Summary Science gateways provide UIs and high-level services to access and manage applications and data collections on distributed resources. They facilitate users to perform data analysis on distributed computing infrastructures without getting involved into the technical details. The e-BioInfra Gateway is a science gateway for biomedical data analysis on a national grid infrastructure, which has been successfully adopted for neuroscience research. This paper describes the motivation, requirements, and design of a new generation of e-BioInfra Gateway, which is based on the grid and cloud user support environment (also known as WS-PGRADE/gUSE framework) and supports heterogeneous infrastructures. The new gateway has been designed to have additional data and meta-data management facilities to access and manage (biomedical) data servers, and to provide data-centric user interaction. We have implemented and deployed the new gateway for the computational neuroscience research community of the Academic Medical Center of the University of Amsterdam. This paper presents the system architecture of the new gateway, highlights the improvements that have been achieved, discusses the choices that we have made, and reflects on those based on initial user feedback. Copyright © 2014 John Wiley & Sons, Ltd. Copyright © 2014 John Wiley & Sons, Ltd.","computational neuroscience, e-science, grid computing, medical image analysis, problem solving environment , science gateways, virtual laboratory, virtual research enviroment (VRE)",1,1,0,2
10.1002/cpe.3283,Early experiences in developing and managing the neuroscience gateway,Concurrency and Computation: Practice and Experience,2015,Article,"Summary The last few decades have seen the emergence of computational neuroscience as a mature field where researchers are interested in modeling complex and large neuronal systems and require access to high performance computing machines and associated cyber infrastructure to manage computational workflow and data. The neuronal simulation tools, used in this research field, are also implemented for parallel computers and suitable for high performance computing machines. But using these tools on complex high performance computing machines remains a challenge because of issues with acquiring computer time on these machines located at national supercomputer centers, dealing with complex user interface of these machines, dealing with data management and retrieval. The Neuroscience Gateway is being developed to alleviate and/or hide these barriers to entry for computational neuroscientists. It hides or eliminates, from the point of view of the users, all the administrative and technical barriers and makes parallel neuronal simulation tools easily available and accessible on complex high performance computing machines. It handles the running of jobs and data management and retrieval. This paper shares the early experiences in bringing up this gateway and describes the software architecture it is based on, how it is implemented, and how users can use this for computational neuroscience research using high performance computing at the back end. We also look at parallel scaling of some publicly available neuronal models and analyze the recent usage data of the neuroscience gateway. Copyright © 2014 John Wiley & Sons, Ltd. Copyright © 2014 John Wiley & Sons, Ltd.","computational neuroscience, high-performance computing, NEURON, science gateways",1,0,0,1
10.1002/cpe.3285,Recipes 2.0: Building for today and tomorrow,Concurrency and Computation: Practice and Experience,2015,Article,"SummaryThe history of science gateway development has, in many ways, been a story of the 'Haves' vs. the 'Have-nots'. Large infrastructure projects led the way, building thick client portals to provide coherent interfaces to an incoherent environment. Contrast this with the way the modern Web is designed using light, front end components, and outsourcing much of the heavy lifting to a mash-up of REST application programming interfaces, and it is easy to see why modern web applications can be prototyped and refined into stable products in the time it previously took thick client portals to do an initial release. This paper argues that a 'build for today' philosophy can lead to the rapid development of science gateways to serve the 'Have-nots'. With this philosophy in mind, we are presenting Gateway DNA, a set of responsive front end components built on top of the iPlant Agave application programming interfaces. This toolkit provides the boilerplate for rapid development of lightweight science gateways using only HTML, JavaScript, and CSS. Using Gateway DNA, developers can easily stand up new gateways or quickly add new functionality to existing ones. Copyright © 2014 John Wiley & Sons, Ltd. Copyright © 2014 John Wiley & Sons, Ltd.","Agave, API, HTML5, javascript, REST, science gateways, web, Web service",1,0,0,1
10.1002/cpe.3292,Quantum chemical meta-workflows in MoSGrid,Concurrency and Computation: Practice and Experience,2015,Article,"Summary Quantum chemical workflows can be built up within the science gateway Molecular Simulation Grid. Complex workflows required by the end users are dissected into smaller workflows that can be combined freely to larger meta-workflows. General quantum chemical workflows are described here as well as the real use case of a spectroscopic analysis resulting in an end-user desired meta-workflow. All workflow features are implemented via Web Services Parallel Grid Runtime and Developer Environment and submitted to UNICORE. The workflows are stored in the Molecular Simulation Grid repository and ported to the SHIWA repository. Copyright © 2014 John Wiley & Sons, Ltd. Copyright © 2014 John Wiley & Sons, Ltd.","DCIs, MoSGrid, quantum chemistry, service grids, workflows",1,0,0,1
10.1002/cpe.3486,The Globus Galaxies platform: Delivering science gateways as a service,Concurrency and Computation: Practice and Experience,2015,Article,"The use of public cloud computers to host sophisticated scientific data and software is transforming scientific practice by enabling broad access to capabilities previously available only to the few. The primary obstacle to more widespread use of public clouds to host scientific software ('cloud-based science gateways') has thus far been the considerable gap between the specialized needs of science applications and the capabilities provided by cloud infrastructures. We describe here a domain-independent, cloud-based science gateway platform, the Globus Galaxies platform, which overcomes this gap by providing a set of hosted services that directly address the needs of science gateway developers. The design and implementation of this platform leverages our several years of experience with Globus Genomics, a cloud-based science gateway that has served more than 200 genomics researchers across 30 institutions. Building on that foundation, we have implemented a platform that leverages the popular Galaxy system for application hosting and workflow execution; Globus services for data transfer, user and group management, and authentication; and a cost-aware elastic provisioning model specialized for public cloud resources. We describe here the capabilities and architecture of this platform, present six scientific domains in which we have successfully applied it, report on user experiences, and analyze the economics of our deployments. © 2015 John Wiley & Sons, Ltd.","cloud computing, HPC, science gateways",1,0,0,1
10.1002/cpe.3498,A multi-infrastructure gateway for virtual drug screening,Concurrency and Computation: Practice and Experience,2015,Article,"In computer-aided drug design, software tools are used to narrow down possible drug candidates, thereby reducing the amount of expensive in vitro research, by a process called virtual screening. This process includes large computations that require advanced computing infrastructure; however, using rapidly evolving high-performance computing platforms can be difficult for biochemists. In this paper, we present a science gateway for virtual screening that has been tailored to the specific needs of our local users. The gateway provides user-friendly access to distributed computing infrastructures for high-throughput experiments with a few clicks. Its design is based on the generic layer developed for another gateway for neuroimaging data analysis, including data and computation management, as well as support for its operation. To facilitate scalability, the system architecture allows for adding new computing platforms to the back-end without affecting the front-end, from which the user can dynamically choose the preferred infrastructure. This paper describes the user-centered design process, the system architecture and a performance assessment using gLite grid, Hadoop, and a local cluster. The empirical results show considerable speed-ups and ease of use, as well as user satisfaction. © 2015 John Wiley & Sons, Ltd.","drug discovery, e-science, grid computing, Hadoop, science gateways, virtual screening",1,0,0,1
10.1002/cpe.3519,The GenApp framework integrated with Airavata for managed compute resource submissions,Concurrency and Computation: Practice and Experience,2015,Article,"A new framework (GenApp) for rapid generation of scientific applications running on a variety of systems including science gateways has recently been developed. This framework currently builds a GUI and/or web-based user interface for a variety of target environments on a collection of executable modules. The method for execution of modules has limited framework restrictions: primarily the requirement of wrapping the application to accept input and output formatted in JavaScript Object Notation (JSON). Initial implementation supports direct execution on a user's workstation, a web server, or a compute resource accessible from the web server. After a successful initial workshop utilizing the framework to create a web-based user interface wrapping a scientific software suite, it was discovered that long-running jobs would sometimes fail, because of the loss of a Transmission Control Protocol (TCP) connection. This precipitated an improvement to the execution method with the bonus of easily allowing multiple web clients to attach to the running job. To support a diversity of queue managed compute resources, a Google 'Summer of Code' project was completed to integrate the Apache Airavata middleware as an additional execution model within the GenApp framework. New features of file management, job management with progress, and message box support are described. © 2015 John Wiley & Sons, Ltd.","CASE tools, design, human factors, languages, middleware, science gateways",1,0,0,1
10.1002/cpe.3520,Remote storage management in science gateways via data bridging,Concurrency and Computation: Practice and Experience,2015,Article,"State-of-the-art science gateways can be connected to several distributed computing infrastructures (DCIs) and are able to run jobs and workflows simultaneously in all those DCIs. Flexibility of accessing diverse data storages from these workflows and assisting end users to manage these storages are however the missing features in current gateway implementations, in which these problems often prove to be a barrier of exploiting the power of distributed computing by user communities having no or little IT competence. This paper addresses these issues by integrating a data bridging service called Data Avenue into WS-PGRADE/gUSE portal framework. Data Avenue offers tools for the end users to easily manage their data residing on various storage resources, and also, jobs become capable of accessing different storages regardless of the particular distributed computing infrastructure where the job is currently being run. © 2015 John Wiley & Sons, Ltd.","data handling, data storage systems, data transfer, grid computing",1,0,0,1
10.1002/cpe.3524,Reflections on science gateways sustainability through the business model canvas: Case study of a neuroscience gateway,Concurrency and Computation: Practice and Experience,2015,Article,"The sustainability of science gateways has been a topic of active discussion because they have been created and supported in the context of temporary research and infrastructure projects. As successful projects come to an end, it is necessary to find (new) models to secure continuous exploitation of products generated by these projects. Taking this step requires business considerations that are not trivial to do from the role of a researcher. This paper presents our experiences in adopting a methodology from lean business development, the Business Model Canvas (BMC). This methodology enables structured reflection upon the business model and facilitates exploring alternative ones (pivoting). We have applied the BMC to one of the science gateways designed, developed, and operated by the Academic Medical Center (AMC) e-Science group: the AMC Computational Neuroscience Gateway. The current gateway BMC is explained in the paper and used as basis for a reflection to improve its sustainability. Alternative business models are given as examples of BMC iteration or pivots. This exercise helped us to structure the various aspects to be considered when designing or reflecting upon the business model of our gateway. It also facilitated the visualization of the complete business picture and helps the reflection about improvements in the business model toward sustainability. We believe that this methodology could be valuable also for the reflection about sustainability of other science gateways that are growing from academic groups that do not have business training. © 2015 John Wiley & Sons, Ltd.","Business Model Canvas (BMC), science gateways, sustainability, virtual research environments",1,0,1,2
10.1002/cpe.3525,WorkWays: Interacting with Scientific Workflows,Concurrency and Computation: Practice and Experience,2015,Article,"WorkWays is a science gateway that supports human-in-the-loop scientific workflows. Human-workflow interactions are enabled by a dynamic Input Output (IO) model, which allows users to insert data into, or export data out of, a continuously running workflow. WorkWays has been used to solve a number of scientific problems where the user wishes to examine intermediate results in order to interact with the computation as the workflow progresses. This interactive capability not only provides better insights into the computation but also allows users to focus on different input parameter combinations. We have implemented a variety of data types and modes of interaction to account for a wide range of use cases and application domains. This paper demonstrates the applicability of WorkWays on three use cases from different domains. © 2015 John Wiley & Sons, Ltd.","human-in-the-loop workflows, interactive workflow-based science gateways, science gateways, scientific workflows",1,0,0,1
10.1002/cpe.3533,IMP Science Gateway: From the Portal to the Hub of Virtual Experimental Labs in e-Science and Multiscale Courses in e-Learning,Concurrency and Computation: Practice and Experience,2015,Article,"Science gateway' (SG) ideology means a user-friendly intuitive interface between scientists (or scientific communities) and different software components + various distributed computing infrastructures (DCIs), where researchers can focus on their scientific goals and less on the peculiarities of software/DCI. G.V.Kurdyumov Institute for Metal Physics 'IMP Science Gateway Portal' (http://scigate.imp.kiev.ua) is presented for complex workflow management and integration of distributed computing resources (like clusters, service grids, desktop grids, and clouds). It is created on the basis of Web Service - Parallel Grid Run-time and Application Development Environment (WS-PGRADE) and gUSE (grid and cloud User Support Environment) technologies, where WS-PGRADE is designed for science workflow operation and gUSE - for smooth integration of available resources for parallel and distributed computing in various heterogeneous DCIs. Some use cases (scientific workflows) are considered for molecular dynamics simulations of complex behavior of various nanostructures. The modular approach allows scientists to use SG portals as research hubs of various virtual experimental labs in the context of practical applications in material science, physics, and nanotechnologies. In addition, workflows and their components are proposed to be used as Lego-style construction units for learning modules of various scale by duration, complexity, targeted audience, and so on. These workflows can be used also in e-Learning infrastructures as constituent elements of learning hubs for the management of learning content, tools, resources, and users in the regular, vocational, lifelong, and informal learning. © 2015 John Wiley & Sons, Ltd.","clusters, desktop grid, distributed computing, e-learning, e-science, grid computing, lifelong learning, materials science, nanotechnologies, physics, science gateways, service grid, ubiquitous learning",1,0,0,1
10.1002/cpe.3534,Apache Airavata: Design and Directions of a Science Gateway Framework,Concurrency and Computation: Practice and Experience,2015,Article,"This paper provides an overview and roadmap of the Apache Airavata software system for science gateways. Gateways use Airavata to manage application and workflow executions on a range of backend resources (grids, computing clouds, and local clusters). Airavata's design goal is to provide component abstractions for major tasks required to provide gateway application management. Components are not directly accessed but are instead exposed through component programming interfaces. This design allows gateway developers to take full advantage of Airavata's capabilities and Airavata developers (including those interested in middleware research) to modify Airavata's implementations and behavior. This is particularly important as Airavata evolves to become a scalable, elastic 'platform as a service' for science gateways. We illustrate the capabilities of Airavata through the discussion of usage vignettes. As an Apache Software Foundation project, Airavata's open community governance model is as important as its software base. We discuss how this works within Airavata and how it may be applicable to other distributed computing infrastructure and cyberinfrastructure efforts. © 2015 John Wiley & Sons, Ltd.","cyberinfrastructures, distributed computing infrastructures, science gateways",1,0,0,1
10.1002/cpe.3538,Mobile application development exploiting science gateway-technologies,Concurrency and Computation: Practice and Experience,2015,Article,"Nowadays, collaborative applications are valuable tools for scientists to share their studies and experiences, for example, by interacting simultaneously with their data and outcomes giving feedback to other colleagues on how the data are processed. This paper presents a mobile application connected to a workflow-enabled framework to perform visualization and data analysis of large-scale, multi-dimensional datasets on distributed computing infrastructures. In particular, the usage of workflow-driven applications, through science gateway technologies, allows the scientist to share heavy data exploration tasks as workflows and the relative results in a transparent and user-friendly way. © 2015 John Wiley & Sons, Ltd.","astrophysics, collaborative environments, DCIs, large-scale datasets, mobile application, science gateways, scientific visualization, workflow systems",1,0,0,1
10.1002/cpe.3540,FACE-IT: A Science Gateway for Food Security Research,Concurrency and Computation: Practice and Experience,2015,Article,"Progress in sustainability science is hindered by challenges in creating and managing complex data acquisition, processing, simulation, post-processing, and intercomparison pipelines. To address these challenges, we developed the Framework to Advance Climate, Economic, and Impact Investigations with Information Technology (FACE-IT) for crop and climate impact assessments. This integrated data processing and simulation framework enables data ingest from geospatial archives; data regridding, aggregation, and other processing prior to simulation; large-scale climate impact simulations with agricultural and other models, leveraging high-performance and cloud computing; and post-processing to produce aggregated yields and ensemble variables needed for statistics, for model intercomparison, and to connect biophysical models to global and regional economic models. FACE-IT leverages the capabilities of the Globus Galaxies platform to enable the capture of workflows and outputs in well-defined, reusable, and comparable forms. We describe FACE-IT and applications within the Agricultural Model Intercomparison and Improvement Project and the Center for Robust Decision-making on Climate and Energy Policy. © 2015 John Wiley & Sons, Ltd.","climate impacts and food security, globus galaxies, science gateways",1,0,0,1
10.1002/cpe.3689,GSoC 2015 student contributions to GenApp and Airavata,Concurrency and Computation: Practice and Experience,2016,Article,"GenApp generates applications on an extensible set of target languages for scientific modules. GenApp utilizes JavaScript object notation (JSON) format for all definition files. To create an application, definition files are created for global directives, menu, and modules. Target languages have definition files detailing the steps-mapping code fragments to output. Modules must be wrapped to accept and produce JSON as defined in the module's definition file. Execution models are not defined by GenApp; they are included in target language code fragments. Previously, GenApp included target languages of HTML5/PHP, Qt3/C++, and Qt4/C++ with execution models of direct local execution, a web server, or a web server accessible resource. A Google Summer of Code (GSoC) 2014 student demonstrated Airavata-managed execution in GenApp's current target languages. Subsequently, Airavata's API and GenApp have evolved. Two GSoC-2015 students updated the previous Airavata integration to support the current API and extend target languages to include Qt5/C++, Qt5/Android, and Java. GenApp was initially developed to wrap modules utilized in the small angles scattering field but is not restricted to this discipline. The GenApp philosophy is to minimize effort of the researcher to deploy modules and insure preservation in an evolving software landscape. Generated applications are in production and used by small angle scattering researchers. © Copyright 2015 John Wiley & Sons, Ltd.","CASE tools, design, human factors, languages, middleware, science gateways",1,0,0,1
10.1002/cpe.3698,User applications driven by the community contribution framework MPContribs in the Materials Project,Concurrency and Computation: Practice and Experience,2016,Article,"This work discusses how the MPContribs framework in the Materials Project (MP) allows user-contributed data to be shown and analyzed alongside the core MP database. The MP is a searchable database of electronic structure properties of over 65,000 bulk solid materials, which is accessible through a web-based science-gateway. We describe the motivation for enabling user contributions to the materials data and present the framework's features and challenges in the context of two real applications. These use cases illustrate how scientific collaborations can build applications with their own 'user-contributed' data using MPContribs. The Nanoporous Materials Explorer application provides a unique search interface to a novel dataset of hundreds of thousands of materials, each with tables of user-contributed values related to material adsorption and density at varying temperature and pressure. The Unified Theoretical and Experimental X-ray Spectroscopy application discusses a full workflow for the association, dissemination, and combined analyses of experimental data from the Advanced Light Source with MP's theoretical core data, using MPContribs tools for data formatting, management, and exploration. The capabilities being developed for these collaborations are serving as the model for how new materials data can be incorporated into the MP website with minimal staff overhead while giving powerful tools for data search and display to the user community. © Copyright 2015 John Wiley & Sons, Ltd.","databases, materials science, science gateways, user-contributed data",1,0,0,1
10.1002/cpe.3700,Lessons learned implementing a science gateway for hydro-meteorological research,Concurrency and Computation: Practice and Experience,2016,Article,"A full hydrometeorological (HM) simulation, from rainfall to impact on urban areas, is a multidisciplinary job, which relies on the execution of a workflow composed of complex and heterogeneous model engines. Moreover, the accuracy of the simulation is strongly dependent on an extensive set of configuration parameters, which have to be selected in a consistent way among the models. Within the Distributed Research Infrastructure for Hydro-Meteorology project, a Web-based science gateway was developed with the aim to support HM researchers in designing, executing, and managing HM experiments. The core of this science gateway is the portal, which takes care of generating all the configuration files and handles the execution of simulation steps on a heterogeneous computing infrastructure composed of high-performance computing, Grid resources, and Cloud resources. This paper presents technological insights about the implementation of the portal, with an analysis of the adopted technologies and infrastructures. Our experience highlights the need of coherent policies in the management of data, computational resources, and software components that represent the ecosystem to develop science gateways. © Copyright 2015 John Wiley & Sons, Ltd.","e-infrastructures, hydrometeorology, science gateways",1,0,0,1
10.1002/cpe.3705,Citizen science in risk communication in the era of ICT,Concurrency and Computation: Practice and Experience,2016,Article,"Risk communication is the exchange of information among stakeholders about an impending disaster and its risks to help individuals take appropriate actions to mitigate hazard impacts. While traditional risk communication follows a command and control structure such that information from hierarchical and vertically integrated organizations is disseminated to broader community, social media uses a decentralized, collaborative, and network based communication approach. The growth of information and communication technologies has made social media a popular channel for disseminating alert and warning messages both by citizens and agencies. However, social media suffers from spreading rumors and hoaxes. To minimize rumors and increase citizen communication, a science gateway (Cyber-Infrastructure for GeoInformatics and Community Resilience) has been deployed. This gateway, resulted from a research conducted along the Mississippi Gulf Coast communities, incorporates citizen science to evaluate warning message sources, message contents and dissemination channels to increase public response to warnings. This gateway built on the social construct of risk communication provides opportunities to citizens to share data and information about a hazard, and participate in building community resilience. © Copyright 2015 John Wiley & Sons, Ltd.","contributory citizen science, resilience, risk communication, science gateways",1,0,0,1
10.1002/cpe.3708,"Integrating Apache Airavata with Docker, Marathon, and Mesos",Concurrency and Computation: Practice and Experience,2016,Article,"Science Gateways provide scientists with tools for creating, executing, and monitoring scientific experiments on multiple resource infrastructures. Apache Airavata abstracts interactions between gateways and distributed computing infrastructures like Extreme Science and Engineering Discovery Environment, international grids, and campus clusters. Airavata consists of several component services such as the API server, Orchestrator, Workflow Interpreter, Credential Store, and Application Factory. In addition, Airavata uses third party software, including RabbbitMQ for messaging, MySQL for production database management, and Apache Zookeeper for internal communications. In this paper, we discuss our initial experiences with leveraging open source technologies to manage Airavata and its dependent components to deploy, detect, and restart failed components in an auto-scaling platform. Such capabilities will allow Airavata services to be deployed in a wide area, large Virtual Machine (VM) based cluster, and a developer's laptop. The emerging technologies in cloud computing and Big Data that address these needs are the following: Docker, Marathon, and Apache Mesos. Docker is a Linux-based lightweight container that allows different applications to run isolated from each other but safely share the machine's resources. Docker images of applications can be published in registries and retrieved for execution in the target infrastructures. Marathon provides a cluster-wide init and control system for services, including Docker containers. Mesos provides a cluster-wide framework to schedule tasks based on fine-grained resource needs. Mesosphere provides the packages, scripts, and web interface to ease the use of these technologies. We present the design, experience, and lessons learned from integrating Mesos, Docker, and Marathon with Apache Airavata. © Copyright 2015 John Wiley & Sons, Ltd.","apache airavata, distributed systems, Docker, Marathon, Mesos",1,0,0,1
10.1002/cpe.3715,Failure analysis and prediction for the CIPRES science gateway,Concurrency and Computation: Practice and Experience,2016,Article,"Science gateways promote collaboration among researchers by providing them with access to community-developed tools and data collections. The Cyberinfrastructure for Phylogenetic Research (CIPRES) science gateway is one of the most popular gateways, with approximately 3000 active users since 2012, and the user base is growing each year. While increasing the number of compute resources available to CIPRES would address their growth needs, it also introduces additional complexity as the likelihood of failure increases. In this paper, we analyze historical job data from CIPRES and combine it with historical software and services monitoring data to create a machine learning model to predict where a user's job will complete successfully on resources. At one operating point of our classifier, we are able to detect 50% of jobs that will fail with a false detection rate less than 5%. In 2014, accurately predicting 50% of CIPRES job failures and redirecting them to other resources would have resulted in 900K compute core hours saved, furthering phylogenetic research. These statistical models will also be used as a base to build a more generic automated monitoring analysis service for science gateways. © Copyright 2015 John Wiley & Sons, Ltd.","failure analysis, machine learning, science gateways",1,0,0,1
10.1002/cpe.4682,TopoLens: Building a CyberGIS community data service for enhancing the usability of high-resolution national topographic datasets,Concurrency and Computation: Practice and Experience,2019,Article,"In recent years, geospatial data have exploded to massive volume and diversity and subsequently cause serious usability issues for researchers in various scientific areas. This paper describes a cyberGIS community data service framework to facilitate geospatial big data access, processing, and sharing based on a hybrid supercomputer architecture. Specifically, the framework aims to enhance the usability of national elevation dataset released by the U.S. Geological Survey in the contiguous United States at the resolution of 1/3 arc-second. A community data service, namely TopoLens, is created to demonstrate the workflow integration of national elevation dataset and the associated computation and analysis. Two user-friendly environments, including a publicly available web application and a private workspace based on the Jupyter notebook, are provided for users to access both precomputed and on-demand computed high-resolution elevation data. The system architecture of TopoLens is implemented by exploiting the ROGER supercomputer, the first cyberGIS supercomputer dedicated to geospatial problem-solving. The usability of TopoLens has been acknowledged in the topographic user community evaluation. © 2018 John Wiley & Sons, Ltd.","CyberGIS, geospatial big data, microservices, science gateways, topographic data",1,0,0,1
10.1002/cpe.5040,CyberGIS-Jupyter for reproducible and scalable geospatial analytics,Concurrency and Computation: Practice and Experience,2019,Article,"The interdisciplinary field of cyberGIS (geographic information science and systems (GIS) based on advanced cyberinfrastructure) has a major focus on data- and computation-intensive geospatial analytics. The rapidly growing needs across many application and science domains for such analytics based on disparate geospatial big data poses significant challenges to conventional GIS approaches. This paper describes CyberGIS-Jupyter, an innovative cyberGIS framework for achieving data-intensive, reproducible, and scalable geospatial analytics using Jupyter Notebook based on ROGER, the first cyberGIS supercomputer. The framework adapts the Notebook with built-in cyberGIS capabilities to accelerate gateway application development and sharing while associated data, analytics, and workflow runtime environments are encapsulated into application packages that can be elastically reproduced through cloud-computing approaches. As a desirable outcome, data-intensive and scalable geospatial analytics can be efficiently developed and improved and seamlessly reproduced among multidisciplinary users in a novel cyberGIS science gateway environment. © 2018 John Wiley & Sons, Ltd.","cloud computing, computational reproducibility, CyberGIS, geospatial big data",1,0,0,1
10.1002/cpe.6080,Recommender-as-a-service with chatbot guided domain-science knowledge discovery in a science gateway,Concurrency and Computation: Practice and Experience,2021,Article,"Scientists in disciplines such as neuroscience and bioinformatics are increasingly relying on science gateways for experimentation on voluminous data, as well as analysis and visualization in multiple perspectives. Though current science gateways provide easy access to computing resources, data sets and tools specific to the disciplines, scientists often use slow and tedious manual efforts to perform knowledge discovery to accomplish their research/education tasks. Recommender systems can provide expert guidance and can help them to navigate and discover relevant publications, tools, data sets, or even automate cloud resource configurations suitable for a given scientific task. To realize the potential of integration of recommenders in science gateways in order to spur research productivity, we present a novel “OnTimeRecommend” recommender system. The OnTimeRecommend comprises of several integrated recommender modules implemented as microservices that can be augmented to a science gateway in the form of a recommender-as-a-service. The guidance for use of the recommender modules in a science gateway is aided by a chatbot plug-in viz., Vidura Advisor. To validate our OnTimeRecommend, we integrate and show benefits for both novice and expert users in domain-specific knowledge discovery within two exemplar science gateways, one in neuroscience (CyNeuro) and the other in bioinformatics (KBCommons). © 2020 John Wiley & Sons Ltd","chatbot-guided user interface, knowledge discovery, microservices, recommender system, science gateways",1,0,0,1
10.1002/cpe.6099,Measuring success for a future vision: Defining impact in science gateways/virtual research environments,Concurrency and Computation: Practice and Experience,2021,Article,"Scholars worldwide leverage science gateways/virtual research environments (VREs) for a wide variety of research and education endeavors spanning diverse scientific fields. Evaluating the value of a given science gateway/VRE to its constituent community is critical in obtaining the financial and human resources necessary to sustain operations and increase adoption in the user community. In this article, we feature a variety of exemplar science gateways/VREs and detail how they define impact in terms of, for example, their purpose, operation principles, and size of user base. Further, the exemplars recognize that their science gateways/VREs will continuously evolve with technological advancements and standards in cloud computing platforms, web service architectures, data management tools and cybersecurity. Correspondingly, we present a number of technology advances that could be incorporated in next-generation science gateways/VREs to enhance their scope and scale of their operations for greater success/impact. The exemplars are selected from owners of science gateways in the Science Gateways Community Institute (SGCI) clientele in the United States, and from the owners of VREs in the International Virtual Research Environment Interest Group (VRE-IG) of the Research Data Alliance. Thus, community-driven best practices and technology advances are compiled from diverse expert groups with an international perspective to envisage futuristic science gateway/VRE innovations. © 2020 John Wiley & Sons, Ltd.","futuristic vision, measuring impact, science gateways, success metrics, virtual research environments",1,0,1,2
10.1002/cpe.6100,The Science Library: Curation and visualization of a science gateway repository,Concurrency and Computation: Practice and Experience,2021,Article,"Scientific publications from a group or consortium often form a coherent larger body of work with underlying threads and relationships. Rich social, structural, and topical networks between authors and organizations can be identified, and to convey these we have created the publicly available “Science Library” as a user-centric, interactive portal. A key consideration in this endeavor is rapid and efficient curation of the corpus of publications, both in terms of assuring quality, as well minimizing the effort required. For this to be sustainable it must offer substantial benefits to the community and avoid excessive operational cost through cumbersome or complex processes. We describe the agility of the Science Library implementation as a controlled natural language (CNL) semantic knowledge graph and describe the different roles within the community to ensure efficient curation, validation, and provenance of the content. By describing the process of curation and validation, alongside the CNL-based definition of the model we show how relatively non-technical users are able to interact with, and contribute to the Science Library. This provides an extensible approach, initially based around digital library and virtual community capabilities, that can be applied more broadly to support other desired capabilities of Science Gateways. © 2020 IBM Research Europe. Concurrency and Computation: Practice and Experience published by John Wiley & Sons Ltd.","Controlled English, human-computer interaction, science gateways, Science Library, visualization",1,0,0,1
10.1002/cpe.6103,Tapis v3 Streams API: Time-series and data-driven event support in science gateway infrastructure,Concurrency and Computation: Practice and Experience,2021,Article,"The explosion of IoT devices and sensors in recent years has led to a demand for efficiently storing, processing and analyzing time-series data. Geoscience researchers use time-series data stores such as Hydroserver, Virtual Observatory and Ecological Informatics System (VOEIS), and Cloud-Hosted Real-time Data Service (CHORDS). Many of these tools require a great deal of infrastructure to deploy and expertise to manage and scale. The Tapis framework, an NSF funded project, provides science as a service APIs to allow researchers to achieve faster scientific results, by eliminating the need to set up a complex infrastructure stack. The University of Hawai'i (UH) and Texas Advanced Computing Center (TACC) have collaborated to develop an open source Tapis Streams API that builds on the concepts of the CHORDS time series data service to support research. This new hosted service allows storing, processing, annotating, archiving, and querying time-series data in the Tapis multi-user and multi-tenant collaborative platform. The Streams API provides a hosted production level middleware service that enables new data-driven event workflows capabilities that may be leveraged by researchers and Tapis powered science gateways for handling spatially indexed time-series datasets. © 2020 John Wiley & Sons, Ltd.","Abaco, API, CHORDS, Kapacitor, streaming data, Tapis",1,0,0,1
10.1002/cpe.6114,"Open OnDemand: State of the platform, project, and the future",Concurrency and Computation: Practice and Experience,2021,Article,"High performance computing (HPC) has led to remarkable advances in science and engineering and has become an indispensable tool for research. Unfortunately, HPC use and adoption by many researchers is often hindered by the complex way these resources are accessed. Indeed, while the web has become the dominant access mechanism for remote computing services in virtually every computing area, HPC is a notable exception. Open OnDemand is an open source project negating this trend by providing web-based access to HPC resources (https://openondemand.org). This article describes the challenges to adoption and other lessons learned over the 3-year project that may be relevant to other science gateway projects. We end with a description of future plans the project team has during the Open OnDemand 2.0 project including specific developments in machine learning and GPU monitoring. © 2020 John Wiley & Sons, Ltd.","high-performance computing, interactive, Open OnDemand, science gateways, web platform",1,0,0,1
10.1002/cpe.6130,GHub: Building a glaciology gateway to unify a community,Concurrency and Computation: Practice and Experience,2021,Article,"There is no consensus on how quickly the earth's ice sheets are melting due to global warming, nor on the ramifications to sea level rise. Due to its potential effects on coastal populations and global economies, sea level rise is a grave concern, making ice melt rates an important area of study. The ice-sheet science community consists of two groups that perform related but distinct kinds of research: a data community, and a model building community. The data community characterizes past and current states of the ice sheets by assembling data from field and satellite observations. The modeling community forecasts the rate of ice-sheet decline with computational models validated against observations. Although observational data and models depend on one another, these two groups are not well integrated. Better coordination between data collection efforts and modeling efforts is imperative if we are to improve our understanding of ice sheet loss rates. We present a new science gateway, GHub, a collaboration space for ice sheet scientists. This web-accessible gateway will host datasets and modeling workflows, and provide access to codes that enable tool building by the ice sheet science community. Using GHub, we will collect and centralize existing datasets, creating data products that more completely catalog the ice sheets of Greenland and Antarctica. We will build workflows for model validation and uncertainty quantification, extending existing ice sheet models. Finally, we will host existing community codes, enabling scientists to build new tools utilizing them. With this new cyberinfrastructure, ice sheet scientists will gain integrated tools to quantify the rate and extent of sea level rise, benefitting human societies around the globe. © 2020 John Wiley & Sons, Ltd.","community codes, datasets, high-performance computing, ice-sheet science, science gateways, tool building",1,0,0,1
10.1002/cpe.6324,Streamlining geospatial data processing for isotopic landscape modeling,Concurrency and Computation: Practice and Experience,2021,Article,"Stable isotopic landscape modeling has become a promising approach for answering research questions in multiple disciplines. However, its application has been hindered by the difficulty for individual researchers to collect, compile, and integrate environmental and isotopic data over large spatial and temporal scales and to develop and interpret geostatistical models. To address these challenges, we developed IsoMAP (http://isomap.org), a science gateway that enables researchers to access and integrate a number of disparate and diverse datasets, develop isoscape models over selected spatiotemporal domains using geostatistical algorithms, predict maps for the stable isotopic ratios, and associate a sample's isotope value with its most likely geographic origin. One main challenge in developing IsoMAP is to efficiently integrate large heterogeneous datasets into the modeling workflow to ensure real-time query response and timely data update. In this paper, we described how the geospatial data processing workflow was implemented in the initial version of gateway and how it has been improved by leveraging the built-in vector and raster data processing capabilities and the materialized view object of the PostgreSQL/PostGIS database. Our experience and lessons learned will be applicable to the development of other geospatial data workflows, a common task in the cyberinfrastructure of many science disciplines. © 2021 John Wiley & Sons, Ltd.","geospatial data processing, IsoMAP, isoscape modeling, PostGIS, science gateways",1,0,0,1
10.1002/cpe.6727,"Building a portal for climate data—Mapping automation, visualization, and dissemination",Concurrency and Computation: Practice and Experience,2021,Article,"This article discusses the technologies and implementation of a climate data portal. This portal provides researchers and community stakeholders access to climatological data and resources, currently focusing on the state of Hawai'i. The portal provides interactive access to and visualization of hosted historical and near-real-time gridded maps and aggregated sensor station observational data. Climate data (currently precipitation and temperature) from sensor stations are collected, quality controlled, and processed daily to produce high-resolution gridded maps of climate data. A publicly available web application allows users to navigate the available data and visualize the produced gridded data products and sensor stations data on an interactive map element, view information about the sensor stations used to produce a given map, and generate time series from sensor station data. The portal can also generate packages of data to export from the application. The portal is designed to host and disseminate any climatological variables that can be processed into a set of observational data and gridded value maps. The established workflow and automation procedure is generally extensible to additional variables and will be used similarly to expand the scope of the portal. © 2021 John Wiley & Sons, Ltd.","climate, hydrology, precipitation, science gateways, sustainability, Tapis",1,0,0,1
10.1002/cpe.6728,A serverless gateway for event-driven machine learning inference in multiple clouds,Concurrency and Computation: Practice and Experience,2021,Article,"Serverless computing and, in particular, the functions as a service model has become a convincing paradigm for the development and implementation of highly scalable applications in the cloud. This is due to the transparent management of three key functionalities: triggering of functions due to events, automatic provisioning and scalability of resources, and fine-grained pay-per-use. This article presents a serverless web-based scientific gateway to execute the inference phase of previously trained machine learning and artificial intelligence models. The execution of the models is performed both in Amazon Web Services and in on-premises clouds with the OSCAR framework for serverless scientific computing. In both cases, the computing infrastructure grows elastically according to the demand adopting scale-to-zero approaches to minimize costs. The web interface provides an improved user experience by simplifying the use of the models. The usage of machine learning in a computing platform that can use both on-premises clouds and public clouds constitutes a step forward in the adoption of serverless computing for scientific applications. © 2021 John Wiley & Sons, Ltd.","cloud computing, function as a service, machine learning, serverless computing",1,0,0,1
10.1002/cpe.6872,Toward a reference architecture based science gateway framework with embedded e-learning support,Concurrency and Computation: Practice and Experience,2022,Conference Paper,"Science gateways have been widely utilized by a large number of user communities to simplify access to complex distributed computing infrastructures. While science gateways are still becoming increasingly popular and the number of user communities is growing, the fast and efficient creation of new science gateways and the flexibility to deploy these gateways on-demand on heterogeneous computational resources, remain a challenge. Additionally, the increase in the number of users, especially with very different backgrounds, requires intuitive embedded e-learning tools that support all stakeholders to find related learning material and to guide the learning process. This paper introduces a novel science gateway framework that addresses these challenges. The framework supports the creation, publication, selection, and deployment of cloud-based reference architectures that can be automatically instantiated and executed even by nontechnical users. The framework also incorporates a knowledge repository exchange and learning module that provides embedded e-learning support. To demonstrate the feasibility of the proposed solution, two scientific case studies are presented based on the requirements of the plasmasphere, ionosphere, and thermosphere research communities. © 2022 The Authors. Concurrency and Computation: Practice and Experience published by John Wiley & Sons Ltd.","cloud orchestration, embedded e-learning support, microservices, reference architectures, science gateways",1,0,0,1
10.1007/978-3-030-39905-4_15,RepOSGate: Open Science Gateways for Institutional Repositories,Digital Libraries: The Era of Big Data and Data Science,2020,Conference Paper,"Most repository platforms used to operate Institutional Repositories fail at delivering a complete set of functionalities required by institutions and researchers to fully comply with Open Science publishing practices. This paper presents RepOSGate, a software that implements an overlay application capable of collecting metadata records from a repository and transparently deliver search, statistics, upload of Open Access versions functionalities over an enhanced version of the metadata collection, which include: links to datasets, Open Access versions of the artifacts, links to projects from several funders, subjects, citations, etc. The paper will also present two instantiations of RepOSGate, used to enhance the publication metadata collections of two CNR institutes: Institute of Information Science and Technologies (ISTI) and Institute of Marine Sciences (ISMAR). © 2020, Springer Nature Switzerland AG.","Institutional repository, Open Access, open science, OpenAIRE, Scholarly communication",1,0,0,1
10.1007/978-3-030-44728-1_9,Accelerating Experimental Science Using Jupyter and NERSC HPC,Tools and Techniques for High Performance Computing,2020,Conference Paper,"Large scale experimental science workflows require support for a unified, interactive, real-time platform that can manage a distributed set of resources connected to High Performance Computing (HPC) systems. What is needed is a tool that provides the ease-of-use and interactivity of a web science gateway, while providing the scientist the ability to build custom, ad-hoc workflows in a composable way. The Jupyter platform can play a key role here to enable the ingestion and analysis of real-time streaming data, integrate with HPC resources in a closed-loop, and enable interactive ad-hoc analyses with running workflows. We want to enable high-quality reproducible human-in-the-loop science using HPC and Jupyter at the National Energy Research Scientific Computing Center (NERSC). Achieving that goal is challenging in the general case because scientific workflows and data can vary significantly in size and type between disciplines. There are many areas of work to achieve highly reproducible science, let alone human-in-the-loop interactive scientific workflows, but we focus here on some basic elements for enabling an improved interactive HPC experience including creating reusable recipes and workflows with Notebooks, sharing and cloning Notebooks, and parallelization and scaling of scientific code requiring HPC and using Jupyter. © 2020, This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply.","HPC, interactive, Jupyter, Parameters, Reuse, scientific workflows",1,0,0,1
10.1007/978-3-030-50896-8_7,Augmented reality based scientific gateway as education form,Advances in Intelligent Systems and Computing,2020,Conference Paper,"A Science Gateway is a community-developed set of tools, applications, and data that are integrated via a portal or a suite of applications, usually in a graphical user interface, that is further customized to meet the needs of a specific community. Gateways enable entire communities of users associated with a common discipline to use national resources through a common interface that is configured for optimal use. Researchers can focus on their scientific goals and less on assembling the cyber infrastructure they require. Gateways can also foster collaborations and the exchange of ideas among researchers. Our paper deal with position the augmented and mixed reality tool as a one of main component the scientific gateway and portals. The scientific portals and gateways are cumulative all classes of visualization, Augment and Mixed reality. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2020.","3D visualization, augmented reality, mixed reality, Research results, scientific gateways",1,0,0,1
10.1007/978-3-030-88207-5_34,Virtual Learning Tools for Students with Delimited Ability,"Cooperative Design, Visualization, and Engineering",2021,Conference Paper,"Augmented Reality (AR) is a technology that dramatically shifts the location and timing of learning and training, while for students with limited ability it shifts the way of education and learning. This paper describes our research on augmented reality, how it applies to learning and training for students with limited ability, and the potential impact on the future of education. We developed Apps including virtual speaking head, speech synthesis, text to speech and speech to text conversion. We found out that for students with hearing impairments and for those with limited ability it is the best way of learning. Augmented reality is incredibly important as a tool of communication too, because, as a part of scientific gateway it creates a space for communities, collaboration, data sharing and visualization. It is very important for us, researchers to communicate our science to non-scientists. Our paper shows how augmented reality can serve as an important component of the virtual learning process. It enables students to take the courses and workshops online, manage course contents and downloadable resources, to validate courses and so on. In this paper, we present one of our developed tools for students, especially for those with limited ability. © 2021, Springer Nature Switzerland AG.","augmented reality, Cooperative visualization, Limited ability, Speech synthesis, Virtual speaking head",1,0,0,1
10.1007/978-3-319-10894-0_10,A framework for domain-specific science Gateways,eScience on Distributed Computing Infrastructure,2014,Article,"While modern Federated Computing Infrastructures-Grids, Clouds and other technologies-continuously increase their computing power, their use for research still stays lower than desired. The authors’ diagnosis of this problem is a technology barrier hard to overcome to people who want to focus only on science. The federated infrastructures are difficult to use not only due to the physical distribution of the resources and, thus, need for remote access, but, mainly, due to the fact that everyday patterns of interaction with a computer cannot be directly used for these resources. The way of performing computing operations on them is different than the usual way the scientists do their research using laptops or personal computers. The authors claim that the key to increase the use of modern federated infrastructures for science is making the processing on these infrastructures resemble using a personal computer. The paper collects requirements from different scientific use cases and, from these requirements, derives a processing model that could satisfy all of them, thus, allowing to build a system, in which computations on large infrastructures can be similar to everyday work. This model is implemented by a framework for creating Science Gateways-InSilicoLab. © Springer International Publishing Switzerland 2014.","Federated infrastructures, Framework, In silico, Processingmodel, science gateways",1,0,0,1
10.1007/978-3-319-10894-0_11,Easy Development and Integration of Science Gateways with Vine Toolkit,eScience on Distributed Computing Infrastructure,2014,Article,"Science Gateway is a set of tools for scientists to facilitate access to their computational resources in a comprehensive, efficient and easy manner. Themost common instance of ScienceGateway comes in the form of aweb portal. It provides space for communities, collaboration, data sharing and visualization along with the possibility of defining, running and managing computational tasks. The main objective of such a portal is to allow users to access the computational resources, to process and analyze their data and to obtain results in a uniform and user friendly way. In this publication we briefly describe solutions for Nanomechanics, Quantum Chemistry and Molecular Physics fields with the use of Vine Toolkit and QosCosGrid tools and different domain-specific applications. © Springer International Publishing Switzerland 2014.","Advance reservations, Anelli, Lammps, monitoring, NanoMD, Nanomechanics, portals, QosCosGrid, science gateways, SIMPL, Vine Toolkit, web2.0, workflows",1,0,0,1
10.1007/978-3-319-38904-2_14,An science gateway with cost adaptive resource management schemes,"Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering",2016,Conference Paper,"In order to process heavy data and computation applications such as scientific application in cloud computing environment, it is important to do an efficient resource schedule that decrease the resource usage cost while guaranteeing users’ Service Level Agreement. To resolve this issue, we propose and implement Science Gateway, which execute the scientific application efficiently on heterogeneous cloud service providers instead of users. Especially, we propose a cost-adaptive resource management schemes (i.e. VM pool management scheme that decreases the resource management cost significantly based on the long-term payment plans of cloud resource providers and VM placement management scheme that guarantee the performance of communication between VMs). Finally, we demonstrate that our proposed system improves the performance of existing cloud systems through some experimental and simulation results. © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2016.","Cloud broker, cloud computing, Scientific workflow application",1,0,0,1
10.1007/978-3-319-43696-8_6,Deployment of an E-infrastructure for academic research,e-Infrastructure and e-Services,2016,Conference Paper,"One of the greatest problems researchers in Africa face, according a 2007 UNESCO report is a chronic lack of investment in facilities for research and teaching. This has both affected the quality and quantity of research output from institutions of higher learning, with the ripple effect of stagnating industrialization and R&D processes. This paper presents the design and implementation of an e-infrastructure, which is made up of cloud and grid computing clusters domiciled in University of Nigeria Nsukka (UNN). The project has objectives, such as to deploy an Identity Provider (IdP) based on Simple Access Markup Language (SAML) that uses robot certificates to authenticate users on the cloud and grid infrastructures, deploy a Web 2.0 based Science Gateway application server that enables researchers have access to simulation, and modeling applications in their research domains on the infrastructure. As well as implement a Virtualized cluster for big data analytics. Results from one of the applications developed and deployed on the infrastructure show over 60 % predication accuracy while participation database in the infrastructure has reached up to 350 users. © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2016.","cloud computing, clusters, e-infrastructures, IdP, Robot certificates, science gateways",1,0,0,1
10.1007/978-3-642-19644-7_31,Visualization tool and its integration in a gateway for astronomy and astrophysics,Advances in Intelligent and Soft Computing,2011,Conference Paper,"Thanks to e-infrastructures, researchers can collaborate, communicate, share resources, access remote equipment or computers and produce results as effectively as if they and the resources they require were physically co-located. However, to properly achieve those results, community-oriented e-science environments are required. E-sciences ask for developing user-friendly interfaces, which sophisticated implementations are also known as science gateway. The science gateway is important component of many large-scale Earth, astronomical, environmental and natural disasters science projects. Developing the sciences portals and the science gateways is coverage of requirements of large scale sciences such as Earth science, astronomy and all sciences which are using grid, cloud or cluster computing and high-performance computing infrastructure. The paper shows the main position of visualization in Science Gateway and describes architecture of the Visualization Tool (VT), for astrophysics simulations and shows some examples. VT is integrated in the web portal, as is e-science gateway for astronomy and astrophysics. © 2011 Springer-Verlag Berlin Heidelberg.","gateways, grid, Visualization tool, web portal",1,0,0,1
10.1007/978-3-642-28267-6_16,Online web-based science Gateway for nanotechnology research,Building a National Distributed e-Infrastructure–PL-Grid,2012,Article,"The main objective of Science Gateways is to give users remote access to supercomputers and large-scale computing environments in an interactive, web-based and graphical manner. We present a tool, called Vine Toolkit, that has been successfully used as a core web platform for various Science Gateways. Vine Toolkit is a modular, extensible and easy-to-use tool as well as a high-level Application Programming Interface (API) for various applications, visualization components and building blocks. In a nutshell, it allows interoperability between many different HPC and grid technologies within the service layer. As a result, Vine Toolkit provides an ability to build a portal upon different HPC technologies working together to deliver a complete solution to the users. In this article, we briefly describe our most complex and feature-rich project - the Nanotechnology Gateway, as well as a set of tools relevant to advanced scientific portals, development of which was driven by various requirements defined by scientists and gathered in scope of the PL-Grid project. © 2012 Springer-Verlag Berlin Heidelberg.","ABINIT, Adobe Flex, Java, Liferay, material science, nanotechnology, science gateways, Vine Toolkit, web2.0",1,0,0,1
10.1007/s10723-010-9166-8,Parameter Sweep Workflows for Modelling Carbohydrate Recognition,Journal of Grid Computing,2010,Article,"Carbohydrate recognition is a phenomenon critical to a number of biological functions in humans. Understanding the dynamic behaviour of oligosaccharides should help in the discovery of the mechanisms which lead to specific and selective recognition of carbohydrates by proteins. Computer programs which can provide insight into such biological recognition processes have significant potential to contribute to biomedical research if the results of the simulation can prove consistent with the outcome of conventional wet laboratory experiments. In order to validate these simulation tools and support their wider uptake by the bio-scientist research community, high-level easy to use integrated environments are required to run massively parallel simulation workflows. This paper describes how the ProSim Science Gateway, based on the WS-PGRADE Grid portal, has been created to execute and visualise the results of complex parameter sweep workflows for modelling carbohydrate recognition. © 2010 Springer Science+Business Media B.V.","Bio-molecular simulation, grid portal, Grid workflow, science gateways",1,0,0,1
10.1007/s10723-012-9233-4,A Grid-Enabled Gateway for Biomedical Data Analysis,Journal of Grid Computing,2012,Article,"Biomedical researchers can leverage Grid computing technology to address their increasing demands for data- and compute-intensive data analysis. However, usage of existing Grid infrastructures remains difficult for them. The e-infrastructure for biomedical science (e-BioInfra) is a platform with services that shield middleware complexities, in particular workflow management and monitoring. These services can be invoked from a web-based interface, called e-BioInfra Gateway, to perform large scale data analysis experiments, such that the biomedical researchers can focus on their own research problems. The gateway was designed to simplify usage both by biomedical researchers and e-BioInfra administrators, and to support straightforward extensions with new data analysis methods. In this paper we present the architecture and implementation of the gateway, also showing statistics for its usage. We also share lessons learned during the gateway development and operation. The gateway is currently used in several biomedical research projects and in teaching medical students the principles of data analysis. © 2012 Springer Science+Business Media B.V.","Biomedical research, e-science, grid computing, Grid user interface, Grid web portal, scientific gateways",1,0,0,1
10.1007/s10723-012-9236-1,Easy Development and Integration of Science Gateways with Vine Toolkit,Journal of Grid Computing,2012,Article,"Science Gateways are web portal environments targeted for a given community and dedicated to specific scientific needs. Scientists require a different set of tools, applications, visualizations, data integration patterns, to be able to satisfy unique requirements of different research domains. To enable users to benefit from remote computational and storage resources, a web portal framework should support an easy integration and access to the e-Infrastructure. In this paper we present results of our research and development activities leading to the release of the Vine Toolkit framework integrated with Adobe Flex/BlazeDs technologies. It offers a set of unified and abstract APIs for different Grid middleware and a rich graphic presentation layer. Additionally, it automates the integration process with portal frameworks, such as Liferay or GridSphere. Vine Toolkit introduces a concept of subprojects which extend core APIs or define new low level components and web applications. This way, a Science Gateway prototyping process is definitely shortened. Consequently, it allows programmers to build software components that can be reused in a simple manner for different Science Gateways. © 2012 Springer Science+Business Media Dordrecht.","nanotechnology, portals, science gateways, Vine Toolkit",1,0,0,1
10.1007/s10723-012-9240-5,WS-PGRADE/gUSE Generic DCI Gateway Framework for a Large Variety of User Communities,Journal of Grid Computing,2012,Article,"The WS-PGRADE/gUSE generic DCI gateway framework has been developed to support a large variety of user communities. It provides a generic purpose, workflow-oriented graphical user interface to create and run workflows on various DCIs including clusters, Grids, desktop Grids and clouds. The framework can be used by NGIs to support small user communities who cannot afford to develop their own customized science gateway. The WS-PGRADE/gUSE framework also provides two API interfaces (Application Specific Module API and Remote API) to create application-specific science gateways according to the needs of different user communities. The paper describes in detail the workflow concept of WS-PGRADE, the DCI Bridge service that enables access to most of the popular European DCIs and the Application Specific Module and Remote API concepts to generate application-specific science gateways. © 2012 Springer Science+Business Media Dordrecht.","Customized interface, distributed computing infrastructures, science gateways, workflows",1,0,0,1
10.1007/s10723-012-9242-3,The DECIDE Science Gateway,Journal of Grid Computing,2012,Article,"The motivation of this work fits with the general vision to enable e-health for European citizens, irrespective of their social and financial status and their place of residence. Services to be provided include access to a high-quality early diagnostic and prognostic service for the Alzheimer Disease and other forms of dementia, based both on the European Research and Education Networks and the European Grid Infrastructure. The present paper reports on the architecture and services of a Science Gateway developed in the context of the DECIDE project, which aims to support the medical community in its daily duties of patients' examination and diagnosis. The implementation of the Science Gateway is described with particular focus on the standard technologies adopted to ease the access by non IT-. expert users. The work leverages on an authentication and authorization infrastructure based on Identity Federations and robot certificates and on the adoption of the SAGA standard for middleware-independent Grid interaction. The architecture and the functionalities of the digital repository for medical image storage and analysis are also presented. © 2012 The Author(s).","e-health service, grid computing, science gateways, Standard-based development and middleware-independent deploy",1,0,0,1
10.1007/s10723-012-9243-2,Assessing the Usability of a Science Gateway for Medical Knowledge Bases with TRENCADIS,Journal of Grid Computing,2012,Article,"Biomedical applications are often built on top of knowledge bases that contain medical images and clinical reports. Currently, these bases are being used to improve diagnosis, research and teaching, but in many cases, the infrastructure required has a prohibitive cost for many medical centres. However, resources can be attached from existing e-Science infrastructures. Therefore, many efforts have been made to establish best practices that allow the use of such infrastructures. However, e-Science relies on open, distributed, collaborative environments, built on top of very specialized technologies, such as Grid and Cloud computing, which require reasonable technical skills for their usage. Therefore, science gateways have become essential tools that assist users in interacting with e-Science applications. This paper describes TRENCADIS, a technology that supports the creation and operation of virtual knowledge bases. To this end, it provides developers with components and APIs for building secure data services that can be annotated and queried through ontology templates, based on DICOM and DICOM-SR. This technology was used in this paper to build a gateway for assisting diagnosis and research in breast cancer. We also present here the results of a study conducted to evaluate the gateway, from the point of view of the usability perceived by a group of physicians and radiologists. © 2012 Springer Science+Business Media Dordrecht.","DICOM, DICOM-SR, knowledge base, usability",1,0,0,1
10.1007/s10723-012-9244-1,Distributed Application Runtime Environment (DARE): A Standards-based Middleware Framework for Science-Gateways,Journal of Grid Computing,2012,Article,"Gateways have been able to provide efficient and simplified access to distributed and high-performance computing resources. Gateways have been shown to support many common and advanced requirements, as well as proving successful as a shared access mode to production cyberinfrastructure such as the TG/XSEDE. There are two primary challenges in the design of effective and broadly-usable gateways: the first revolves around the creation of interfaces that catpure existing and future usage modes so as to support desired scientific investigation. The second challenge and the focus of this paper, is concerned about the requirement to integrate the user-interfaces with computational resources and specialized cyberinfrastructure in an interoperable, extensible and scalable fashion. Currently, there does not exist a commonly usable middleware to that enables seamless integration of different gateways to a range of distributed and high-performance infrastructures. The development of multiple similar gateways that can work over a range of production cyberinfrastructures, usage modes and application requirements is not scalable without a effective and extensible middleware. Some of the challenges that make using production cyberinfrastructure as a collective resource difficult are also responsible for the absence of middleware that enables multiple gateways to utilize the collective capabilities. We introduce the SAGA-based, Distributed Application Runtime Environment (DARE) framework, using which gateways that seamlessly and effectively utilize scalable distributed infrastructure can be built. We discuss the architecture of DARE-based gateways, and show using several different prototypes-DARE-HTHP, DARE-NGS, how gateways can be constructed by utilizing the DARE middleware framework. © 2012 Springer Science+Business Media Dordrecht.","clouds, DARE, EGI, grids, interoperability, middleware, Pilot Jobs, SAGA, science gateways, standards, XSEDE",1,0,0,1
10.1007/s10723-012-9247-y,A Single Sign-On Infrastructure for Science Gateways on a Use Case for Structural Bioinformatics,Journal of Grid Computing,2012,Article,"Structural bioinformatics applies computational methods to analyze and model three-dimensional molecular structures. There is a huge number of applications available to work with structural data on large scale. Using these tools on distributed computing infrastructures (DCIs), however, is often complicated due to a lack of suitable interfaces. The MoSGrid (Molecular Simulation Grid) science gateway provides an intuitive user interface to several widely-used applications for structural bioinformatics, molecular modeling, and quantum chemistry. It ensures the confidentiality, integrity, and availability of data via a granular security concept, which covers all layers of the infrastructure. The security concept applies SAML (Security Assertion Markup Language) and allows trust delegation from the user interface layer across the high-level middleware layer and the Grid middleware layer down to the HPC facilities. SAML assertions had to be integrated into the MoSGrid infrastructure in several places: the workflow-enabled Grid portal WS-PGRADE (Web Services Parallel Grid Runtime and Developer Environment), the gUSE (Grid User Support Environment) DCI services, and the cloud file system XtreemFS. The presented security infrastructure allows a single sign-on process to all involved DCI components and, therefore, lowers the hurdle for users to utilize large HPC infrastructures for structural bioinformatics. © 2012 Springer Science+Business Media Dordrecht.","DCIs, science gateways, security, Single sign-on, Structural bioinformatics",1,0,0,1
10.1007/s10723-015-9330-2,An Innovative Science Gateway for the Cherenkov Telescope Array,Journal of Grid Computing,2015,Article,"The Cherenkov Telescope Array (CTA) is currently building the next generation, ground-based, very high-energy gamma-ray instrumentation. CTA is expected to collect very large datasets (in the order of petabytes) which will have to be stored, managed and processed. This paper presents a graphical user interface built inside a science gateway aiming at providing CTA-users with a common working framework. The gateway is WS-PGRADE/gUSE workflow-oriented and is equipped with a flexible SSO (based on SAML) to control user access for authentication and authorization. An interactive desktop environment is provided, called Astronomical & Physics Cloud Interactive Desktop (ACID). Users are able to exploit the graphical interface as provided natively by the tools included in ACID. A cloud data service shares and synchronizes data files and output results between the user desktop and the science gateway. Our solution is a first attempt towards an ecosystem of new technologies with a high level of flexibility to suit present and future requirements of the CTA community. © 2015, Springer Science+Business Media Dordrecht.","ACID, cloud services, CTA, gUSE, science gateways, workflows, WS-PGRADE",1,0,0,1
10.1007/s10723-016-9362-2,Metadata Management in the MoSGrid Science Gateway - Evaluation and the Expansion of Quantum Chemistry Support,Journal of Grid Computing,2017,Article,"Science gateways are employed to hide increasingly complex IT infrastructures from users via easy-to-use graphical interfaces while enabling IT-driven research not possible before. The science gateway MoSGrid (Molecular Simulation Grid) is a valuable and user-friendly workbench to submit and process molecular simulation studies on a large scale. With regard to the needs of the users, we focus on the interoperability of simulations using two prominent quantum chemical codes, Gaussian09 and NWChem. At a first glimpse, the definition of functionals and basis sets seems to be sufficient to evoke the same type of calculation in both codes using the quantum chemical workflows in MoSGrid. In more detail, this is not true and more aspects such as integration grids, convergence criteria and basis set dimensions have to be well defined in order to obtain a trustworthy comparability between quantum chemical codes. In previous work, these details have not been defined and included in the MSML (Molecular Simulation Markup Language) implementation within MoSGrid. After the investigation presented here, all these details can be integrated to extend the quantum chemical workflows in MoSGrid. Furthermore, a performance evaluation of the underlying metadata management is performed to investigate its suitability and scalability to the MSML extension. © 2016, Springer Science+Business Media Dordrecht.","metadata management, quantum chemistry, science gateways",1,0,0,1
10.1007/s10723-016-9369-8,Extending Science Gateway Frameworks to Support Big Data Applications in the Cloud,Journal of Grid Computing,2016,Article,"Cloud computing offers massive scalability and elasticity required by many scientific and commercial applications. Combining the computational and data handling capabilities of clouds with parallel processing also has the potential to tackle Big Data problems efficiently. Science gateway frameworks and workflow systems enable application developers to implement complex applications and make these available for end-users via simple graphical user interfaces. The integration of such frameworks with Big Data processing tools on the cloud opens new opportunities for application developers. This paper investigates how workflow systems and science gateways can be extended with Big Data processing capabilities. A generic approach based on infrastructure aware workflows is suggested and a proof of concept is implemented based on the WS-PGRADE/gUSE science gateway framework and its integration with the Hadoop parallel data processing solution based on the MapReduce paradigm in the cloud. The provided analysis demonstrates that the methods described to integrate Big Data processing with workflows and science gateways work well in different cloud infrastructures and application scenarios, and can be used to create massively parallel applications for scientific analysis of Big Data. © 2016, The Author(s).","big data, Hadoop, MapReduce, science gateways, workflows, WS-PGRADE",1,0,0,1
10.1007/s10723-016-9377-8,From Lesson Learned to the Refactoring of the DRIHM Science Gateway for Hydro-meteorological Research,Journal of Grid Computing,2016,Article,"A full hydro-meteorological (HM) simulation, from rainfall to impact on urban areas, is a multidisciplinary activity which consists in the execution of a workflow composed by complex and heterogeneous model engines. Moreover an extensive set of configuration parameters have to be selected consistently among the models, otherwise the simulation can fail or produce unreliable results. The DRIHM portal is a Web-based science gateway aiming to support HM researchers in designing, executing and managing HM simulations. The first version of the portal was developed during the DRIHM project using the gUSE science gateway toolkit. The lesson we learned is guiding a refactoring process that, together with a review of the most relevant technologies for the development of a science gateway, represent the focus of this paper. Beside the technological aspects, the need of a strong interplay between ICT and other domain-specific communities clearly emerged, together with coherent policies in the management of data, computational resources and software components that represent the ecosystem of a science gateways. © 2016, Springer Science+Business Media Dordrecht.","e-infrastructures, hydrometeorology, science gateways",1,0,0,1
10.1007/s10723-016-9379-6,The Essential Components of a Successful Galaxy Service,Journal of Grid Computing,2016,Article,"Driven by advances in data generation technologies and fuelled by radical reduction in costs, genomics has become a data science. Nonetheless the field of genomics has been restrained by the ability to analyse data. Science gateways, such as Galaxy, have the potential to enable bench biologists to analyse their own data without needing be familiar with the command line. Implementing a production scale Galaxy service, sufficiently well-featured and resourced to meet the needs of the end-users, is a significant undertaking and requires the consideration and combination of a number of factors to be successfully adopted by the community. In this paper, we describe the process that we undertook to implement a Galaxy service and describe what we consider to be the essential components of such a service. Our experience and insights will be of interest to those who are planning on implementing a science gateway service in a research organisation. © 2016, Springer Science+Business Media Dordrecht.","bioinformatics, Galaxy, HPC, next generation sequencing, science gateways",1,0,0,1
10.1007/s10723-016-9384-9,Development of Science Gateways Using QCG — Lessons Learned from the Deployment on Large Scale Distributed and HPC Infrastructures,Journal of Grid Computing,2016,Article,"Today, various Science Gateways created in close collaboration with scientific communities provide access to remote and distributed HPC, Grid and Cloud computing resources and large-scale storage facilities. However, as we have observed there are still many entry barriers for new users and various limitations for active scientists. In this paper we present our latest achievements and software solutions that significantly simplify the use of large scale and distributed computing. We describe several Science Gateways that have been successfully created with the help of our application tools and the QCG (Quality in Cloud and Grid) middleware, in particular Vine Toolkit, QCG-Portal and QCG-Now, and make the use of HPC, Grid and Cloud more straightforward and transparent. Additionally, we share the best practices and lessons learned after creating jointly with user communities many domain-specific Science Gateways, e.g. dedicated for physicists, medical scientists, chemists, engineers and external communities performing multi-scale simulations. As our deployed software solutions have reached recently a critical mass of active users in the PLGrid e-infrastructure in Poland, we also discuss in this paper how changing technologies, visual design and user experience could impact the way we should re-design Science Getaways or even develop new attractive tools, e.g. desktop or mobile-based applications in the future. Finally, we present information and statistics regarding the behaviour of users to help readers understand how new capabilities and functionalities may influence the growth of user interest in Science Gateways and HPC technologies. © 2016, Springer Science+Business Media Dordrecht.","clouds, grid, GUIs, high-performance computing, science gateways",1,0,0,1
10.1007/s10723-016-9385-8,Using Science Gateways for Bridging the Differences between Research Infrastructures,Journal of Grid Computing,2016,Article,"Researchers can perform large-scale analyses on diverse computing and data infrastructures such as NGIs (National Grid Infrastructures), XSEDE (Extreme Science and Engineering Discovery Environment) and PRACE (Partnership for Advanced Computing in Europe). Some are national like NGIs and XSEDE, some are international like PRACE and all of them require a more or less restrictive application process to get access to resources. Science gateways integrating diverse infrastructures provide the possibility to re-use methods independent of such underlying infrastructures and thus potentially deliver the technical prerequisite for creating reproducible science. To achieve this goal, science gateways have to be integrated seamlessly with security mechanisms and job, data as well as workflow management of the targeted resources. This paper gives an overview on general findings for porting science gateways as well as the challenges faced for porting the German MoSGrid science gateway (Molecular Simulation Grid) to exploit XSEDE and PRACE infrastructures. © 2016, Springer Science+Business Media Dordrecht.","Reproducibility, research infrastructures, security, workflows, science gateways",1,0,0,1
10.1007/s10723-016-9388-5,Enabling Workflow-Oriented Science Gateways to Access Multi-Cloud Systems,Journal of Grid Computing,2016,Article,"In this paper we present a solution to cloud-enable workflow-oriented science gateways. The integration mechanism described in the paper is a generic method that can be followed by other gateway developers. The paper describes the principles and the concrete ways to integrate science gateways with multi-cloud systems. The concrete example to demonstrate the integration principles builds on the integration of WS-PGRADE/gUSE and the CloudBroker Platform (CBP). The integration of WS-PGRADE and the CloudBroker Platform offers a complete cloud-enabled science gateway platform for a diverse set of use-cases and user communities, with the availability to use mainstream cloud middleware types and services (Amazon, IBM, OpenStack, OpenNebula). The advantage of the integrated WS-PGRADE and CloubBroker Platform system is that if a domain-specific science gateway is customized from WS-PGRADE gateway framework it immediately inherits this cloud access flexibility, i.e. the user community of that gateway can access all the cloud types enabled by the integrated system presented. © 2016, Springer Science+Business Media Dordrecht.","clouds, science gateways, workflows",1,0,0,1
10.1007/s10723-020-09515-1,A Negotiation Protocol for Fine-Grained Accountable Resource Provisioning and Sharing in e-Science,Journal of Grid Computing,2020,Article,"With the increasing demand for dynamic and customised resource provisioning for computational experiments in e-Science, solutions are required to mediate different participants’ varied demands for such resource provision. This paper presents a novel negotiation protocol based on a new collaboration model. The protocol allows e-Scientists, the manager of an e-Scientist’s collaboration, and resource providers to reach resource provisioning agreements. By considering the manager of an e-Scientist collaboration for negotiation decisions, the protocol enables fine-grained accountable resource provision on a per job basis for e-Scientist collaborations, without binding the e-Scientist collaboration to resource providers. A testbed built with the protocol is also presented, making use of a production e-Science gateway, use cases, and infrastructures. The testbed is experimentally evaluated, via designed scenarios and comparison with existing production tools. It demonstrates that the proposed negotiation protocol can facilitate accountable resource provision per job, based on resource sharing rules defined and managed by e-Scientist collaborations. © 2020, The Author(s).","e-science, Fine-grained accounting, Negotiation protocol, Resource sharing",1,0,0,1
10.1007/s10723-020-09518-y,"Design of a Flexible, User Friendly Feature Matrix Generation System and its Application on Biomedical Datasets",Journal of Grid Computing,2020,Article,"The generation of a feature matrix is the first step in conducting machine learning analyses on complex data sets such as those containing DNA, RNA or protein sequences. These matrices contain information for each object which have to be identified using complex algorithms to interrogate the data. They are normally generated by combining the results of running such algorithms across various datasets from different and distributed data sources. Thus for non-computing experts the generation of such matrices prove a barrier to employing machine learning techniques. Further since datasets are becoming larger this barrier is augmented by the limitations of the single personal computer most often used by investigators to carry out such analyses. Here we propose a user friendly system to generate feature matrices in a way that is flexible, scalable and extendable. Additionally by making use of The Berkeley Open Infrastructure for Network Computing (BOINC) software, the process can be speeded up using distributed volunteer computing possible in most institutions. The system makes use of a combination of the Grid and Cloud User Support Environment (gUSE), combined with the Web Services Parallel Grid Runtime and Developer Environment Portal (WS-PGRADE) to create workflow-based science gateways that allow users to submit work to the distributed computing. This report demonstrates the use of our proposed WS-PGRADE/gUSE BOINC system to identify features to populate matrices from very large DNA sequence data repositories, however we propose that this system could be used to analyse a wide variety of feature sets including image, numerical and text data. © 2020, The Author(s).","BOINC, desktop grid, DNA feature identification, DNA sequence, DNA sequence, Feature subset selection, gUSE, high-performance computing, machine learning, Speedup, WS-PGRADE",1,0,0,1
10.1007/s10723-020-09529-9,Building Science Gateways for Analysing Molecular Docking Results Using a Generic Framework and Methodology,Journal of Grid Computing,2020,Article,"Molecular docking and virtual screening experiments require large computational and data resources and high-level user interfaces in the form of science gateways. While science gateways supporting such experiments are relatively common, there is a clearly identified need to design and implement more complex environments for further analysis of docking results. This paper describes a generic framework and a related methodology that supports the efficient development of such environments. The framework is modular enabling the reuse of already existing components. The methodology, which proposes three techniques that the development team can use, is agile and encourages active participation of end-users. Based on the framework and methodology, two prototype implementations of science-gateway-based docking environments are presented and evaluated. The first system recommends a receptor-ligand pair for the next docking experiment, and the second filters docking results based on ligand properties. © 2020, The Author(s).","bioinformatics, cloud computing, distributed computing infrastructures, Molecular docking, science gateways, virtual screening",1,0,0,1
10.1016/j.advengsoft.2017.06.019,"A Researcher-oriented Automated Data Ingestion Tool for rapid data Processing, Visualization and Preservation",Advances in Engineering Software,2017,Article,"A select number of scientific communities have been quite successful in evolving the culture within their community to encourage publishing and to provide resources for re-using well-documented data. These data have great potential for analysis and knowledge generation beyond the purposes for which they were collected and intended. However, there are still barriers in this process. To explore this problem, we have developed a prototype tool: the Experiment Dashboard (ED), with the objective of demonstrating the ability and potential of enabling automated data ingestion from typical research laboratories. This innovative prototype was developed to create a novel system and artifact to explore the possibilities of allowing researchers in laboratories across the nation to link their data acquisition systems directly to structured data repositories for data and metadata ingestion. The prototype functions with commonly used data acquisition software at the data source and the HUBzero scientific gateway at the data sink. ED can be set up with minimal effort and expertise. In this paper, we describe the motivation and purposes for the prototype, the architecture we devised and functionality of this tool, and provide a demonstration of the tool for optical measurements in a structural engineering laboratory. The goal of this paper is to articulate and show through our prototype a vision for future cyberinfrastructure for empirical disciplines that rely on the rapid collection, analysis, and dissemination of valuable experimental data. We also discuss lessons learned that may be useful for others seeking to solve similar problems. © 2017 Elsevier Ltd","Data ingestion, experiments, HUBzero, Open-Source Data Turbine",1,0,0,1
10.1016/j.ascom.2015.01.006,An integrated visualization environment for the virtual observatory: Current status and future directions,Astronomy and Computing,2015,Article,"Visual exploration and discovery applications are invaluable tools to provide prompt and intuitive insights into the intrinsic data characteristics of modern astronomy and astrophysics datasets. Due to the massively large and highly complex datasets, various technical challenges are involved to reach, e.g. interactivity, integration, navigation and collaboration. This paper describes a number of approaches to address these challenges, and focuses on the current status of VisIVO (Visualization Interface for the Virtual Observatory) concentrating on the provided tools ranging from a desktop application to a science gateway and a mobile application. We emphasize the latest developments made in the context of past and current international European funded projects and highlight planned future developments towards further integration within the framework of the Virtual Observatory. © 2015 Elsevier B.V.","data analysis, science gateways, scientific visualization, workflows",1,0,0,1
10.1016/j.ascom.2015.02.001,Feeding an astrophysical database via distributed computing resources: The case of BaSTI,Astronomy and Computing,2015,Article,"Stellar evolution model databases, spanning a wide ranges of masses and initial chemical compositions, are nowadays a major tool to study Galactic and extragalactic stellar populations. The Bag of Stellar Tracks and Isochrones (BaSTI) database is a VO-compliant theoretical astrophysical catalogue that collects fundamental datasets involving stars formation and evolution. The creation of this database implies a large number of stellar evolutionary computations that are extremely demanding in term of computing power. Here we discuss the efforts devoted to create and update the database using Distributed Computing Infrastructures and a Science Gateway and its future developments within the framework of the Italian Virtual Observatory project. © 2015 Elsevier B.V.","science gateways, Semi-analytical code, Stellar evolution, workflows",1,0,0,1
10.1016/j.ascom.2015.02.006,VO-compliant workflows and science gateways,Astronomy and Computing,2015,Article,"Workflow and science gateway technologies have been adopted by scientific communities as a valuable tool to carry out complex experiments. They offer the possibility to perform computations for data analysis and simulations, whereas hiding details of the complex infrastructures underneath. There are many workflow management systems covering a large variety of generic services coordinating execution of workflows. In this paper we describe our experiences in creating workflows oriented science gateways based on gUSE/WS-PGRADE technology and in particular we discuss the efforts devoted to develop a VO-compliant web environment. © 2015 Elsevier B.V.","Computing infrastructure, science gateways, scientific workflows, Virtual observatory tools",1,0,0,1
10.1016/j.csi.2015.02.001,An interoperable cloud-based scientific GATEWAY for NDVI time series analysis,Computer Standards & Interfaces,2015,Article,"Processing of high-resolution time series satellite images typically requires a large amount of computational resources and time. We introduce here a scientific gateway for computing the Normalized Difference Vegetation Index (NDVI) time series data. Based on a distributed workflow using the Web Processing Service (WPS) standard, the gateway aims to be completely interoperable with other standardized tools. The availability of this gateway may help researchers to acquire knowledge of land cover changes more efficiently over very large spatial and temporal extents, which is especially important in the context of Armenia for which timely decision-making is needed. © 2015 Elsevier B.V. All rights reserved.","clouds, Geoprocessing, GRASS GIS, NDVI, PyWPS",1,0,0,1
10.1016/j.future.2010.08.006,GriF: A new collaborative framework for a web service approach to grid empowered calculations,Future Generation Computer Systems,2011,Article,"A new Collaborative Grid Framework named GriF has been developed and validated to run on the Grid by considering as a study case quantum reactive scattering codes. Its use as a tool of Science Gateways to facilitate massive calculations also with the aim of improving scientific collaboration is discussed. Accordingly, a preliminary study on how to profile the users of virtual organizations in order to pave the way to a systematic evaluation of the work carried out in the Grid and to foster its sustainability, is presented. © 2010 Elsevier Inc. All rights reserved.","collaborative environments, Grid frameworks, Grid services, Quality evaluations, Quality of users, Reactive scattering, science gateways, virtual organizations, Virtual research communities, web services",1,0,0,1
10.1016/j.future.2010.12.008,Using a private desktop grid system for accelerating drug discovery,Future Generation Computer Systems,2011,Article,"Drug design is a challenging and computationally intensive task. Chemists are often faced with handling huge amounts of data as well as with working with huge amounts of computational resources. This paper shows that using the BOINC system as a private, dedicated desktop grid a community, like the EU CancerGrid chemist community, can easily set up its own high-end infrastructure based on available and inexpensive desktop computers. The CancerGrid Computing System described in the paper can easily be adapted for the needs of other user communities having similar infrastructure requirements. © 2011 Elsevier B.V. All rights reserved.","BOINC, clouds, desktop grid, drug discovery, science gateways, service grid",1,0,0,1
10.1016/j.future.2012.03.007,Evolution of grid-based services for Diffusion Tensor Image analysis,Future Generation Computer Systems,2012,Article,"Analyzing Diffusion Tensor Image data of the human brain of large study groups is complex and demands new, sophisticated and computationally intensive pipelines that can efficiently be executed. We present our progress over the past five years in the development and porting of the DTI analysis pipeline to a grid infrastructure. Starting with simple jobs submitted from the command-line, we moved towards a workflow-based implementation and finally into the e-BioInfra Gateway, which offers a web interface for the execution of selected biomedical data analysis software on the Dutch Grid. This gateway is currently being actively used by neuroscientists and for educational purposes. © 2012 Elsevier B.V. All rights reserved.","Diffusion Tensor Imaging, e-infrastructures, e-science, grid computing, Grid front-end, Medical imaging, scientific gateways, workflows",1,0,0,1
10.1016/j.future.2017.08.038,VIALACTEA science gateway for Milky Way analysis,Future Generation Computer Systems,2019,Article,"This paper presents the latest developments on the VIALACTEA Science Gateway in the context of the FP7 VIALACTEA project. The science gateway operates as a central workbench for the VIALACTEA community in order to allow astronomers to process the new-generation surveys (from Infrared to Radio) of the Galactic Plane to build and deliver a quantitative 3D model of our Milky Way Galaxy. The final model will be used as a template for external galaxies to study star formation across the cosmic time. The adopted agile software development process allowed to fulfill the community needs in terms of required workflows and underlying resource monitoring. Scientific requirements arose during the process highlighted the needs for easy parameter setting, fully embarrassingly parallel computations and large-scale input dataset processing. Therefore the science gateway based on the WS-PGRADE/gUSE framework has been able to fulfill the requirements mainly exploiting the parameter sweep paradigm and parallel job execution of the workflow management system. Moving from development to production environment an efficient resource monitoring system has been implemented to easily analyze and debug sources of potential failures occurred during workflow computations. The results of the resource monitoring system are exploitable not only for IT experts, administrators and workflow developers but also for the end-users of the gateway. The affiliation to the STARnet Gateway Federation ensures the sustainability of the presented products after the end of the project, allowing the usage of the VIALACTEA Science Gateway to all the stakeholders, not only to the community members. © 2017 Elsevier B.V.","astrophysics, collaborative environments, DCIs, Infrastructure tests, Milky way analysis, monitoring, science gateways, workflow systems",1,0,0,1
10.1016/j.future.2017.11.033,Using Apache Airavata and EasyGateway for the creation of complex science gateway front-end,Future Generation Computer Systems,2019,Article,"The development of community-specific user interfaces of a science gateway can be a challenging task for non-IT experts. This contribution proposes an original, easy-to-use solution to tackle this issue based on EasyGateway. EasyGateway is a modern, lightweight solution for the development of science gateway able to interplay with most toolkits. In this paper we present how EasyGateway can “dress” Apache Airavata to manage experiment configurations and job submissions. We discuss the proposed approach considering a real case application represented by the Weather Research and Forecasting Model (WRF), a community model exploited by a large number of users in meteorology and climatology domains. The combined use of EasyGateway and Apache Airavata leads to an improved user experience, enhancing the model configuration phase with support in finding inconsistencies immediately, but also exploiting the possibility of accessing a potentially large set of computational resources to perform model execution. © 2017 Elsevier B.V.","apache airavata, EasyGateway, science gateways, WRF",1,0,0,1
10.1016/j.future.2017.11.034,BioClimate: A Science Gateway for Climate Change and Biodiversity research in the EUBrazilCloudConnect project,Future Generation Computer Systems,2019,Article,"Climate and biodiversity systems are closely linked across a wide range of scales. To better understand the mutual interaction between climate change and biodiversity there is a strong need for multidisciplinary skills, scientific tools, and access to a large variety of heterogeneous, often distributed, data sources. Related to that, the EUBrazilCloudConnect project provides a user-oriented research environment built on top of a federated cloud infrastructure across Europe and Brazil, to serve key needs in different scientific domains, which is validated through a set of use cases. Among them, the most data-centric one is focused on climate change and biodiversity research. As part of this use case, the BioClimate Science Gateway has been implemented to provide end-users transparent access to (i) a highly integrated user-friendly environment, (ii) a large variety of data sources, and (iii) different analytics & visualization tools to serve a large spectrum of users needs and requirements. This paper presents a complete overview of BioClimate and the related scientific environment, in particular its Science Gateway, delivered to the end-user community at the end of the project. © 2018 Elsevier B.V.","Biodiversity and climate research, science gateways, Scientific data management and analytics",1,0,0,1
10.1016/j.future.2017.12.028,A science gateway for Exploring the X-ray Transient and variable sky using EGI Federated Cloud,Future Generation Computer Systems,2019,Article,"Modern soft X-ray observatories can yield unique insights into time domain astrophysics, and a huge amount of information is stored – and largely unexploited – in data archives. Like a treasure-hunt, the EXTraS project harvested the hitherto unexplored temporal domain information buried in the serendipitous data collected by the European Photon Imaging Camera instrument onboard the ESA XMM-Newton, in 16 years of observations. All results have been released to the scientific community, together with new software analysis tools. This paper presents the architecture of the EXTraS science gateway, that has the goal to provide the software through a web based portal using the EGI Federated Cloud infrastructure. The main focus is on the light software architecture of the portal and on the technological insights for an effective use of the EGI ecosystem. © 2017 Elsevier B.V.","astrophysics, microservices, science gateways",1,0,0,1
10.1016/j.future.2018.02.004,VIDIA: A HUBzero gateway for data analytics education,Future Generation Computer Systems,2019,Article,"We describe a scientific gateway collaboration undertaken by members of the State University of New York (SUNY) system. The University at Buffalo's Center for Computational Research (CCR) partnered with SUNY College at Oneonta to offer a gateway for teaching data analytics. The result, called Virtual Infrastructure for Data Intensive Analysis (VIDIA), hosts open-source tools that have been used by more than 300 students enrolled in 18 SUNY courses. Additional tools enable researchers across the SUNY system to submit larger jobs to CCR's compute cluster; altogether, 5 SUNY campuses benefit from the resource to date. VIDIA supports data-intensive computation for teaching and research at campuses that lack access to traditional high-performance computing (HPC) resources. © 2018 Elsevier B.V.","Data analytics, science gateways, Undergraduate education",1,0,0,1
10.1016/j.future.2018.02.005,MyGeoHub—A sustainable and evolving geospatial science gateway,Future Generation Computer Systems,2019,Article,"Science gateways are an integral component of modern collaborative research. They find widespread adoption by research groups to share data, code and tools both amongst collaborators on a project and the broader community. However, not unlike research groups, gateways too, face the vagaries of research funding often resulting in a bleak outlook for their maintenance beyond the original project's conclusion. We present a sustainability model based on the HUBzero cyberinfrastructure platform that enables multiple research projects to share a single science gateway allowing for their maintenance even after the original funding source has run out. This model brings with it certain other advantages as well; general improvements to the gateway apply to all hosted projects, similar requirements across projects can often be abstracted into new general purpose capabilities for the gateway which feed back into all hosted projects. Such newly developed capabilities can also foster additional research aiding in new funding proposals that can revitalize and jumpstart hosted dormant projects. We describe a specific instance of a HUBzero science gateway, MyGeoHub, that successfully employs this sustainability model to host several geospatial research projects. We also illustrate the specific advantages of this sustainability model in the case of the MyGeoHub gateway that have led to the development of general-purpose data management and visualization software modules that have found use beyond MyGeoHub. © 2018 Elsevier B.V.","cyberinfrastructures, geospatial, science gateways, sustainability",1,0,0,1
10.1016/j.future.2018.04.009,An integrated workspace for the Cherenkov Telescope Array,Future Generation Computer Systems,2019,Article,"The Cherenkov Telescope Array (CTA) represents the next generation of ground-based gamma-ray observatories. We present a prototype workspace, developed by INAF, that aims at providing innovative solutions for the CTA community. The workspace is composed of a science gateway and an interactive desktop integrated with a federated authentication and authorization infrastructure. The workspace leverages open source technologies providing web access to a set of tools widely used by the CTA community. The workflow management system, accessed via the science gateway, allows to run applications widely used in astronomy and physics researches into distributed computing infrastructures (ranging from clusters to grids and clouds). These software packages are also available through the interactive virtual desktop environment to exploit their native graphical user interface. The implemented authentication and authorization infrastructure is composed by a Shibboleth Identity Provider and a Grouper authorization solution. The Grouper released attributes are consumed by the science gateway to authorize the access to specific web resources and the role management mechanism provides the attribute-role mapping. © 2018 Elsevier B.V.","astrophysics, Authentication and authorization, collaborative environments, DCIs, science gateways, workflow systems",1,0,0,1
10.1016/j.future.2018.06.006,The CloudSME simulation platform and its applications: A generic multi-cloud platform for developing and executing commercial cloud-based simulations,Future Generation Computer Systems,2018,Article,"Simulation is used in industry to study a large variety of problems ranging from increasing the productivity of a manufacturing system to optimising the design of a wind turbine. However, some simulation models can be computationally demanding and some simulation projects require time consuming experimentation. High performance computing infrastructures such as clusters can be used to speed up the execution of large models or multiple experiments but at a cost that is often too much for Small and Medium-sized Enterprises (SMEs). Cloud computing presents an attractive, lower cost alternative. However, developing a cloud-based simulation application can again be costly for an SME due to training and development needs, especially if software vendors need to use resources of different heterogeneous clouds to avoid being locked-in to one particular cloud provider. In an attempt to reduce the cost of development of commercial cloud-based simulations, the CloudSME Simulation Platform (CSSP) has been developed as a generic approach that combines an AppCenter with the workflow of the WS-PGRADE/gUSE science gateway framework and the multi-cloud-based capabilities of the CloudBroker Platform. The paper presents the CSSP and two representative case studies from distinctly different areas that illustrate how commercial multi-cloud-based simulations can be created. © 2018 The Authors","Agent-based simulation, cloud computing, Computational fluid dynamics, Multi-cloud simulation, workflows",1,0,0,1
10.1016/j.future.2018.10.035,The gCube system: Delivering Virtual Research Environments as-a-Service,Future Generation Computer Systems,2019,Article,"Important changes have characterised research and knowledge production in recent decades. These changes are associated with developments in information technologies and infrastructures. The processes characterising research and knowledge production are changing through the digitalisation of science, the virtualisation of research communities and networks, the offering of underlying systems and services by infrastructures. This paper gives an overview of gCube, a software system promoting elastic and seamless access to research assets (data, services, computing) across the boundaries of institutions, disciplines and providers to favour collaboration-oriented research tasks. gCube's technology is primarily conceived to enable Hybrid Data Infrastructures facilitating the dynamic definition and operation of Virtual Research Environments. To this end, it offers a comprehensive set of data management commodities on various types of data and a rich array of “mediators” to interface well-established Infrastructures and Information Systems from various domains. Its effectiveness has been proved by operating the D4Science.org infrastructure and serving concrete, multidisciplinary, challenging, and large scale scenarios. © 2018 Elsevier B.V.","science gateways, social networking, virtual research environments",1,0,1,2
10.1016/j.future.2018.12.026,"The global impact of science gateways, virtual research environments and virtual laboratories",Future Generation Computer Systems,2019,Article,"Science gateways, virtual laboratories and virtual research environments are all terms used to refer to community-developed digital environments that are designed to meet a set of needs for a research community. Specifically, they refer to integrated access to research community resources including software, data, collaboration tools, workflows, instrumentation and high-performance computing, usually via Web and mobile applications. Science gateways, virtual laboratories and virtual research environments are enabling significant contributions to many research domains, facilitating more efficient, open, reproducible research in bold new ways. This paper explores the global impact achieved by the sum effects of these programs in increasing research impact, demonstrates their value in the broader digital landscape and discusses future opportunities. This is evidenced through examination of national and international programs in this field. © 2019 Elsevier B.V.","cyberinfrastructures, e-infrastructures, open science, science gateways, virtual laboratories, virtual research environments",1,1,1,3
10.1016/j.future.2019.04.011,I-TASSER gateway: A protein structure and function prediction server powered by XSEDE,Future Generation Computer Systems,2019,Article,"There is an increasing gap between the number of known protein sequences and the number of proteins with experimentally characterized structure and function. To alleviate this issue, we have developed the I-TASSER gateway, an online server for automated and reliable protein structure and function prediction. For a given sequence, I-TASSER starts with template recognition from a known structure library, followed by full-length atomic model construction by iterative assembly simulations of the continuous structural fragments excised from the template alignments. Functional insights are then derived from comparative matching of the predicted model with a library of proteins with known function. The I-TASSER pipeline has been recently integrated with the XSEDE Gateway system to accommodate pressing demand from the user community and increasing computing costs. This report summarizes the configuration of the I-TASSER Gateway with the XSEDE-Comet supercomputer cluster, together with an overview of the I-TASSER method and milestones of its development. © 2019 Elsevier B.V.","I-TASSER web-server, Protein structure prediction, Structure-based protein function annotation, XSEDE science gateway",1,0,0,1
10.1016/j.future.2019.05.082,REMEDI central — expanding and sustaining a medical device community,Future Generation Computer Systems,2019,Article,"The Regenstrief Center for Healthcare Engineering (RCHE), an interdisciplinary research center located at Purdue University, facilitated the development of a science community for medical device informatics, known as Regenstrief National Center for Medical Device Informatics (REMEDI). The community uses an online science gateway called REMEDI Central for a variety of data analytic and collaboration activities. Formed in 2009, REMEDI is an evidence-based community of practice, initially focused on smart pump technology and infusion therapy safety. REMEDI is a virtual community of pharmacists, nurses, other clinicians, infusion pump vendors, researchers, and national organizations such as the American Association of Medical Instrumentation (AAMI) and the American Society of Health-System Pharmacists (ASHP). In 2017, in response to a need identified by AAMI, REMEDI expanded its scope to include new applications, databases, and community engagement spaces for respiratory therapists, nurses, and ventilator vendors. In 2018, the REMEDI project started analyzing new sustainable funding models with a funding model implemented in 2019. In this paper, we reflect on the virtual community's growth and the successful implementation of a sustainable business model, which is an approach other science gateways might consider. © 2019","CatalyzeCare, Evidence-based community, HUBzero, Patient safety, REMEDI Central, science gateways",1,0,0,1
10.1016/j.future.2019.10.011,The ICTBioMed NCIP Hub: Cancer research in a science gateway consortium,Future Generation Computer Systems,2020,Article,"ICTBioMed, the International Consortium for Technology in Biomedicine is a consortium for biomedical collaborative research and the consortium partners believe in decentralization and democratization of science. The consortium works on strategies to develop ready-to-use research initiatives bridging the gap between research, implementation and ready-to-use science. The consortium has identified real science use cases with the help of the collaborative partners to get access of shared data and methods using the principles of science gateways. ICTBioMed has set up an NCIP Hub instance based upon the HUBzero framework and started using it for community research activities. It is an environment for scientific collaboration where researchers can access and take advantage of a variety of resources shared by others. The NCIP Hub supports members with shared access to data, tools, and standards across the cancer research community. Cancer researchers, in principle, have access to a wide range of data and software tools but in practice, however, they make limited use of these resources. Barriers that restrict access include the need to install software locally, inconsistent user interfaces, security concerns and poor documentation. ICTBioMed is developing a cancer science gateway that will greatly simplify analysis in cancer imaging research by offering a single point of entry and a unified interface for multiple tools, databases, and image repositories widely used by the community. The consortium aims at borderless research with a common goal to solve real life biomedical problems by facilitating collaborative research. © 2019 Elsevier B.V.","Biomedicine, cancer research, clouds, HUBzero, ICTBioMed, NCIP Hub",1,0,0,1
10.1016/j.future.2019.10.029,The Social Media Macroscope: A science gateway for research using social media data,Future Generation Computer Systems,2020,Article,"In recent years, the explosion of social media platforms and the public collection of social data has brought forth a growing desire and need for research capabilities in the realm of social media and social data analytics. Research on this scale, however, requires a high level of computational and data-science expertise, limiting the researchers who are capable of undertaking social media data-driven research to those with significant computational expertise or those who have access to such experts as part of their research team. The Social Media Macroscope (SMM) is a science gateway with the goal of removing that limitation and making social media data, analytics, and visualization tools accessible to researchers and students of all levels of expertise. The SMM provides a single point of access to a suite of intuitive web interfaces for performing social media data collection, analysis, and visualization via for open-source and commercial tools. Within the SMM social scientists are able to process and store large datasets and collaborate with other researchers by sharing ideas, data, and methods. This document functions as a brief primer on the initial build of the SMM and we end this paper discussing future directions for the SMM. © 2019","cloud computing, Research computing infrastructure, science gateways, Social media analytics",1,0,0,1
10.1016/j.future.2019.10.030,A citizen science exploration of the X-ray transient sky using the EXTraS science gateway,Future Generation Computer Systems,2020,Article,"Modern soft X-ray observatories can yield unique insights into time domain astrophysics, and a huge amount of information is stored – and largely unexploited – in data archives. Like a treasure-hunt, the EXTraS project harvested the hitherto unexplored temporal domain information buried in the serendipitous data collected by the European Photon Imaging Camera instrument onboard the XMM-Newton satellite in 20 years of observations. The result is a vast catalogue, describing the temporal behaviour of hundreds of thousands of X-ray sources. But the catalogue is just a starting point because it has to be, in its turn, further analysed. During the project an education activity has been defined and run in several workshops for high school students in Italy, Germany and UK. The final goal is to engage the students, and in perspective citizen scientists, to go through the whole validation process: they look into the data and try to discover new sources, or to characterize already known sources. This paper describes how the EXTraS science gateway is used to accomplish these tasks and highlights the first discovery, a flaring X-ray source in the globular cluster NGC 6540. © 2019","astrophysics, citizen science, science gateways, virtual observatory, X-ray astronomy",1,0,0,1
10.1016/j.future.2020.01.030,BioinfoPortal: A scientific gateway for integrating bioinformatics applications on the Brazilian national high-performance computing network,Future Generation Computer Systems,2020,Article,"Science gateways have gained increasing attention in the last years from diverse communities. Science gateways are software solutions that bring out the integration of reusable data and specialized techniques via Web servers while hiding the complexity of the underlying high-performance computing resources. Several projects and initiatives have been started worldwide to develop frameworks that support the broad range of key scientific domains. Biological sciences are undergoing a revolution since novel technologies, such as next-generation sequencing, allow data generation in exascale dimensions. Bioinformatics covers a wide range of important applications in health, diversity, and life sciences with the understanding of the high-performance computing culture to accelerate the transition of computational simulations of biological systems at all scales. The article introduces the BioinfoPortal gateway, its architecture, functionalities, and the integration to the CSGrid middleware used to manage the high-performance computing environment of the Brazilian National High-Performance Computing System, SINAPAD, including the Santos Dumont supercomputer. We present a discussion about the challenges of integrating BioinfoPortal and CSGrid framework, which considers the general process of the installation, configuration, and deployment. Finally, we present the findings of the performance analysis of high-performance computing applications, presenting how machine learning was applied to optimize the functionality of BioinfoPortal based on recommending predictive models for the efficient allocation of resources obtained over 75% of performance efficiency. © 2020 Elsevier B.V.","bioinformatics, Computational complexity, data analysis, high-performance computing, science gateways",1,0,0,1
10.1016/j.imu.2018.06.005,Medical Image Processor and Repository – MIPAR,Informatics in Medicine Unlocked,2018,Article,"Background and Objectives: The recent progress in medical image analysis has given birth to image-guided therapy, virtual reality and augmented reality. These among other innovations have greatly improved healthcare delivery, improved quality of life and also saved lives. The advances in Internet and network technology have produced web technologies which make it possible to offer platform or software as a service via the web, making it possible for end users to access computer resources or specialized computer tools remotely. However, the high cost of image acquisition, the limited availability of medical image analysts, and the limited collaborative efforts between medical experts and scientists are major challenges for medical image analysis in the developing world. The aim of this project was to develop a medical image e-infrastructure called Medical Image Processor and Analysis (MIPAR) to contain a repository of medical images acquired from Africa and a platform for processing medical images. Methods: The backend of MIPAR which is resident on a High-Performance Computing infrastructure was built using FutureGateway, a framework for building science gateway. The image upload and download module was built upon the framework of Open Access Repository with the front end developed using HTML, CSS and BootStrap. JavaScript and JQuery were used for scripting. User's access to the server is controlled with HTTP response and a Client-Server Architecture, while the image processing tools on the server side communicate with PHP using Representational State Architecture (REST) API. Results: MIPAR was tested using brain MRI images. Images were submitted remotely via MIPAR's web interface and kept in the repository. Image processing facility of MIPAR was tested using the brain extraction module, a 3D image of approximately 43MB was successfully brain extracted within 60 s. Conclusion: MIPAR allows users to donate, download and process medical images at no cost. It is our hope that such useful and unique tool will encourage collaboration, improve diagnosis, improve patient management, and promote open science in Africa. © 2018","e-infrastructures, Image analysis, Medical image, open source, repository",1,0,0,1
10.1016/j.jocs.2014.01.005,E-science infrastructures for molecular modeling and parametrization,Journal of Computational Science,2014,Article,"E-science infrastructures are becoming the essential tools for computational scientific research. In this paper, we describe two e-science infrastructures: Science and Engineering Applications Grid (SEAGrid) and molecular modeling and parametrization (ParamChem). The SEAGrid is a virtual organization with a diverse set of hardware and software resources and provides services to access such resources in a routine and transparent manner. These essential services include allocations of computational resources, client-side application interfaces, computational job and data management tools, and consulting activities. ParamChem is another e-science project dedicated for molecular force-field parametrization based on both ab-initio and molecular mechanics calculations on high performance computers (HPCs) driven by scientific workflow middleware services. Both the projects share a similar three-tier computational infrastructure that consists of a front-end client, a middleware web services layer, and a remote HPC computational layer. The client is a Java Swing desktop application with components for pre- and post-data processing, communications with middleware server and local data management. The middleware service is based on Axis2 web service and MySQL relational database, which provides functionalities for user authentication and session control, HPC resource information collections, discovery and matching, job information logging and notification. It can also be integrated with scientific workflow to manage computations on HPC resources. The grid credentials for accessing HPCs are delegated through MyProxy infrastructure. Currently SEAGrid has integrated several popular application software suites such as Gaussian for quantum chemistry, NAMD for molecular dynamics and engineering software such as Abacus for mechanical engineering. ParamChem has integrated CGenFF (CHARMM General Force-Field) for molecular force-field parametrization of drug-like molecules. Long-term storage of user data is handled by tertiary data archival mechanisms. SEAGrid science gateway serves more than 500 users while more than 1000 users use ParamChem services such as atom typing and initial force-field parameter guess at present. © 2014 Elsevier B.V.","computational chemistry, cyberinfrastructures, e-science, GridChem, Molecular modeling, Science and engineering simulation and design, science gateways, scientific workflows, virtual organizations, XSEDE",1,0,0,1
10.1016/j.jsb.2015.02.003,CapsidMaps: Protein-protein interaction pattern discovery platform for the structural analysis of virus capsids using Google Maps,Journal of Structural Biology,2015,Article,"Structural analysis and visualization of protein-protein interactions is a challenging task since it is difficult to appreciate easily the extent of all contacts made by the residues forming the interfaces. In the case of viruses, structural analysis becomes even more demanding because several interfaces coexist and, in most cases, these are formed by hundreds of contacting residues that belong to multiple interacting coat proteins. CapsidMaps is an interactive analysis and visualization tool that is designed to benefit the structural virology community. Developed as an improved extension of the ϕ-. ψ Explorer, here we describe the details of its design and implementation. We present results of analysis of a spherical virus to showcase the features and utility of the new tool. CapsidMaps also facilitates the comparison of quaternary interactions between two spherical virus particles by computing a similarity (. S)-score. The tool can also be used to identify residues that are solvent exposed and in the process of locating antigenic epitope regions as well as residues forming the inside surface of the capsid that interact with the nucleic acid genome. CapsidMaps is part of the VIPERdb Science Gateway, and is freely available as a web-based and cross-browser compliant application at http://viperdb.scripps.edu. © 2015 Elsevier Inc.","Heat maps, Quaternary interactions, Similarity score, Viral capsids, web interfaces",1,0,0,1
10.1016/j.mcm.2012.11.024,Optical TCAD on the Net: A tight-binding study of inter-band light transitions in self-assembled InAs/GaAs quantum dot photodetectors,Mathematical and Computer Modelling,2013,Article,"A new capability of our well-known NEMO 3-D simulator (Ref. Klimeck et al., 2007[10]) is introduced by carefully investigating the utility of III-V semiconductor quantum dots as infrared photodetectors at a wavelength of 1.2-1.5 μm. We not only present a detailed description of the simulation methodology coupled to the atomistic sp3d5s* tight-binding band model, but also validate the suggested methodology with a focus on a proof of principle on small GaAs quantum dots (QDs). Then, we move the simulation scope to optical properties of realistically sized dome-shaped InAs/GaAs QDs that are grown by self-assembly and typically contain a few million atoms. Performing numerical experiments with a variation in QD size, we not only show that the strength of ground state inter-band light transitions can be optimized via QD size-engineering, but also find that the hole ground state wavefunction serves as a control factor of transition strengths. Finally, we briefly introduce the web-based cyber infrastructure that is developed as a government-funded project to support online education and research via TCAD simulations. This work not only serves as a useful guideline to experimentalists for potential device designs and other modelers for the self-development of optical TCAD, but also provides a good chance to learn about the science gateway project ongoing in the Republic of Korea. © 2012 Elsevier Ltd.","Atomistic modeling, III-V photodetector, Optoelectronics, Parallel computing, science gateways, Tight-binding",1,0,0,1
10.1016/j.procs.2014.05.213,The workways problem solving environment,Procedia Computer Science,2014,Conference Paper,"Science gateways allow computational scientists to interact with a complex mix of mathematical models, software tools and techniques, and high performance computers. Accordingly, various groups have built high-level problem-solving environments that allow these to be mixed freely. In this paper, we introduce an interactive workflow-based science gateway, called WorkWays. WorkWays integrates different domain specific tools, and at the same time is flexible enough to support user input, so that users can monitor and steer simulations as they execute. A benchmark design experiment is used to demonstrate WorkWays. © The Authors. Published by Elsevier B.V.","Computational steering, interactive workflow-based science gateways, science gateways, scientific workflows",1,0,0,1
10.1016/j.procs.2016.05.535,Community science exemplars in seagrid science gateway: Apache airavata based implementation of advanced infrastructure,Procedia Computer Science,2016,Conference Paper,"We describe the science discovered by some of the community of researchers using the SEAGrid Science gateway. Specific science projects to be discussed include calcium carbonate and bicarbonate hydrochemistry, mechanistic studies of redox proteins and diffraction modeling of metal and metal-oxide structures and interfaces. The modeling studies involve a variety of ab initio and molecular dynamics computational techniques and coupled execution of a workflows using specific set of applications enabled in the SEAGrid Science Gateway. The integration of applications and resources that enable workflows that couple empirical, semi-empirical, ab initio DFT, and Moller-Plesset perturbative models and combine computational and visualization modules through a single point of access is now possible through the SEAGrid gateway. Integration with the Apache Airavata infrastructure to gain a sustainable and more easily maintainable set of services is described. As part of this integration we also provide a web browser based SEAGrid Portal in addition to the SEAGrid rich client based on the previous GridChem client. We will elaborate the services and their enhancements in this process to exemplify how the new implementation will enhance the maintainability and sustainability. We will also provide exemplar science workflows and contrast how they are supported in the new deployment to showcase the adoptability and user support for services and resources. © The Authors. Published by Elsevier B.V.","apache airavata, Community Infrastructure, computational chemistry, cyberinfrastructures, SEAgrid Science Gateway, workflows",1,0,0,1
10.1021/ct500159h,The MoSGrid science gateway - A complete solution for molecular simulations,J. Chem. Theory Comput.,2014,Article,"The MoSGrid portal offers an approach to carry out high-quality molecular simulations on distributed compute infrastructures to scientists with all kinds of background and experience levels. A user-friendly Web interface guarantees the ease-of-use of modern chemical simulation applications well established in the field. The usage of well-defined workflows annotated with metadata largely improves the reproducibility of simulations in the sense of good lab practice. The MoSGrid science gateway supports applications in the domains quantum chemistry (QC), molecular dynamics (MD), and docking. This paper presents the open-source MoSGrid architecture as well as lessons learned from its design. © 2014 American Chemical Society.","Physical and Theoretical Chemistry, computer science applications, data science, workflows, distributed computing, metadata, computer science, user interfaces, science gateways",1,0,0,1
10.1038/s41598-020-69101-z,STAGdb: a 30K SNP genotyping array and Science Gateway for Acropora corals and their dinoflagellate symbionts,Scientific Reports,2020,Article,"Standardized identification of genotypes is necessary in animals that reproduce asexually and form large clonal populations such as coral. We developed a high-resolution hybridization-based genotype array coupled with an analysis workflow and database for the most speciose genus of coral, Acropora, and their symbionts. We designed the array to co-analyze host and symbionts based on bi-allelic single nucleotide polymorphisms (SNP) markers identified from genomic data of the two Caribbean Acropora species as well as their dominant dinoflagellate symbiont, Symbiodinium ‘fitti’. SNPs were selected to resolve multi-locus genotypes of host (called genets) and symbionts (called strains), distinguish host populations and determine ancestry of coral hybrids between Caribbean acroporids. Pacific acroporids can also be genotyped using a subset of the SNP loci and additional markers enable the detection of symbionts belonging to the genera Breviolum, Cladocopium, and Durusdinium. Analytic tools to produce multi-locus genotypes of hosts based on these SNP markers were combined in a workflow called the Standard Tools for Acroporid Genotyping (STAG). The STAG workflow and database are contained within a customized Galaxy environment (https://coralsnp.science.psu.edu/galaxy/), which allows for consistent identification of host genet and symbiont strains and serves as a template for the development of arrays for additional coral genera. STAG data can be used to track temporal and spatial changes of sampled genets necessary for restoration planning and can be applied to downstream genomic analyses. Using STAG, we uncover bi-directional hybridization between and population structure within Caribbean acroporids and detect a cryptic Acroporid species in the Pacific. © 2020, The Author(s).","Multidisciplinary, Article, bioinformatics, Genetic databases, data processing, Marine biology, Conservation biology, Ecological genetics, Restoration ecology, Acropora, biology.organism_classification, biology, SNP, Evolutionary biology, SNP genotyping, Genotype, Genotyping, Host (biology), Symbiodinium, Dinoflagellate, lcsh:Medicine, lcsh:R, lcsh:Science, lcsh:Q",1,0,0,1
10.1051/0004-6361/202039783,The EXTraS project: Exploring the X-ray transient and variable sky,Astronomy and Astrophysics,2021,Article,"Temporal variability in flux and spectral shape is ubiquitous in the X-ray sky and carries crucial information about the nature and emission physics of the sources. The EPIC instrument on board the XMM-Newton observatory is the most powerful tool for studying variability even in faint sources. Each day, it collects a large amount of information about hundreds of new serendipitous sources, but the resulting huge (and growing) dataset is largely unexplored in the time domain. The project called Exploring the X-ray transient and variable sky (EXTraS) systematically extracted all temporal domain information in the XMM-Newton archive. This included a search and characterisation of variability, both periodic and aperiodic, in hundreds of thousands of sources spanning more than eight orders of magnitude in timescale and six orders of magnitude in flux, and a search for fast transients that were missed by standard image analysis. All results, products, and software tools have been released to the community in a public archive. A science gateway has also been implemented to allow users to run the EXTraS analysis remotely on recent XMM datasets. We give details on the new algorithms that were designed and implemented to perform all steps of EPIC data analysis, including data preparation, source and background modelling, generation of time series and power spectra, and search for and characterisation of different types of variabilities. We describe our results and products and give information about their basic statistical properties and advice on their usage. We also describe available online resources. The EXTraS database of results and its ancillary products is a rich resource for any kind of investigation in almost all fields of astrophysics. Algorithms and lessons learnt from our project are also a very useful reference for any current and future experiment in the time domain. © 2021 ESO.","Astronomical databases: miscellaneous, Catalogs, Methods: data analysis, X-rays: general",1,0,0,1
10.1088/1742-6596/251/1/012097,Neutron Science TeraGrid Gateway,Journal of Physics: Conference Series,2010,Conference Paper,"The unique contributions of the Neutron Science TeraGrid Gateway (NSTG) are the connection of national user facility instrument data sources to the integrated cyberinfrastructure of the National Science FoundationTeraGrid and the development of a neutron science gateway that allows neutron scientists to use TeraGrid resources to analyze their data, including comparison of experiment with simulation. The NSTG is working in close collaboration with the Spallation Neutron Source (SNS) at Oak Ridge as their principal facility partner. The SNS is a next-generation neutron source. It has completed construction at a cost of $1.4 billion and is ramping up operations. The SNS will provide an order of magnitude greater flux than any previous facility in the world and will be available to all of the nation's scientists, independent of funding source, on a peer-reviewed merit basis. With this new capability, the neutron science community is facing orders of magnitude larger data sets and is at a critical point for data analysis and simulation. There is a recognized need for new ways to manage and analyze data to optimize both beam time and scientific output. The TeraGrid is providing new capabilities in the gateway for simulations using McStas and a fitting service on distributed TeraGrid resources to improved turnaround. NSTG staff are also exploring replicating experimental data in archival storage. As part of the SNS partnership, the NSTG provides access to gateway support, cyberinfrastructure outreach, community development, and user support for the neutron science community. This community includes not only SNS staff and users but extends to all the major worldwide neutron scattering centers. © 2010 IOP Publishing Ltd.","computer science applications, history, education, cyberinfrastructures, TeraGrid, engineering, business.industry, business, Gateway (computer program), Systems engineering, Outreach, Neutron source, Spallation Neutron Source, Operations research, Neutron scattering, Service (systems architecture)",1,0,0,1
10.1088/1755-1315/509/1/012043,Unidata Science Gateway for Enabling Science as a Service to Facilitate Open Science and Reproducible Research,IOP Conference Series: Earth and Environmental Science,2020,Conference Paper,"Unidata, an NSF-funded geoscience cyberinfrastructure facility, has deployed data infrastructure and data-proximate scientific workflows and analysis tools, using cloud computing technologies, for analyzing and visualizing well-documented datasets that combine robust access to well-documented datasets. Docker containers and Jupyter notebooks, and other analytic methods are enabled via ""Software as a Service"" and ""Data as a Service"". The collective impact of these services is to enable scientists to not only conduct their research but also share their work with other researchers. © 2020 Published under licence by IOP Publishing Ltd.","science gateways, open science, World Wide Web, computer science, Service (business)",1,0,0,1
10.1109/BIBM49941.2020.9313097,A Formative Usability Study to Improve Prescriptive Systems for Bioinformatics Big Data,IEEE International Conference on Bioinformatics and Biomedicine,2020,Conference Paper,"Big data computation tools are vital for researchers and educators from various domains such as plant science, animal science, biomedical science and others. With the growing computational complexity of biology big data, advanced analytic systems, known as prescriptive systems, are being built using machine learning models to intelligently predict optimum computation solutions for users for better data analysis. However, lack of user-friendly prescriptive systems poses a critical roadblock to facilitating informed decision-making by users. In this paper, we detail a formative usability study to address the complexities faced by users while using prescriptive systems. Our usability research approach considers bioinformatics workflows and community cloud resources in the KBCommons framework's science gateway. The results show that recommendations from usability studies performed in iterations during the development of prescriptive systems can improve user experience, user satisfaction and help novice as well as expert users to make decisions in a well-informed manner. © 2020 IEEE.","big data, bioinformatics, Cloud solution, Prescriptive analytics, usability, User experience",1,0,0,1
10.1109/eScience.2012.6404425,An integrated science portal for collaborative compute and data intensive protein structure studies,International Conference on e-Science,2012,Conference Paper,"The SBGrid Science Portal provides multi-modal access to computational infrastructure, data storage, and data analysis tools for the structural biology community. It incorporates features not previously seen in cyberinfrastructure science gateways. It enables researchers to securely share a computational study area, including large volumes of data and active computational workflows. A rich identity management system has been developed that simplifies federated access to US national cyberinfrastructure, distributed data storage, and high performance file transfer tools. It integrates components from the Virtual Data Toolkit, Condor, glideinWMS, the Globus Toolkit and Globus Online, the FreeIPA identity management system, Apache web server, and the Django web framework. ©2012 IEEE.","data management, Digital collaboration, Federated identity management, grid computing, science portal",1,0,0,1
10.1109/eScience.2015.38,VERCE delivers a productive e-science environment for seismology research,International Conference on e-Science,2015,Conference Paper,"The VERCE project has pioneered an e-Infrastructure to support researchers using established simulation codes on high-performance computers in conjunction with multiple sources of observational data. This is accessed and organised via the VERCE science gateway that makes it convenient for seismologists to use these resources from any location via the Internet. Their data handling is made flexible and scalable by two Python libraries, ObsPy and dispel4py and by data services delivered by ORFEUS and EUDAT. Provenance driven tools enable rapid exploration of results and of the relationships between data, which accelerates understanding and method improvement. These powerful facilities are integrated and draw on many other e-Infrastructures. This paper presents the motivation for building such systems, it reviews how solid-Earth scientists can make significant research progress using them and explains the architecture and mechanisms that make their construction and operation achievable. We conclude with a summary of the achievements to date and identify the crucial steps needed to extend the capabilities for seismologists, for solid-Earth scientists and for similar disciplines. © 2015 IEEE.","data science, Data-intensive, e-infrastructures, HPC, metadata and storage, science gateways, Solid-earth sciences, virtual research environments",1,0,1,2
10.1109/IWSG.2014.7,Data avenue: Remote storage resource management in WS-PGRADE/gUSE,International Workshop on Science Gateways,2014,Conference Paper,"State-of-the-art gateways are connected to several distributed computing infrastructures (DCIs) and are able to run jobs and workflows simultaneously in all those different DCIs. However, the flexibility of accessing data storages belonging to different DCIs is a missing feature of current gateways. SZTAKI (Institute for Computer Science and Control) has developed a Data Avenue Blacktop service and aLiferay-based Data Avenue port let that open the door for integrating such features into science gateways. The paper explains the design considerations of the Data Avenue Blacktop service and its usage scenarios in science gateways through the Data Avenue port let. © 2014 IEEE.","data handling, data storage systems, data transfer, grid computing",1,0,0,1
10.1109/TVCG.2017.2744479,BASTet: Shareable and Reproducible Analysis and Visualization of Mass Spectrometry Imaging Data via OpenMSI,IEEE Transactions on Visualization and Computer Graphics,2018,Article,"Mass spectrometry imaging (MSI) is a transformative imaging method that supports the untargeted, quantitative measurement of the chemical composition and spatial heterogeneity of complex samples with broad applications in life sciences, bioenergy, and health. While MSI data can be routinely collected, its broad application is currently limited by the lack of easily accessible analysis methods that can process data of the size, volume, diversity, and complexity generated by MSI experiments. The development and application of cutting-edge analytical methods is a core driver in MSI research for new scientific discoveries, medical diagnostics, and commercial-innovation. However, the lack of means to share, apply, and reproduce analyses hinders the broad application, validation, and use of novel MSI analysis methods. To address this central challenge, we introduce the Berkeley Analysis and Storage Toolkit (BASTet), a novel framework for shareable and reproducible data analysis that supports standardized data and analysis interfaces, integrated data storage, data provenance, workflow management, and a broad set of integrated tools. Based on BASTet, we describe the extension of the OpenMSI mass spectrometry imaging science gateway to enable web-based sharing, reuse, analysis, and visualization of data analyses and derived data products. We demonstrate the application of BASTet and OpenMSI in practice to identify and compare characteristic substructures in the mouse brain based on their chemical composition measured via MSI. © 1995-2012 IEEE.","Analysis Workflows, data management, data provenance, data sharing, Mass spectrometry imaging, visualization",1,0,0,1
10.1117/12.2056763,Integrating the ODI-PPA scientific gateway with the QuickReduce pipeline for on-demand processing,Proceedings of SPIE - The International Society for Optical Engineering,2014,Conference Paper,"As imaging systems improve, the size of astronomical data has continued to grow, making the transfer and processing of data a significant burden. To solve this problem for the WIYN Observatory One Degree Imager (ODI), we developed the ODI-Portal, Pipeline, and Archive (ODI-PPA) science gateway, integrating the data archive, data reduction pipelines, and a user portal. In this paper, we discuss the integration of the QuickReduce (QR) pipeline into PPA's Tier 2 processing framework. QR is a set of parallelized, stand-alone Python routines accessible to all users, and operators who can create master calibration products and produce standardized calibrated data, with a short turn-around time. Upon completion, the data are ingested into the archive and portal, and made available to authorized users. Quality metrics and diagnostic plots are generated and presented via the portal for operator approval and user perusal. Additionally, users can tailor the calibration process to their specific science objective(s) by selecting custom datasets, applying preferred master calibrations or generating their own, and selecting pipeline options. Submission of a QuickReduce job initiates data staging, pipeline execution, and ingestion of output data products all while allowing the user to monitor the process status, and to download or further process/analyze the output within the portal. User-generated data products are placed into a private user-space within the portal. ODI-PPA leverages cyberinfrastructure at Indiana University including the Big Red II supercomputer, the Scholarly Data Archive tape system and the Data Capacitor shared file system. © 2014 SPIE.","astronomy pipeline, Compute archive, distributed system, HTML5, javascript, observatory data management, science gateways, web portal",1,0,0,1
10.1117/12.2057123,"ODI-portal, pipeline, and archive (ODI-PPA): A web-based astronomical compute archive, visualization, and analysis service",Software and Cyberinfrastructure for Astronomy III,2014,Conference Paper,"The One Degree Imager-Portal, Pipeline, and Archive (ODI-PPA) is a web science gateway that provides astronomers a modern web interface that acts as a single point of access to their data, and rich computational and visualization capabilities. Its goal is to support scientists in handling complex data sets, and to enhance WIYN Observatory's scientific productivity beyond data acquisition on its 3.5m telescope. ODI-PPA is designed, with periodic user feedback, to be a compute archive that has built-in frameworks including: (1) Collections that allow an astronomer to create logical collations of data products intended for publication, further research, instructional purposes, or to execute data processing tasks (2) Image Explorer and Source Explorer, which together enable real-time interactive visual analysis of massive astronomical data products within an HTML5 capable web browser, and overlaid standard catalog and Source Extractor-generated source markers (3) Workflow framework which enables rapid integration of data processing pipelines on an associated compute cluster and users to request such pipelines to be executed on their data via custom user interfaces. ODI-PPA is made up of several light-weight services connected by a message bus; the web portal built using Twitter/Bootstrap, AngularJS and jQuery JavaScript libraries, and backend services written in PHP (using the Zend framework) and Python; it leverages supercomputing and storage resources at Indiana University. ODI-PPA is designed to be reconfigurable for use in other science domains with large and complex datasets, including an ongoing offshoot project for electron microscopy data. © 2014 SPIE.","astronomy pipeline, Compute archive, distributed system, HTML5, javascript, observatory data management, science gateways, web portal",1,0,0,1
10.1117/12.2233111,"Trident: Scalable compute archives: Workflows, visualization, and analysis",Software and Cyberinfrastructure for Astronomy IV,2016,Conference Paper,"The Astronomy scientific community has embraced Big Data processing challenges, e.g. Associated with time-domain astronomy, and come up with a variety of novel and efficient data processing solutions. However, data processing is only a small part of the Big Data challenge. Efficient knowledge discovery and scientific advancement in the Big Data era requires new and equally efficient tools: modern user interfaces for searching, identifying and viewing data online without direct access to the data; tracking of data provenance; searching, plotting and analyzing metadata; interactive visual analysis, especially of (time-dependent) image data; and the ability to execute pipelines on supercomputing and cloud resources with minimal user overhead or expertise even to novice computing users. The Trident project at Indiana University offers a comprehensive web and cloud-based microservice software suite that enables the straight forward deployment of highly customized Scalable Compute Archive (SCA) systems; including extensive visualization and analysis capabilities, with minimal amount of additional coding. Trident seamlessly scales up or down in terms of data volumes and computational needs, and allows feature sets within a web user interface to be quickly adapted to meet individual project requirements. Domain experts only have to provide code or business logic about handling/visualizing their domain's data products and about executing their pipelines and application work flows. Trident's microservices architecture is made up of light-weight services connected by a REST API and/or a message bus; a web interface elements are built using NodeJS, AngularJS, and HighCharts JavaScript libraries among others while backend services are written in NodeJS, PHP/Zend, and Python. The software suite currently consists of (1) a simple work flow execution framework to integrate, deploy, and execute pipelines and applications (2) a progress service to monitor work flows and sub-work flows (3) ImageX, an interactive image visualization service (3) an authentication and authorization service (4) a data service that handles archival, staging and serving of data products, and (5) a notification service that serves statistical collation and reporting needs of various projects. Several other additional components are under development. Trident is an umbrella project, that evolved from the One Degree Imager, Portal, Pipeline, and Archive (ODI-PPA) project which we had initially refactored toward (1) a powerful analysis/visualization portal for Globular Cluster System (GCS) survey data collected by IU researchers, 2) a data search and download portal for the IU Electron Microscopy Center's data (EMC-SCA), 3) a prototype archive for the Ludwig Maximilian University's Wide Field Imager. The new Trident software has been used to deploy (1) a metadata quality control and analytics portal (RADY-SCA) for DICOM formatted medical imaging data produced by the IU Radiology Center, 2) Several prototype work flows for different domains, 3) a snapshot tool within IU's Karst Desktop environment, 4) a limited component-set to serve GIS data within the IU GIS web portal. Trident SCA systems leverage supercomputing and storage resources at Indiana University but can be configured to make use of any cloud/grid resource, from local workstations/servers to (inter)national supercomputing facilities such as XSEDE. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","AngularJS, Docker, IU trident, javascript, microservices, NodeJS, science gateways",1,0,0,1
10.1145/1838574.1838575,Conjugating Science Gateways and Grid Portals into e-Collaboration environments: The Liferay and GENIUS/EnginFrame use case,TeraGrid Conference,2010,Conference Paper,"Nowadays, e-Science uses sophisticated high level tools that allow scientists separated by long distances and belonging to different administrative domains to work on the same project. Among them, Science Gateways and general purpose Grid Portals are becoming very popular. The first ones are generally customized for a given Virtual Research Community (VRC) while the second ones lack very often the possibility to be easily adapted to specific needs. In this paper we present a new e-Collaboration environment that merges the concepts of Science Gateway and Grid Portal. An implementation case using Liferay and GENIUS/Enginframe technologies will be shown. Copyright 2010 ACM.","e-collaboration, e-science, grid computing, grid portal, science gateways",1,0,0,1
10.1145/1838574.1838576,TeraGrid Science Gateway AAAA Model: Implementation and lessons learned,TeraGrid Conference,2010,Conference Paper,"In this paper, we present our experience implementing on the TeraGrid the ""Science Gateway AAAA Model"" we proposed in our 2005 paper. We describe how we have modified the model based on our experiences, the details of our implementation, an update on the open issues we identified in our paper, and our lessons learned.","TeraGrid, science gateways, SAML, PKI",1,0,0,1
10.1145/1838574.1838597,Accelerating science gateway development with web 2.0 and swift,TeraGrid Conference,2010,Conference Paper,"A Science Gateway is a computational web portal that enables scientists to run scientific simulations, data analysis, and visualization through their web browsers. The major problem of building a science gateway on TeraGrid is how to deploy scientific applications rapidly on computational resources and expose these applications as web services to scientists. In this paper we propose a novel science application framework that can greatly accelerate the development cycle of science gateway systems. This framework enables science gateway developers to import their domain-specific scientific workflow scripts and generate Web 2.0 gadgets for running these application workflows and visualizing the output from workflow executions without writing any web related code. By assembling these applicationspecific gadgets and some common gadgets predefined in the framework for workflow management, developers can easily set up a customized computational science gateway to meet community requirements. We demonstrate the utility of the framework with an example from computational biochemistry. Copyright 2010 ACM.","OpenSocial, science gateways, web2.0, workflows",1,0,0,1
10.1145/1838574.1838598,Bringing high performance climate modeling into the classroom,TeraGrid Conference,2010,Conference Paper,"Climate science educators face great challenges on combining theory with hands-on practices in teaching climate modeling. Typical model runs require large computation and storage resources that may not be available on a campus. Additionally, the training and support required to bring novices up to speed would consume significant class time. The same challenges also exist across many other science and engineering disciplines. The TeraGrid science gateway program is leading the way of a new paradigm in addressing such challenges. As part of the TeraGrid science gateway initiative, The Purdue CCSM portal aims at assisting both research and education users to run Community Climate System Model (CCSM) simulations using the TeraGrid high performance computing resources. It provides a one-stop shop for creating, configuring, running CCSM simulations as well as managing jobs and processing output data. The CCSM portal was used in a Purdue graduate class for students to get hands-on experience with running world class climate simulations and use the results to study climate change impact on political policies. The CCSM portal is based on a service-oriented architecture with multiple interfaces to facilitate training. This paper describes the design of the CCSM portal with the goal of supporting classroom users, the challenges of utilizing the portal in a classroom setting, and the solutions implemented. We present two student projects from the fall 2009 class that successfully used the CCSM portal. Copyright 2010 ACM.","Community climate system model (CCSM), science gateways",1,0,0,1
10.1145/1890799.1890808,The dark energy survey data management system as a data lntensive science gateway,"International Workshop on Middleware for Grids, Clouds and e-Science",2010,Conference Paper,"The Dark Energy survey (DEs) collaboration is science effort to understand cosmic acceleration and cdark energy1 responsible for this phenomenon. Dark Energy survey Data Management (DEsDM) system observational astronomy processingpipeline management system that will be used to: process obtained from a survey with the newDEs field camera (DE covering 5ooo sq degree of southern sky; archive final co-added images;extractcatalogs of celestial object every image anddeliver data products to communitythrough portals and services. DEsDM has been designed as a data intensive science Gateway coupling use of shared computational resources (e.g. Teragrid) wi owned databases and file systems for storage distributed across three continents. DEsDM system over the next six years time will perform over 1omillioncPu-hours(sus) of image processing and serve over 4Petabytesof images and 14 objectsto the international DEs collaboration. when delivered for operations in 2o11, it will be one of, if not the, most scalable and powerful systems for processing telescope images, creating co added deep images, and generating detailed catalogs in existence. The project1s software components consist of a processing framework, an ensemble of astronomy codes, integratedarchive,adata-access framework infrastructure. This paper provides an overview of the scope and highlights, the architectural features developed and planned to be able to supportGateway-style management scaleintensive continuous processing and on-demand user queries for analysis. Copyright 2010 ACM.","Collaborative web applications, Large scale systems, Observational astronomy, Pipeline",1,0,0,1
10.1145/2016741.2016777,Virtual laboratory for planetary materials (VLab): An updated overview of system service architecture,TeraGrid,2011,Conference Paper,"In this paper we review the main features and illustrate the use of VLab, a Science Gateway that provides Cyber-infrastructure (CI) for distributed first principles computations in materials science. The VLab CI includes Web Services running in different computers, controlled from a Web Portal running predefined, distributed, and interactive workflows by multiple users. Currently, in addition to simple electronic structure calculations, it supports calculations of materials properties important for mineral physics that require substantial number of tasks, such as, thermodynamic and thermal elastic properties. VLab uses the Quantum ESPRESSO software for first principles computations. Here, we show details of the task distribution in batch system using a ""bag of tasks"" approach. We also explain VLab's approach to interactive user tools, including interactive image plots developed for thermodynamic properties, pressure scale calculator, and a database of results. © 2011 ACM.","cyberinfrastructures, grid computing, grid portal, Quantum ESPRESSO, TeraGrid, virtual laboratory, web services",1,1,0,2
10.1145/2016741.2016778,UltraScan gateway enhancements: In collaboration with TeraGrid advanced user support,TeraGrid Conference,2011,Conference Paper,"The Ultrascan gateway provides a user friendly web interface for evaluation of experimental analytical ultracentrifuge data using the UltraScan modeling software. The analysis tasks are executed on the TeraGrid and campus computational resources. The gateway is highly successful in providing the service to end users and consistently listed among the top five gateway community account usage. This continued growth and challenges of sustainability needed additional support to revisit the job management architecture. In this paper we describe the enhancements to the Ultrascan gateway middleware infrastructure provided through the TeraGrid Advanced User Support program. The advanced support efforts primarily focused on a) expanding the TeraGrid resources incorporate new machines; b) upgrading UltraScan's job management interfaces to use GRAM5 in place of the deprecated WS-GRAM; c) providing realistic usage scenarios to the GRAM5 and INCA resource testing and monitoring teams; d) creating general-purpose, resource-specific, and UltraScan-specific error handling and fault tolerance strategies; and e) providing forward and backward compatibility for the job management system between UltraScan's version 2 (currently in production) and version 3 (expected to be released mid-2011). © 2011 ACM.","application web services, distributed application abstractions, fault tolerance, grid computing, science gateways, scientific application management, scientific workflows, service-oriented architecture",1,0,0,1
10.1145/2016741.2016779,Molecular parameter optimization gateway (ParamChem): Workflow management through TeraGrid ASTA,TeraGrid Conference,2011,Conference Paper,"Parameter optimization for chemical systems requires generation of initial guesses. These parameters should be generated using systematic sampling of parameter space, minimizing differences between output data and the corresponding reference data. In this paper we discuss the ParamChem project, which is creating reusable and extensible infrastructure for the computational chemistry community that will reduce unnecessary and eliminate redundancies in parametrized computations using modern software engineering tools. The paper particularly focuses on constructing and executing coupled molecular chemistry models as complicated workflow graphs. These workflow management capabilities have been integrated with the GridChem Science Gateway infrastructure through the TeraGrid advanced user support program. Further, we describe how the project is enabling a sustainable growth for science gateway infrastructure by building upon tools provided by the Open Gateway Computing Environments. The paper also discusses plans for integrating TeraGrid information, monitoring and prediction services to provide automated job scheduling with resource maintenance and fault aware services. © 2011 ACM.","GridChem, OGCE, ParamChem, science gateways, scientific workflows, TeraGrid advanced user support",1,0,0,1
10.1145/2016741.2016782,Building gateways for life-science applications using the Dynamic Application Runtime Environment (DARE) framework,TeraGrid Conference,2011,Conference Paper,"This work is predicated on three important trends: (i) that the importance, impact and percentage of TeraGrid/XD resources assigned to the life sciences is increasing at a rate that is probably greater than other disciplines, (ii) that gateways have proven to be a very effective access mechanism to distributed HPC resources provided by the TeraGrid/XD, and in particular a very successful model for shared/community access models, and (iii) that in spite of the previous two points there are missing capabilities and abstractions that enable the use of the collective capacity of distributed cyberinfrastructure such as TeraGrid/XD, especially those that can be used to develop gateways in an easy, extensible and scalable fashion for both compute and data-intensive applications. We introduce the SAGA-based, Dynamic Application Runtime Environment (DARE) framework from which extensible, versatile and effective gateways that seamlessly utilize scalable infrastructure can be built for a life-science applications. We discuss the architecture of DARE-based gateways, and four specific life-science gateways - DARE-RFOLD, DARE-DOCK, DARE-HTHP and DARE-NGS, that use the DARE-framework to support a wide-range of life-science capabilities. © 2011 ACM.","data-intensive computing, distributed computing, pilot-job abstraction, runtime environment, science gateways, simple API for grid applications (SAGA)",1,0,0,1
10.1145/2016741.2016784,Transitioning BioVLab cloud workbench to a science gateway,TeraGrid Conference,2011,Conference Paper,"BioVLab gateway is built upon Open Gateway Computing Environments and is currently used as reconfigurable cloud computing workbench. In this talk, we will discuss the new directions towards a TeraGrid Science Gateway and experiences and technical challenges in migrating a Cloud workbench Grid based science gateway. © 2011 Authors.","bioinformatics, cancer research, cloud computing, OGCE workflows suite, TeraGrid science gateways",1,0,0,1
10.1145/2016741.2016785,The CIPRES science gateway: A community resource for phylogenetic analyses,TeraGrid Conference,2011,Conference Paper,"The CIPRES Science Gateway (CSG) provides researchers and educators with browser-based access to community codes for inference of phylogenetic relationships from DNA and protein sequence data. The CSG allows users to deploy jobs on the high-performance computers of the TeraGrid without requiring detailed knowledge of their complexities. Use of the CSG has grown rapidly; through March 2011 it had more than 2,200 users and enabled more than 180 peer-reviewed publications. The rapid growth in resource consumption was accommodated by deploying codes on Trestles, a new TeraGrid computer. Tools and policies were developed to insure efficient and effective resource use. This paper describes progress in managing the growth of this public cyberinfrastructure resource and reviews the domain science that it has enabled. © 2011 ACM.","CIPRES, GARLI, MAFFT, MrBayes, phylogenetics, RAxML, science gateways",1,0,0,1
10.1145/2016741.2016786,A CyberGIS gateway approach to interoperable access to the National Science Foundation TeraGrid and the Open Science Grid,TeraGrid Conference,2011,Conference Paper,"The vision of creating a ""virtual supercomputing"" environment to solve large-scale scientific problems has largely been facilitated by the development and deployment of Grid middleware. However, with the deployment of multiple disconnected Grid environments, we are now faced with the problem of interoperable access to resources from multiple environments to meet the requirements of scientific applications. Within the U. S. cyberinfrastructure environments, two key elements: both the National Science Foundation TeraGrid and the Open Science Grid (OSG) provide varied but important capabilities and resources needed by diverse computational communities. Hence, it is critical to understand how these communities can benefit from bridging these different environments and utilize them when needed. In this paper we present a novel approach to interoperable access to both OSG and TeraGrid to users through the CyberGIS Gateway - an online geographic information system. In particular, five key interoperability themes are addressed: authentication and authorization, information services, data management, and computation management and auditing. We take a scientific application use-case (viewshed analysis) on the CyberGIS Gateway to demonstrate how to exploit resources on both OSG and TeraGrid. © 2011 ACM.","CyberGIS, cyberinfrastructure interoperability, distributed computing, science gateways",1,0,0,1
10.1145/2016741.2016788,A solution looking for lots of problems: Generic portals for science infrastructure,TeraGrid Conference,2011,Conference Paper,"Science gateways have dramatically simplified the work required by science communities to run their codes on TeraGrid resources. Gateway development typically spans the duration of a particular grant, with the first production runs occurring some months after the award and concluding near the end of the project. Scientists use gateways as a means to interface with large resources. Our gateway infrastructure facilitates this by hiding away the various details of the underlying resources and presents an intuitive way to interact with the resource. In this paper, we present our work on GPSI, a general-purpose science gateway infrastructure that can be easily customized to meet the needs of an application. This reduces the time to deployment and improves scientific productivity. Our contribution in this paper is two-fold: to elaborate our vision for a user-driven gateway infrastructure that includes components required by multiple science domains, thus aiding the speedy development of gateways, and presenting our experience in moving from our initial portal implementations to the current effort based on Python [15] and Django [16]. © 2011 ACM.","Django, Python, science gateways, Swift, web2.0, workflows",1,0,0,1
10.1145/2016741.2016789,Automated grid probe system to improve end-to-end grid reliability for a science gateway,TeraGrid Conference,2011,Conference Paper,"In 2010, the science gateway nanoHUB.org, the world's largest nanotechnology user facility, hosted 9,809 simulation users who performed 372,404 simulation runs. Many of these jobs are compute-intensive runs that benefit from submission to clusters at Purdue, TeraGrid, and Open Science Grid (OSG). Most of the nanoHUB users are not computational experts but end-users who expect complete and uninterrupted service. Within the ecology of grid computing resources, we need to manage the grid submissions of these users transparently with the highest possible degree of user satisfaction. In order to best utilize grid computing resources, we have developed a grid probe protocol to test the job submission system from end to end. Beginning in January 2009, we have collected a total of 1.2 million probe results from job submissions to TeraGrid, OSG, Purdue, and nanoHUB compute clusters. We then utilized these results to intelligently submit jobs to various grid sites using a model for probability of success based in part on probe test history. In this paper we present details of our grid probe model, results from the grid probe runs, and a discussion of data from production runs over the same time period. These results have allowed us to begin assessing our utilization of grid resources while providing our users with satisfactory outcomes. © 2011 ACM.","grid computing, HUBzero, NanoHUB, nanotechnology, performance monitoring, science gateways, simulations",1,0,0,1
10.1145/2016741.2016790,Developing an integrated end-to-end TeraGrid climate modeling environment,TeraGrid Conference,2011,Conference Paper,"The Community Earth System Model (CESM) is a widely used community model for studying the climate system on the Earth. The CESM model is both data and computationally intensive, making it difficult for users to set up and run CESM simulations using local resources. In this paper, we describe an integrated climate modeling environment that supports CESM simulations on the TeraGrid, comprehensive model metadata description, and automatic archival of model data and metadata for easy community access. This system builds upon and integrates several existing efforts - the Purdue CCSM modeling portal, the Earth System Grid, the Earth System Modeling Framework, and the Earth System Curator. We present the design and implementation of our prototype system as well as an end-to-end usage scenario which is broken down into three workflows: model execution, data publishing, and metadata collection/publishing. The system will be used to support research and education on climate systems. We describe our plan and early efforts to engage users and obtain their feedback. © 2011 ACM.","CCSM, CESM, climate model, earth system grid, ESMF, metadata, Purdue CCSM portal, science gateways, TeraGrid",1,0,0,1
10.1145/2070770.2070774,Integrating CyberGIS gateway with Windows Azure: A case study on MODFLOW groundwater simulation,ACM SIGSPATIAL Second International Workshop on High Performance and Distributed Geographic Information Systems,2011,Conference Paper,"The CyberGIS Gateway represents a cutting-edge cyberin-frastructure-based geographic information system that facilitates computationally intensive and collaborative spatial analysis and modeling. As more and more geospatial problems are becoming increasingly computationally intensive and complex to solve, Cloud computing, often characterized as on-demand and elastic, provides promising approaches to these problems. This research has developed an integration framework for CyberGIS Gateway to leverage the Microsoft Windows Azure Cloud platform. The framework is based on a generic architectural design for the CyberGIS Gateway to integrate with Cloud computing environments. This paper describes our initial implementation of the integration framework based on a case study of groundwater ensemble run, and discusses major challenges and future direction for establishing hybrid cyberinfrastructure encompassing both high-end and Cloud computing environments. © 2011 ACM.","cloud computing, CyberGIS, MODFLOW, science gateways, Windows Azure",1,0,0,1
10.1145/2070770.2070775,Bring integrated GIS data and modeling capabilities into HUBzero platform,ACM SIGSPATIAL Second International Workshop on High Performance and Distributed Geographic Information Systems,2011,Conference Paper,"The rapid advancement in the collection of environmental data, geospatial analysis and modeling software calls for new GIS-enabled cyberinfrastructure (CI) capable of support large scale integrated data and modeling activities. Although the HUBzero platform is gaining popularity as a portal development framework for many science and engineering communities, it has limited success in earth and environmental science domains, mainly due to its lack of native support for large geospatial data management and GIS functionalities in the Rappture toolkit. In this paper, we describe our initial work on bringing integrated GIS data and modeling capabilities into the HUBzero platform. We describe the overall architecture of our CI solution which is scalable, extensible and portable to other gateway framework as well. Two prototype applications are presented as a proof-of-concept. Coupling the scalable GIS capabilities with a wealth of tools for user participation and community building on the HUBzero platform, we hope to help new science communities in utilizing this platform. © 2011 ACM.","data and model integration, GIS-enabled cyberinfrastructure, HUBzero, science gateways",1,0,0,1
10.1145/2110486.2110488,A history of the TeraGrid Science Gateway program: A personal view,ACM workshop on Gateway computing environments,2011,Conference Paper,"This paper describes the NSF TeraGrid Science Gateways program, its formation, progress, lessons learned and current contributions over its seven-year life and new directions in the NSF XSEDE program. Early requirements analysis work with path-finding gateways that formed the underpinning of the program are described as are current projects and their unique contributions to the larger program. Future directions both within the XSEDE program and for gateways more generally are discussed. © 2011 ACM.","computational science, middleware, portals, science gateways",1,0,0,1
10.1145/2110486.2110490,Apache Airavata: A framework for distributed applications and computational workflows,ACM workshop on Gateway computing environments,2011,Conference Paper,"In this paper, we introduce Apache Airavata, a software framework to compose, manage, execute, and monitor distributed applications and workflows on computational resources ranging from local resources to computational grids and clouds. Airavata builds on general concepts of service-oriented computing, distributed messaging, and workflow composition and orchestration. This paper discusses the architecture of Airavata and its modules, and illustrates how the software can be used as individual components or as an integrated solution to build science gateways or general-purpose distributed application and workflow management systems. © 2011 ACM.","Grid applications, science gateways, scientific workflows",1,0,0,1
10.1145/2110486.2110491,Open community development for science gateways with Apache Rave,ACM workshop on Gateway computing environments,2011,Conference Paper,"Science gateways enable researchers and students to use distributed scientific computing infrastructure (cyberinfrastructure) through Web browsers and Web-enabled desktop clients. This paper describes the use of the open source, open community Apache Rave project as the basis for developing science gateways. Building on Apache Shindig (for OpenSocial Gadgets) and Apache Wookie (for W3C Widgets), Rave provides an out-of-the box deployment that can be used to host reusable social Web components. Rave is based on the Spring MVC framework and so can also be extensively customized or extended with (for example) custom database back-ends and authentication modules. In this paper we consider Rave as a development platform for science gateways and discuss how the source code may be extended through three use cases that focus on gateway security requirements. A major consideration of this paper is how to design Rave as a development environment so that developers can make local customizations and extensions freely on both a rapidly changing code base (during Rave's initial development), and (later) between stable code bases during version upgrades. We conclude with a discussion of the implications of developing science gateways and other cyberinfrastructure software within the Apache Software Foundation and present its potential advantages. © 2011 ACM.","cloud computing, grid computing, OpenSocial, science gateways, W3C widget, Web computing",1,0,0,1
10.1145/2110486.2110492,Google Web Toolkit for OGCE gadget based architecture,ACM workshop on Gateway computing environments,2011,Conference Paper,"This paper introduces a gadget-based web 2.0 architecture for building scientific and educational tools. This architecture builds on ideas from both Google Web Toolkit (GWT) and Google gadget and adds AJAX functionality. The gadgets developed with GWT are hosted in the Open Gateway Computing Environments (OGCE) container. The community of scientific applications and science gateways developers face the challenges of rapid development of scientific and educational tools for their users. This web application development approach allows developers to create a gadget graphical user interface within hours and, thus, can potentially expand the variety of OpenSocial Gadgets. A gadget that has been developed using our gadget-based architecture for online Community Earth System Model (CESM) simulations is presented as a use case in this paper. © 2011 ACM.","Community Earth System Modeling (CESM), GWT gadget, Large data transport, OGCE, science gateways, Web service",1,0,0,1
10.1145/2110486.2110494,Building an environment to facilitate discoveries for plant sciences,ACM workshop on Gateway computing environments,2011,Conference Paper,"The iPlant Collaborative is an NSF-funded cyberinfrastructure (CI) effort directed towards the plant sciences community. This paper enumerates the key concepts, middleware, tools, and extensions that create the unique capabilities of the iPlant Discovery Environment (DE) that provide access to our CI. The DE is a rich web-based application that brings flexible CI capabilities to a wide audience affiliated with the plant sciences, from computational biologists, bioinformaticians, applications developers, to bench biologists. The inherent interdisciplinary nature of plant sciences research produces diverse and complex data products that range from molecular sequences to satellite imagery as part of the discovery life cycle. With the constant creation of novel analysis algorithms, the advent and spread of large data repositories, and the need for collaborative data analysis, marshaling resources to effectively utilize these capabilities necessitates a highly flexible and scalable approach for implementing underlying CI. The iPlant infrastructure simultaneously supports multiple interdisciplinary projects providing essential features found in traditional science gateways as well as highly customized direct access to its underlying frameworks through use of APIs (Application Programming Interfaces). This allows the community to develop de novo applications. This approach allows us to serve broad community needs while providing flexible, secure, and creative utilization of our platform that is based on best practices and that leverages established computational resources. © 2011 ACM.","bioinformatics, Computational biology, cyberinfrastructures, Plant biology, Plant sciences, science gateways",1,0,0,1
10.1145/2335755.2335836,The CIPRES science gateway: Enabling high-impact science for phylogenetics researchers with limited resources,Conference on Extreme Science and Engineering Discovery Environment,2012,Conference Paper,"The CIPRES Science Gateway (CSG) provides browser-based access to computationally demanding phylogenetic codes run on large HPC resources. Since its release in December 2009, there has been a sustained, near-linear growth in the rate of CSG use, both in terms of number of users submitting jobs each month and number of jobs submitted. The average amount of computational time used per month by CSG increased more than 5-fold since its initial release. As of April 2012, more than 4,000 unique users have run parallel tree inference jobs on TeraGrid/XSEDE resources using the CSG. The steady growth in resource use suggests that the CSG is meeting an important need for computational resources in the Systematics/Evolutionary Biology community. To ensure that XSEDE resources accessed through the CSG are used effectively, policies for resource consumption were developed, and an advanced set of management tools was implemented. Studies of usage trends show that these new management tools helped in distributing XSEDE resources across a large user population that has low-to-moderate computational needs. In the first quarter of 2012, 30% of all active XSEDE users accessed computational resources through the CSG, while the analyses conducted by these users accounted for 0.7% of all allocable XSEDE computational resources. User survey results showed that the easy access to XSEDE/TeraGrid resources through the CSG had a critical and measurable scientific impact: at least 300 scholarly publications spanning all major groups within the Tree of Life have been enabled by the CSG since 2009. The same users reported that 82% of these publications would not have been possible without access to computational resources available through the CSG. The results indicate that the CSG is a critical and cost-effective enabler of science for phylogenetic researchers with limited resources. © 2012 ACM.","BEAST, CIPRES, GARLI, MAFFT, MrBayes, phylogenetics, RAxML, science gateways, sequence alignment, tree inference",1,0,0,1
10.1145/2335755.2335863,XSEDE12 panel: Security for science gateways and campus bridging,Conference on Extreme Science and Engineering Discovery Environment,2012,Conference Paper,"The XSEDE science gateway and campus bridging programs share a mission to expand access to cyberinfrastructure, for scientific communities and campus researchers. Since the TeraGrid science gateway program began in 2003, science gateways have served researchers in a wide range of scientific disciplines, from a stronomy to seismology. In its 2011 report, the NSF ACCI Task Force on Campus Bridging identified the critical need for seamless integration of cyberinfrastructure from the scientist's desktop to the local campus, to other campuses, and to regional, national, and international cyberinfrastructure. To effectively expand access to cyberinfrastructure across communities and campuses, XSEDE must address security challenges in areas such as identity/access management, accounting, risk assessment, and incident response. Interoperable authentication, as provided by the InCommon federation, enables researchers to conveniently sign on to access cyberinfrastructure across campus and across the region/nation/world. Coordinated operational protection and response, as provided by REN-ISAC, maintains the availability and integrity of highly connected cyberinfrastructure. Serving large communities of researchers across many campuses requires security mechanisms, processes, and policies to scale to new levels. This panel will discuss the security challenges introduced by science gateways and campus bridging, potential approaches for addressing these challenges (for example, leveraging InCommon and REN-ISAC), and plans for the future. Panelists will solicit requirements and recommendations from attendees as input to future work. © 2012 Authors.","campus bridging, science gateways",1,0,0,1
10.1145/2460756.2460759,Experiences of using a hybrid cloud to construct an environmental virtual observatory,International Workshop on Cloud Data and Platforms,2013,Conference Paper,"Environmental science is often fragmented: data is collected using mismatched formats and conventions, and models are misaligned and run in isolation. Cloud computing offers a lot of potential in the way of resolving such issues by supporting data from different sources and at various scales, by facilitating the integration of models to create more sophisticated software services, and by providing a sustainable source of suitable computational and storage resources. In this paper, we highlight some of our experiences in building the Environmental Virtual Observatory pilot (EVOp), a tailored cloud-based infrastructure and associated web-based tools designed to enable users from different backgrounds to access data concerning different environmental issues. We review our architecture design, the current deployment and prototypes. We also reflect on lessons learned. We believe that such experiences are of benefit to other scientific communities looking to assemble virtual observatories or similar virtual research environments. Copyright © 2013 ACM.","cloud computing, cyberinfrastructures, e-science, Environmental science, Hybrid infrastructure, open science, science gateways, virtual observatory, virtual research environments",1,0,1,2
10.1145/2484762.2484780,"OSC ondemand: A web platform integrating access to HPC systems, web and VNC applications",Conference on Extreme Science and Engineering Discovery Environment,2013,Conference Paper,"In this paper, we describe the OnDemand web platform for providing OSC users integrated access to HPC systems, web applications and VNC services. We present the user experience and implementation of OnDemand and compare it with existing science gateway approaches. © 2013 by the Association for Computing Machinery, Inc.","cyberinfrastructures, high-performance computing, OpenID, REST, virtual organizations, web platform",1,0,0,1
10.1145/2484762.2484784,Developing a high-volume batch submission system for earthquake engineering,Conference on Extreme Science and Engineering Discovery Environment,2013,Conference Paper,"NEES is a network of 14 earthquake engineering labs distributed across the United States. As a part of the NEES effort NEESComm operates a comprehensive cyberinfrastructure that consists of the NEEShub and the NEES Project Warehouse. NEESComm provides consistent access to several High Performance Computing (HPC) venues. These venues include XSEDE, the Open Science Grid (OSG), Purdue Supercomputers, and NEEShub servers. In this paper, we describe the system we developed, Batchsubmit, which allows NEES researchers to make use of all these venues through the NEEShub science gateway. © 2013 by the Association for Computing Machinery, Inc.","Batch submission, earthquake engineering, high-performance computing, simulations",1,0,0,1
10.1145/2484762.2484800,Improvements of the ultrascan scientific gateway to enable computational jobs on large-scale and open-standards based cyberinfrastructures,ACM International Conference Proceeding Series,2013,Conference Paper,"The UltraScan data analysis application is a software package that is able to take advantage of computational resources in order to support the interpretation of analytical ultracentrifugation (AUC) experiments. Since 2006, the UltraScan scientific gateway has been used with ordinary Web browsers in TeraGrid by scientists studying the solution properties of biological and synthetic molecules. Unlike other applications, UltraScan is implemented on a gateway architecture and leverages the power of supercomputing to extract very high resolution information from the experimental data. In this contribution, we will focus on several improvements of the UltraScan scientific gateway that enable a standardized job submission and management to computational resources while retaining its lightweight design in order to not disturb the established workflows of its end-users. This paper further presents a walkthrough of the architectural design including one real installation deployment of UltraScan in Europe. The aim is to provide evidence for the added value of open standards and resulting interoperability enabling not only UltraScan application submissions to resources offered in the US cyber infrastructure Extreme Science and Engineering Discovery Environment (XSEDE), but also submissions to similar infrastructures in Europe and around the world. The use of the Apache Airavata framework for scientific gateways within our approach bears the potential to have an impact on several other scientific gateways too. © 2013 by the Association for Computing Machinery, Inc.","apache airavata, scientific gateways, Ultrascan, UNICORE, XSEDE",1,0,0,1
10.1145/2484762.2484806,Embedding CIPRES science gateway capabilities in phylogenetics software environments,Conference on Extreme Science and Engineering Discovery Environment,2013,Conference Paper,"The explosive growth in DNA sequence data over the past decade makes it possible to clarify evolutionary relationships among all living things at an unprecedented level of resolution. Phylogenetic inference codes are computationally intensive, so turning this wealth of DNA sequence data into new insights about evolution requires access to high performance computing (HPC) resources. The CIPRES Science Gateway (CSG) was designed to meet this need by providing browser-based access to phylogenetic codes run on XSEDE compute resources. The CSG has lowered the barrier for access to HPC resources for biologists worldwide, supporting more than 6,100 users and enabling more than 600 publications over the past three years. Here we describe plans to create a new set of public CSG web services that can be accessed by any developer through a programmatic interface. These services will allow us to embed access to XSEDE resources within well-established phylogenetics software packages, thus leveraging the investments by developers in creating these rich work environments and by users in learning to use them. The services will also allow any developer with modest scripting skills to access and use CSG capabilities outside of the current browser interface. Our goal in creating these services is to allow scientists to conduct analyses without leaving their preferred work environment, whether that is a complex desktop application, a set of ad hoc scripted workflows, or the existing CSG browser interface. This paper describes the architectural design of the CSG web services, identifies potential issues that will be addressed in exposing programmatic access to HPC resources, and describes plans to embed the CSG web services in eight popular community applications. © 2013 by the Association for Computing Machinery, Inc.","CIPRES, phylogenetics, Representational state transfer, tree inference, web services",1,0,0,1
10.1145/2484762.2484808,Integration of science gateways: A case study with CyberGIS and opentopography,Conference on Extreme Science and Engineering Discovery Environment,2013,Conference Paper,"Science gateways are collaborative software environments designed to enable community-driven development and use of cyberinfrastructure services, software tools, applications, and data through common interfaces, typically an online portal, customized to meet the needs of individual communities [1]. By abstracting the assemblage of cyberinfrastructure needed by the research communities and democratizing access to high-end computational resources, science gateways (e.g. those on XSEDE) provide a shared problem-solving environment and promote collaborations among community users. The integration work presented here represents a cutting-edge approach to coupling two independent geospatial software environments developed separately, namely CyberGIS [2] and OpenTopography [3]. © 2013 by the Association for Computing Machinery, Inc.","CyberGIS, Integration, OpenTopography, science gateways",1,0,0,1
10.1145/2484762.2484813,Idata: A community geospatial data sharing environment to support data-driven science,Conference on Extreme Science and Engineering Discovery Environment,2013,Conference Paper,"With the advent of XSEDE, the national cyberinfrastructure has evolved from a set of traditional HPC resources to a broader range of digital services. Science gateways, which serve as portals to scientific applications, have also evolved as researchers are dealing with rapidly expanding scientific datasets and the increasingly complex workflows. More and more gateways are being developed to support integrated services for running data-driven applications on HPC resources such as those on XSEDE. To facilitate this type of workflow, there is a pressing need for web-based data management systems that are easy to use, support data upload, sharing, access and management, and can be integrated with advanced computation and storage resources. More importantly such systems need to be accessible by users from the broad research and education communities. In this paper, we describe the design and implementation of iData, a web-based community data publishing and sharing system. iData supports both generic file-based data collections and several commonly used environmental data collection formats including time series, GIS vector and raster data. Integrated data processing, visualization and filtering capabilities are provided for these data formats. Currently iData can be downloaded and deployed in a HUBzero-based gateway, and we plan to make it available for non-HUBzero platforms in the future. We present two examples in which iData has been successfully used to support research collaboration in driNET and GEOSHARE projects. © 2013 by the Association for Computing Machinery, Inc.","Community data, Data publishing, data sharing, geospatial data, HUBzero, Science gateway data management, XSEDE",1,0,0,1
10.1145/2484762.2484815,US-SOMO cluster methods: Year one perspective,Conference on Extreme Science and Engineering Discovery Environment,2013,Conference Paper,"UltraScan Solution Modeler (US-SOMO) computes hydiodynamie parameters and small-angle scattering data from biological macromolecular structural representations and compares them with experimental data for structural determination and validation. At XSEDE 12, a GUI integrated gateway was introduced to offload large computations to various HPC resources. The gateway was directly integrated into the Qt/GUI based software to allow the users a seamless experience. The software is available as source code or precompiled for Apple Mac OSX, MS-Windows and Linux. Current cluster resources include TACC Lonestar and Stampede, SDSC Trestles and a 256 CPU cluster local to the University of Texas Health Science Center at San Antonio. The simplicity of design allowed the implementation of a new method of modeling small angle scattering data that provided new scientific insights and was presented at the 2012 international small-angle scattering conference. Since introduction, multiple workshops have been taught and users are beginning to utilize the gateway in their biological research. © 2013 by the Association for Computing Machinery, Inc.","Analytical ultracentrifugation, apache airavata, Bead modeling, Community outreach, Enabled science, Hydrodynamics, Open gateway computing environment, science gateways, Small angle scattering, Structural biology, Ultrascan",1,0,0,1
10.1145/2484762.2484816,A neuroscience gateway - Software and implementation,Conference on Extreme Science and Engineering Discovery Environment,2013,Conference Paper,"In this paper, we describe the neuroscience gateway (NSG), which facilitates access to high performance computing resources for computational neuroscientists. Through a simple web-based portal, the NSG provides a streamlined environment for uploading models, specifying HPC job parameters, querying running job status, receiving job completion notices, and storing and retrieving output data. The NSG architecture transparently distributes user jobs to appropriate HPC resources available through the XSEDE organization. © 2013 by the Association for Computing Machinery, Inc.","computational neuroscience, Neuronal tools, Science gateway software, web portal",1,0,0,1
10.1145/2616498.2616560,An open extensible multitarget application generation tool for simple rapid deployment of multiscale scientific codes,Conference on Extreme Science and Engineering Discovery Environment,2014,Conference Paper,"Combining modules wrapping a diversity of executable codes derived from various scientific research labs with a range of computational and data scales into a sustainable framework requires careful considerations. In the described framework, we have separated the module's executable codes from the user-interface and created an application generation tool which produces all the code necessary to create a web based science gateway simultaneously with a local GUI based application. This work was driven by requirements related to an international collaborative grant. This ongoing development is producing applications and will be in the hands of beta testers at the time of this publication. Copyright 2014 ACM.","CASE tools, science gateways",1,0,0,1
10.1145/2616498.2616561,Dynamically provisioning portable gateway infrastructure using docker and agave,Conference on Extreme Science and Engineering Discovery Environment,2014,Conference Paper,"The iPlant Agave Developer APIs are a Science-As-A-Service platform for developing modern science gateways. One trend we see emerging from our users is the aggregation of many different, distributed compute and storage systems. The rise in popularity in IaaS, PaaS, and container technologies has made the rapid deployment of elastic gateway infrastructure a reality. In this talk we will introduce Docker and the Agave Developer APIs then demonstrate how to use them to provision applications and infrastructure that are portable across any Linux hosting environment. We will conclude by using our lightweight gateway technology, GatewayDNA, to run an application and move data across multiple systems simultaneously. Copyright 2014 ACM.","API, Docker, Portability, REST, software-as-a-service",1,0,0,1
10.1145/2616498.2616563,Incorporating job predictions into the SEAGrid science gateway,Conference on Extreme Science and Engineering Discovery Environment,2014,Conference Paper,This paper describes the process of incorporating predictions of job queue wait times and run times into a Science Gateway. Science Gateways that integrate multiple resources can use predictions of queue wait times and run times to advice users when they choose where a job is executed or in an automated resource selection process. These predictions are also critical in executing workflows were it isn't feasible to have users specify where each task executes and the workflow management system therefore has to perform resource selection programmatically. SEAGrid science gateway has partly integrated the estimation of wait time prediction based on Karnak prediction service and is in the process of extending this to run time prediction. Copyright 2014 ACM.,"computational chemistry, Queue prediction, Run time prediction, Scheduling, science gateways",1,0,0,1
10.1145/2676585.2676591,Unified nanoscale gateway to HPC and Grid environments,Symposium on Information and Communication Technology,2014,Conference Paper,"Nanotechnology and advanced materials research is offered as a transformative technology with the potential to improve every aspect of social, physical, and economic well-being. Presently, the excellent research is running at Slovak Academy of Sciences (SAS) in various subfields and research disciplines in nanotechnology. As many other fields, nano-technology research also requires computational and infrastructure support, especially for modelling and simulations. From this point of view, the nanotechnology area represents a big challenge where different scales meet. The high performance computing (HPC) and the Grid computing gives a good chance to simulate real physical nano-structural systems even on atomic level under various external conditions. This paper presents the computational support approach in such environments: a scientific user-centric gateway into the high computational capacity for nanoscale simulations. Copyright 2014 ACM.","Advanced materials research, cloud computing, grid computing, high-performance computing, Micro-magnetism, modeling and simulations, nanotechnology, scientific gateways",1,0,0,1
10.1145/2753524.2753527,Science Gateway canvas: A business reference model for Science Gateways,Workshop on the Science of Cyberinfrastructure,2015,Conference Paper,"Science Gateways (SGs) have emerged as systems that facilitate access to cyberinfrastructures. There is a growing interest in the exploitation and development of SGs. However, it remains challenging to understand and design SG with the required properties because of the complex nature of SGs. Additionally, it is difficult to decide upon frameworks that can be used to build them. In this paper we propose the Science Gateway Canvas, a business reference model for SGs that embodies the common SG functions and their organization into groups and categories. We used the Science Gateway Canvas for a systematic analysis and comparison of the functions offered by a selection of available frameworks that are used to build SGs. This illustrated the applicability of the Science Gateway Canvas as a comprehensive and generic reference model for understanding SGs. The canvas can also be used for systematic analysis by scientists who are searching for an existing SG that supports their research goal or developers who want to determine the functional requirements for a new SG. Copyright © 2015 ACM.","Business reference model, Collaboratory, cyberinfrastructures, e-infrastructures, e-Research environment, e-science, problem solving environment , science gateways, Science Gateway Canvas (SGC), Science Gateway development, Science Gateway frameworks, Science Gateway technologies, science portal, virtual laboratory, virtual research environments",1,1,1,3
10.1145/2753524.2753529,Apache airavata as a laboratory: Architecture and case study for component-based gateway middleware,Conference on Extreme Science and Engineering Discovery Environment,2015,Conference Paper,"Science gateways are more than user interfaces to computational grids and clouds. Gateways are middleware in their own right, providing flexible, lightweight federations of heterogenous collections of computing resources (such as campus clusters, supercomputers, computational clouds), all of which remain challenges for many alternative middleware approaches. Gateways also are notable for providing science application-centric interfaces to computing resources rather than resource-centric views. An important challenge for science gateway research is to generalize specific science gateway strategies, defining a reference architecture that emcompasses major gateway capabilities while enabling implementation flexibility. Such a reference architecture should also enable ""platform as a service"" approaches that provide hosted versions of common gateway capabilities. In this paper, we summarize the Apache Airavata software system as a candidate reference architecture for science gateways. We propose the use of a component-based architecture to encompass major gateway capabilities (such as metadata management, meta-scheduling, execution management, and messaging). We examine the messaging system component in this abstract architecture in detail and describe its reimplementation and validation using third party messaging system software to replace a custom-built messaging system. Besides the operational validation of this specific component, we infer a preliminary validation of the overall architecture. The flexibility of component implementations within an overall architecture is essential as it allows gateway middleware to be the subject of distributed computing research for its own sake while also ensuring that we don't get locked into less than optimal implementations for gateway operations. Copyright © 2015 ACM.","apache airavata, distributed systems, Evolutionary architecture, Microservice architecture, science gateways",1,0,0,1
10.1145/2792745.2792781,Bring the NLACE model online using xseDE and HUBzero,Conference on Extreme Science and Engineering Discovery Environment,2015,Conference Paper,"In this paper, we describe a ""gateway as a service"" approach to help researchers bring their applications online quickly and make them available for the broad user community. This approach builds on the HUBzero technology and leverages the XSEDE HPC resources. It enables individual scientists and small research groups to quickly develop, deploy, and share their applications online without having to learn web programming and the XSEDE system level software stacks. The cost of such approach for a small team would be significantly lower than building a science gateway from scratch and sustaining it in the long run. The applicability of this approach was demonstrated via an XSEDE Extended Collaborative Support Service (ECSS) project we have recently completed for developing a biomechanical imaging (BMI) gateway. Our team consists of ECSS staff from Purdue University and biomechanical imaging researchers from Boston University and Rensselaer Polytechnic Institute. In the ECSS work, we were able to quickly develop an online tool for composing and executing NLACE model simulations on Gordon and visualizing the model output interactively using ParaView. The online tool runs on DiaGrid Hub (powered by HUBzero) with comprehensive support for job and workflow submission, tickets, content management, discussion forum, wiki, project, group, documentation, rating, citation, and usage tracking. Copyright © 2015 ACM.","Biomechanical imaging, HUBzero, Nlace model, science gateways, XSEDE",1,0,0,1
10.1145/2792745.2792784,The CIPRES workbench: A flexible framework for creating science gateways,Conference on Extreme Science and Engineering Discovery Environment,2015,Conference Paper,"Here we describe the CIPRES Workbench (CW), an open source software framework for creating new science gateways with minimal overhead. The CW is a web application that can be deployed on a modest server, and can be configured to submit command line instructions to any resource where the application has submission privileges. It is designed to be highly configurable / customizable, and supports GUI-based access to HPC resources through a web browser interface as well as programmatic access via a ReSTful API. Using browser access, the CW architecture creates an environment with secure user accounts where user input data, job results, and job provenance are stored. The ReSTful API allows users with a registered a client application to deliver command lines to analytical codes and retrieve results from remote compute resources. A development effort is underway to allow the CW to submit jobs via the Science Gateways as a Platform (SciGaP) services hosted at Indiana University. Copyright © 2015 ACM.","open source, Restful services, science gateways, SciGaP, software, Workbench",1,0,0,1
10.1145/2792745.2792786,Enabling HPC simulation workflows for complex industrial flow problems,Conference on Extreme Science and Engineering Discovery Environment,2015,Conference Paper,"The use of simulation based engineering taking advantage of massively parallel computing methods by industry is limited due to the costs associated with developing and using high performance computing software and systems. To address industries ability to effectively include large-scale parallel simulations in daily production use, two key areas need to be addressed. The first is access to large-scale parallel computing systems that are cost effective to use. The second is support for complete simulation workflow execution on these systems by industrial users. This paper presents an approach, and set of associated software components, that can support industrial users on large-scale parallel computing systems available at various national laboratories, universities, or on clouds. Copyright © 2015 ACM.","Parallel workflows, science gateways, Simulation based engineering",1,0,0,1
10.1145/2949550.2949574,Tools for studying populations and timeseries of neuroanatomy enabled through GPU acceleration in the computational anatomy gateway,Conference on Extreme Science and Engineering Discovery Environment,2016,Conference Paper,"The Computational Anatomy Gateway is a software as a ser-vice tool for medical imaging researchers to quantify changes in anatomical structures over time, and through the progres-sion of disease. GPU acceleration on the Stampede cluster has enabled the development of new tools, combining advan-tages of grid based and particle based methods for describ-ing fluid flows, and scaling up analysis from single scans to populations and timeseries. We describe algorithms for esti-mating average anatomies, and for quantifying atrophy rate over time. We report code performance on different sized datasets, revealing that the number vertices in a triangu-lated surface presents a bottleneck to our computation. We show results on an example dataset, quantifying atrophy in the entorhinal cortex, a medial temporal lobe brain region whose structure is sensitive changes in early Alzheimer's dis-ease. © 2016 ACM.","Computational anatomy, Medical imaging, Neuroscience, science gateways",1,0,0,1
10.1145/2949550.2949591,Anatomy of the SEAGrid science gateway,"Diversity, Big Data, and Science at Scale",2016,Conference Paper,"The SEAGrid science gateway provides scientists and educators with user interfaces and tools for conducting computational chemistry, material science, and engineering experiments online using XSEDE and campus computing resources. This paper describes the architecture of the recently completed technology refresh for the gateway, replacing its desktop user interface, adding a web browser user interface, using Apache Airavata middleware for job management, and providing enhanced data search and feature extraction capabilities. These introduce several challenges, particularly in providing unified authentication and authorization mechanisms to middleware services for the desktop and web clients, and in extending Apache Airavata middleware with new components. Access, authentication, and authorization problems were solved by using standard-based approaches (OAuth2, XACML) that were implemented by incorporating WSO2's Identity Server into both SEAGrid and Apache Airavata. SEAGrid-specific data extraction capabilities were added to Airavata middleware using a message-based component approach. This approach is generalizable to other advanced and gatewayspecific capabilities and enables Airavata to add additional data analysis components without modifying its core functionality. © 2016 ACM.","computational chemistry, distributed systems, material science, science gateways",1,0,0,1
10.1145/2949550.2949653,The XSEDE BLAST gateway: Leveraging campus development for the XSEDE community,Conference on Extreme Science and Engineering Discovery Environment,2016,Conference Paper,"This paper describes an XSEDE Extended Collaboration Support Service (ECSS) effort on scaling a campus-developed online BLAST service (BLASTer) into an XSEDE gateway to help bridge the gap between genomic researchers and advanced computing and data environments like those found in the Extreme Science and Engineering Discovery Environment (XSEDE) network. Biologists and geneticists all over the world use the suite of Basic Local Alignment Search Tools (BLAST) developed by the National Center for Biotechnology Information (NCBI) throughout the full spectrum of genomic research. It has become one of the de facto bioinformatics applications used in all variety of computing environments. BLASTer allows researchers to achieve those tasks faster and without expert computing knowledge by converting BLAST jobs to parallel executions. It handles all of the details of computation submission, execution, and database access for users through an intuitive web-based interface provided by the unique features of the HUBzero gateway platform. This paper details the core development of BLASTer for campus computing resources at Purdue University, some of its successes among the user community, and the current efforts by an ECSS scientific gateways project from XSEDE to include data-intensive use of resources like Wrangler at the Texas Advanced Computing Center (TACC) in the XSEDE network. The lessons learned from this project will be used to bring other XSEDE computing resources to BLASTer in the future and other programs like BLASTer to XSEDE users.","BLAST, BLASTer, DiaGrid, HTC job submission, HUBzero, XSEDE, XSEDE computing resources",1,0,0,1
10.1145/2949550.2949658,User behavior and usage patterns for a highly accessed science gateway,Conference on Extreme Science and Engineering Discovery Environment,2016,Conference Paper,"The CIPRES Science Gateway (CSG) is a public resource created to provide access to community phylogenetics codes on high performance computing resources. The CSG has been in operation since 2009 and has a large and growing user base. As a popular resource, the CSG provides an opportunity to study user behavior and usage patterns in a gateway environment. Here we examine CSG user and data turnover, job submission success rates, and causes for job failures. The results of our investigation provide a better understanding of the populations that use the CSG and point to areas where improvements can be made in meeting user needs and using resources more efficiently.","CIPRES, phylogenetics, science gateways, open source, Usage patterns, User behavior",1,0,0,1
10.1145/2974927.2974962,Cyberinfrastructure as a platform to facilitate effective collaboration between institutions and support collaboratories,ACM SIGUCCS Annual Conference,2016,Conference Paper,"Researchers, scientists, engineers, granting agencies, and increasingly complex research problems have given rise to the scientific ""collaboratory""-large organizations that span many institutions, with individual members working together to explore a particular phenomenon. These organizations require computational resources in order to support analyses and to provide platforms where the collaborators can interact. The XSEDE Community Infrastructure (XCI) group assists campuses in using their own resources and promotes the sharing of those resources in order to create collaboratories improving use of the nation's collective cyberinfrastructure. Currently XCI provides toolkits and training, and collaborates with organizations such as ACI-REF, XSEDE Campus Champions, and the Open Science Grid to identify tools and best practices that support the community. This paper discusses the progress in and barriers to developing a robust collaborative environment where computational resources can be shared.","ACI-REF, big data, Cluster computing, collaboration, collaboratories, Computation institute, Globus, Jetstream, Open science grid, science gateways, XCI, XSEDE",1,0,0,1
10.1145/3086567.3086570,Globus: A case study in software as a service for scientists,Workshop on Scientific Cloud Computing,2017,Conference Paper,"While some properties of SaaS have long been leveraged in science, particularly in science gateways, there is yet to be widespread adoption of SaaS models. For example, few scientific SaaS providers are publicly available, few leverage elastic cloud platforms, and none-with the exception of Globus-implement subscription-based models to recoup operations costs. Globus has employed the SaaS model for seven years and is fast approaching subscription levels that will support long-term sustainability. In this paper we discuss the SaaS paradigm and explore its suitability to scientific domains. We then describe how production Globus SaaS services are implemented, deployed, and operated. © 2017 ACM.","Globus, Research data management, Science as a service",1,0,0,1
10.1145/3093338.3093345,Advancing analysis of high resolution topography using distributed hpc resources in opentopography,Practice and Experience in Advanced Research Computing,2017,Conference Paper,The OpenTopography science gateway provides effcient online access to high resolution topographic data and processing tools for a broad spectrum of research communities. We have integrated XSEDE HPC resources into the OpenTopography processing work-flow to meet the growing demand for more complex and resource intensive algorithms from the wider community. © 2017 Association for Computing Machinery.,"data, HPC, LiDAR, science gateways, software, Topography",1,0,0,1
10.1145/3093338.3093353,Cloud-enabling a collaborative research platform: The gabbs story,Practice and Experience in Advanced Research Computing,2017,Conference Paper,"Modern cyberinfrastructures typically involve tightly integrated compute, storage and web application resources. They also form the basis of science gateways, which add their own science-specific processing or visualization capabilities. While some science gateways are intended as the central resource provider for a certain scientific community, others provide generic capabilities that are intended for further customization at each installation site. However, replicating their setup is a non-Trivial task often involving specific operating system, software package and configuration choices while also requiring allocation of the actual physical computing resources. Cloud computing provides an attractive alternative, simplifying resource provision and enabling reliable replication. We describe our ongoing efforts to cloud-enable a geospatial science gateway hosting general-purpose software building blocks termed GABBs, that provide geospatial data management, analysis, visualization and processing capabilities. We describe the various compute and storage resources and software underlying these building blocks and our automation of the deployment, software installation and configuration of this science gateway on the AmazonWeb Services (AWS) cloud platform. Some of the challenges that were encountered and resolved during this cloud-enabling process are also described. © 2017 Association for Computing Machinery.","cloud computing, cyberinfrastructures, science gateways",1,0,0,1
10.1145/3093338.3093359,Apache airavata sharing service a tool for enabling user collaboration in science gateways,Practice and Experience in Advanced Research Computing,2017,Conference Paper,"Science Gateways provide user environments and a set of supporting services that help researchers make effective and enhanced use of a diverse set of computing, storage, and related resources. Gateways provide the services and tools users require to enable their scientific exploration, which in-cludes tasks such as running computer simulations or per-forming data analysis. Historically gateways have been con-structed to support the workflow of individual users, but collaboration between users has become an increasingly im-portant part of the discovery process. This trend has created a driving need for gateways to support data sharing between users. For example, a chemistry research group may want to run simulations collaboratively, analyze experimental data or tune parameter studies based on simulation output gen-erated by peers, whether as a default capability, or through explicit creation of sharing privileges. As another example, students in a classroom setting may be required to share their simulation output or data analysis results with the in-structor. However most existing gateways (including the pop-ularly used XSEDE gateways SEAGrid, Ultrascan, CIPRES, and NSG), do not support direct data sharing, so users have to handle these collaborations outside the gateway environ-ment. Given the importance of collaboration in current scien-tific practice, user collaboration should be a prime consider-ation in building science gateways. In this work, we present design considerations and implementation of a generic model that can be used to describe and handle a diverse set of user collaboration use cases that arise in gateways, based on gen-eral requirements gathered from the SEAGrid, CIPRES, and NSG gateways. We then describe the integration of this shar-ing service into these gateways. Though the model and the system were tested and used in the context of Science Gate-ways, the concepts are universally applicable to any domain, and the service can support data sharing in a wide varietyof use cases. © 2017 ACM.","apache airavata, CIPRES, collaboration, Groups, NSG, science gateways, SciGaP, SEAGrid, sharing",1,0,0,1
10.1145/3093338.3093360,Sandstone HPC-A domain-general gateway for new HPC users,Practice and Experience in Advanced Research Computing,2017,Conference Paper,"The complexity of high-performance computing (HPC) resources poses many challenges to new users. A number of science gateways have been developed to increase the productivity of novice users by hiding the underlying infrastructure, however these solutions tend not to teach HPC skills that transfer easily outside of the gateway. In this paper we introduce a domain-general gateway, Sandstone HPC, that represents the HPC environment more naturally to novice users by abstracting the command-line interface and providing contextual help. We assess the degree to which Sandstone HPC improves upon the usability of the command-line interface by analyzing the results of a usability study conducted on both environments. We will also detail how the architecture promotes long-Term sustainability and a community-development model. © 2017 ACM.","high-performance computing, User Studies, Web-Based IDE",1,0,0,1
10.1145/3093338.3093361,Performance of image matching in the computational anatomy gateway: CPU and GPU implementations in opencl,Practice and Experience in Advanced Research Computing,2017,Conference Paper,"The Computational Anatomy Gateway is a software as a service tool that provides tools for analysis of structural MRI to the neuroimaging community by calculating diffeomorphic mappings between a user's data and well characterized atlas images. These tools include automatic parcellation of brain images into labeled regions, described by dense 3D arrays; and shape analysis of regions described by triangulated sur-faces, for hypothesis testing in specific populations. We have developed mapping techniques that combine the benefits of working with triangulated surfaces with those of working with dense images, and have been working toward uniting these two tools: To automatically perform shape analysis on each segmented subcortical structure simultaneously. In this work we investigate the performance of our algo-rithm across a wide range of input data, examining the effect of number of voxels in 3D images, number of vertices in tri-Angulated surfaces, and number of structures being mapped onto simultaneously. Further, we investigate the performance of our OpenCL code implemented in two different environ-ments: The Intel OpenCL environment on a CPU, and the CUDA OpenCL environment on a GPU. We identify a range of inputs, generally smaller datasets, for which the CPU out performs the GPU. Finally we show the feasibility of mapping onto all the human gray matter sub-cortical structures simultaneously, and discuss our strategy. © 2017 Copyright is held by the owner/author(s).","Computational anatomy, Dif-feomorphometry, GPU, Neuroimaging, OpenCL, science gateways",1,0,0,1
10.1145/3093338.3093378,A cybergis-jupyter framework for geospatial analytics at scale,Practice and Experience in Advanced Research Computing,2017,Conference Paper,"The interdisciplinary field of cyberGIS (geographic information science and systems (GIS) based on advanced cyberinfrastructure) has a major focus on data-and computation-intensive geospatial analytics. The rapidly growing needs across many application and science domains for such analytics based on disparate geospatial big data poses significant challenges to conventional GIS approaches. This paper describes CyberGIS-Jupyter, an innovative cyberGIS framework for achieving data-intensive, reproducible, and scalable geospatial analytics using the Jupyter Notebook based on ROGER-the first cyberGIS supercomputer. The framework adapts the Notebook with built-in cyberGIS capabilities to accelerate gateway application development and sharing while associated data, analytics and workflow runtime environments are encapsulated into application packages that can be elastically reproduced through cloud computing approaches. As a desirable outcome, data-intensive and scalable geospatial analytics can be efficiently developed and improved, and seamlessly reproduced among multidisciplinary users in a novel cyberGIS science gateway environment. © 2017 Association for Computing Machinery.","computational reproducibility, CyberGIS, Flood mapping, geospatial big data, science gateways",1,0,0,1
10.1145/3093338.3093386,Designsafe: Using elasticsearch to share and search data on a science web portal,Practice and Experience in Advanced Research Computing,2017,Conference Paper,"Designsafe is a web portal focused on helping Natural Hazards Engineering to conduct research. Natural Hazards Research spans across multiple physical locations, where the experiments take place, and multiple disciplines. Sharing and searching data is an imperative feature when doing research in multiple physical locations. We are able to handle the researchers needs by using a distributed database (Elasticsearch) to index important features extracted from data. In this paper, we will explain the problems we encountered when trying to facilitate sharing and searching of data as well as how we solve these problem with the help of Elasticsearch. © 2017 ACM.","data, Elasticsearch, science gateways, Search",1,0,0,1
10.1145/3093338.3093390,COSMIC<sup>2</sup>: A science gateway for cryo-electron microscopy structure determination,Practice and Experience in Advanced Research Computing,2017,Conference Paper,"Structural biology is in the midst of a revolution. Instrumentation and software improvements have allowed for the full realization of cryo-electron microscopy (cryo-EM) as a tool capable of determining atomic structures of protein and macromolecular samples. These advances open the door to solving new structures that were previously unattainable, which will soon make cryo-EM a ubiquitous tool for structural biology worldwide, serving both academic and commercial purposes. However, despite its power, new users to cryo-EM face significant obstacles. One major barrier consists of the handling of large datasets (10+ terabytes), where new cryo-EM users must learn how to interface with the Linux command line while also dealing with managing and submitting jobs to high performance computing resources. To address this barrier, we are developing the COSMIC2 Science Gateway as an easy, web-based, science gateway to simplify cryo-EM data analysis using a standardized workflow. Specifically, we have adapted the successful and mature Cyberinfrastructure for Phylogenetic Research (CIPRES) Workbench [8] and integrated Globus Auth [6] and Globus Transfer [7] to enable federated user identity management and large dataset transfers to Extreme Science and Engineering Discovery Environment's (XSEDE) [1] high performance computing (HPC) systems. With the support of XSEDE's Extended Collaborative Support Services (ECSS) [16] and the Science Gateway Community Institute's (SGCI) Extended Developer Support (EDS), this gateway will lower the barrier to high performance computing tools and facilitate the growth of cryo-EM to become a routine tool for structural biology. © 2017 ACM.","CIPRES, Cryo-electron microscopy, Globus, science gateways, SGCI EDS, XSEDE ECSS",1,0,0,1
10.1145/3093338.3104151,The PHASTA science gateway:web-based execution of adaptive computational fluid dynamics simulations,Practice and Experience in Advanced Research Computing,2017,Conference Paper,"The Parallel Hierarchic Adaptive Stabilized Transient Analysis (PHASTA) software supports modeling compressible or incompressible, laminar or turbulent, steady or unsteady flows in 3D using unstructured grids. PHASTA, coupled with the Parallel Unstructured Mesh Infrastructure (PUMI), supports parallel, automated, adaptive simulation workflows. Researchers can easily execute these workflows on the TACC Stampede Xeon and Knights Landing nodes without being burdened by the details of each system using the PHASTA science gateway (created with Apache Airavata). In addition to abstracting away job execution and filesystem details, the gateway creates a searchable archive of past jobs to support reproducibility. Our poster presents the construction of the PHASTA gateway, the workflows it currently supports, and our ongoing efforts to expand functionality and the user base. © 2017 Copyright held by the owner/author(s).","ACM proceedings, apache airavata, LATEX, science gateways, Text tagging",1,0,0,1
10.1145/3219104.3219109,SciApps: A bioinformatics workflow platform powered by XSEDE and cyverse,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"SciApps1, a lightweight bioinformatics workflow system powered by the CyVerse infrastructure, uses the Agave Science API to manage the entire cycle of analysis jobs between XSEDE HPC and the CyVerse Data Store. SciApps provides a graphical user interface for job submission, workflow creation, and management of both jobs and workflows. Each reproducible workflow, along with all inputs and results, is retrievable with a unique ID. © 2018 Association for Computing Machinery","Agave science API, cloud computing, CyVerse, infrastructure, science gateways, workflows",1,0,0,1
10.1145/3219104.3219123,A cloud-based scientific gateway for internet of things data analytics,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"As inexpensive Internet of Things (IoT) sensors have become widely available, an increasing number of researchers in domains as diverse as the engineering and geosciences, biomedicine, the social sciences, and even the arts have become interested in the insights and creative expression such sensors might enable. At the University of Iowa, we convened a series of meetings at which we posed the following framing question: “What would you do with 10,000, ~$10 sensors?” These discussions identified the clear need for a standard, end-to-end infrastructure for sensor deployment and data collection through data analytics and visualization, one that allowed researchers to focus on research and scholarship rather than infrastructure development. This paper1 describes the development of a suite of wireless sensors and a cloud-based toolkit for data capture, analysis, and visualization, based on Amazon Web Services (AWS), MQTT, and Jupyter notebooks. © 2018 Association for Computing Machinery.","Arduino, AWS, Elasticsearch, Environmental monitoring, Internet of Things, Jupyter, LoRaWAN, MQTT, White Spaces",1,0,0,1
10.1145/3219104.3219139,The neuroscience gateway - Enabling large scale modeling and data processing in neuroscience,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"The NSF funded Neuroscience Gateway (NSG) has been in operation since the early 2013. We originally designed NSG to reduce technical and administrative barriers that exist to using high performance computing resources for computational neuroscientists. In the last two years, in addition to computational neuroscientists, cognitive and experimental neuroscientists are also using NSG. Currently NSG has over 600 registered users and it is steadily growing. Users can access NSG via a web portal and via RESTful programmatic access. A particular usage mode of programmatic access to NSG enables users of community neuroscience projects such as the Open Source Brain, research projects within the European Human Brain Project and others to access HPC resources via NSG without having to obtain their own accounts on NSG. Based on demand and usage, over the last five years we have successfully acquired increasingly larger allocations (millions to ~ten million core hours) on resources of the Extreme Science and Engineering Discovery Environment (XSEDE) program via the competitive peer review process. We will discuss the overall NSG architecture. We implemented NSG from the generic CIPRES science gateway software to create the NSG specifically for the neuroscience community. We will describe the front end user interface, based on web portal and RESTful programmatic access, and the backend architecture. We will discuss how NSG is evolving over time in response to the interests and needs of the neuroscience community, adapting itself to become a dissemination platform for new tools and pipelines, and becoming an environment for modelers and experimentalists to jointly develop models. © 2018 Association for Computing Machinery.","Neuroscience, RESTful programmatic access, science gateways",1,0,0,1
10.1145/3219104.3219141,Building a science gateway for processing and modeling sequencing data via apache airavata,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"The amount of DNA sequencing data has been exponentially growing during the past decade due to advances in sequencing technology. Processing and modeling large amounts of sequencing data can be computationally intractable for desktop computing platforms. High performance computing (HPC) resources offer advantages in terms of computing power, and can be a general solution to these problems. Using HPCs directly for computational needs requires skilled users who know their way around HPCs and acquiring such skills take time. Science gateways acts as the middle layer between users and HPCs, providing users with the resources to accomplish compute-intensive tasks without requiring specialized expertise. We developed a web-based computing platform for genome biologists by customizing the PHP Gateway for Airavata (PGA) framework that accesses publicly accessible HPC resources via Apache Airavata. This web computing platform takes advantage of the Extreme Science and Engineering Discovery Environment (XSEDE) which provides the resources for gateway development, including access to CPU, GPU, and storage resources. We used this platform to develop a gateway for the dREG algorithm, an online computing tool for finding functional regions in mammalian genomes using nascent RNA sequencing data. The dREG gateway provides its users a free, powerful and user-friendly GPU computing resource based on XSEDE, circumventing the need of specialized knowledge about installation, configuration, and execution on an HPC for biologists. © 2018 Association for Computing Machinery.","apache airavata, cloud computing, next generation sequencing, science gateways, Sequencing data, software-as-a-service",1,0,0,1
10.1145/3219104.3219144,Building the SLATE platform,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"We describe progress on building the SLATE (Services Layer at the Edge) platform. The high level goal of SLATE is to facilitate creation of multi-institutional science computing systems by augmenting the canonical Science DMZ pattern with a generic, “programmable"", secure and trusted underlayment platform. This platform permits hosting of advanced container-centric services needed for higher-level capabilities such as data transfer nodes, software and data caches, workflow services and science gateway components. SLATE uses best-of-breed data center virtualization and containerization components, and where available, software defined networking, to enable distributed automation of deployment and service lifecycle management tasks by domain experts. As such it will simplify creation of scalable platforms that connect research teams, institutions and resources to accelerate science while reducing operational costs and development cycle times. © 2018 Association for Computing Machinery.","Containerization, distributed computing, Edge computing",1,0,0,1
10.1145/3219104.3219150,GISandbox: A science gateway for geospatial computing,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"Science gateways provide easy access to domain-specific tools and data. The field of Geographic Information Science and Systems (GIS) uses myriad tools and datasets, which raises challenges in designing a science gateway to meet users' diverse research and teaching needs. We describe a new science gateway called the GISandbox that is designed meet the needs of researchers and educators leveraging geospatial computing, which is situated at the nexus of GIS and computational science. The GISandbox is built on Jupyter Notebooks to create an easy, open, and flexible platform for geospatial computing. Jupyter Notebooks is a widely used interactive computing environment running in the browser that integrates live code, narrative, equations and images. We extend the Jupyter Notebook platform to enable users to run interactive notebooks on the cloud resource Jetstream or computationally-intensive notebooks on the Bridges supercomputer located at the Pittsburgh Supercomputing Center. A novel Job Management platform allows the user to easily submit a Jupyter Notebook for batch execution on Bridges (and eventually Comet), monitor the SLURM job, and retrieve output files. GISandbox Virtual Machines are created in Jetstream's Atmosphere interface and then deployed and configured using a series of Ansible scripts, which allow us to create an easily reproducible and scalable system. This paper outlines our vision for GISandbox, the current implementation, with a discussion looking toward the future and how the GISandbox could be used in other domains. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Geographic Information Systems, GIS, science gateways",1,0,0,1
10.1145/3219104.3219151,Building science gateway infrastructure in the middle of the pacific and beyond: Experiences using the agave deployer and agave platform to build science gateways,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"In order to increase support for diverse projects amongst a wide range of research areas in accessing advanced computational and data resources, both local and national, the University of Hawai'i at Manoa (UH) and the University of Melbourne, Australia (Melbourne) partnered with the Texas Advanced Computing Center (TACC) to utilize the Agave platform. However, due to distance and the unique geographical locations of Hawai'i and Australia it was necessary to setup local Agave platform instances to provide responsive and robust middleware against which flexible science gateways could be constructed. To lower the entry barrier, required staff, and time required to stand up a local infrastructure, UH became the first external site to use the Agave Deployer which provides a combination of DevOps automation tools and containers to deploy and maintain a functional local Agave authentication/authorization, core science, and data persistence API instances. UH worked with TACC on testing the initial release of the Agave Deployer to provision the local UH infrastructure and later assisted Melbourne in adopting the Agave Deployer to stand up their infrastructure. We present the experiences and lessons learned in deploying and developing science gateway infrastructure and applications at these two institutions. © 2018 Copyright is held by the owner/author(s).","ACM proceedings, HPC, science gateways",1,0,0,1
10.1145/3219104.3219159,Clowder: Open source data management for long tail data,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"Clowder is an open source data management system to support data curation of long tail data and metadata across multiple research domains and diverse data types. Institutions and labs can install and customize their own instance of the framework on local hardware or on remote cloud computing resources to provide a shared service to distributed communities of researchers. Data can be ingested directly from instruments or manually uploaded by users and then shared with remote collaborators using a web front end. We discuss some of the challenges encountered in designing and developing a system that can be easily adapted to different scientific areas including digital preservation, geoscience, material science, medicine, social science, cultural heritage and the arts. Some of these challenges include support for large amounts of data, horizontal scaling of domain specific preprocessing algorithms, ability to provide new data visualizations in the web browser, a comprehensive Web service API for automatic data ingestion and curation, a suite of social annotation and metadata management features to support data annotation by communities of users and algorithms, and a web based front-end to interact with code running on heterogeneous clusters, including HPC resources. © 2018 Copyright held by the owner/author(s). Publication rights licensed to the Association for Computing Machinery.","Data curation, data management, linked data, metadata management, scientific gateways",1,0,0,1
10.1145/3219104.3229240,Supporting science gateways using apache airavata and SciGaP services,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"The Science Gateways Platform as a service (SciGaP.org) project provides a rapid development and stable hosting platform for a wide range of science gateways that focus on software as a service. Based on the open source Apache Airavata project, SciGaP services include user management, workflow execution management, computational experiment archiving and access, and sharing services that allow users to share results and other digital artifacts. SciGaP services are multi-tenanted, with clients accessing services through a well-defined, programming language-independent API. SciGaP services can be integrated into web, mobile, and desktop clients. To simplify development for new clients, SciGaP includes the PGA, a generic PHP-based gateway client for SciGaP services that also acts as a reference implementation of the API. Several example gateways using these services are summarized. © 2018 Copyright held by the owner/author(s).","cyberinfrastructures, science gateways, software-as-a-service",1,0,0,1
10.1145/3219104.3229242,Using a science gateway to deliver SimVascular software as a service for classroom instruction,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"SimVascular (http://www.simvascular.org) is open source software enabling users to construct image-based, patient-specific anatomic models and perform realistic blood flow simulation useful in disease research, medical device design, and surgical planning. The software consists of two core executables: a front-end application and a flow solver. The front-end application enables users to create patient-specific anatomic models from imaging data, generate finite-element meshes, prescribe boundary conditions, and set up an analysis. The finite-element based blood flow solver utilizes MPI and is massively scalable. SimVascular has been successfully integrated into graduate level courses on cardiovascular modeling at multiple institutions including Stanford, UC Berkeley, Purdue, and Marquette to introduce state-of-the-art modeling to the students and provide a basis for hands-on projects. While the front-end application can be installed and run on a laptop, the flow solver requires high performance computing (HPC) for realistic problem sizes. This provides a significant challenge for instructors as many students are unfamiliar with HPC, and local resources might be limited or difficult to administer. There is also a need to provide user and group management capabilities for courses: students should authenticate using campus credentials, instructors should be able to access students' work, and students' access to computing allocations should be limited. Our poster will detail an Apache Airavata-based science gateway to address these needs. XSEDE's Comet provides the backend computing power. This approach allows the SimVascular team to provision HPC resources and install and maintain the software providing students access at institutions across the country. The science gateway interface provides access to SimVascular's flow solver, while allowing students to use SimVascular's desktop interfaces. © 2018 Copyright held by the owner/author(s).","ACM proceedings, apache airavata, science gateways",1,0,0,1
10.1145/3219104.3229243,PHASTA science gateway for high performance computational fluid dynamics,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"The Parallel Hierarchic Adaptive Stabilized Transient Analysis (PHASTA) software supports modeling compressible or incompressible, laminar or turbulent, steady or unsteady flows in 3D using unstructured grids. PHASTA has been applied to industrial and academic flows on complex, as-designed geometric models with over one billion mesh elements using upwards of one million compute cores. The PHASTA Science Gateway (phasta.scigap.org) brings these increasingly critical technologies to a larger user base by providing a central hub for simulation execution, simulation data management, and documentation. Researchers and engineers using the gateway can easily define and execute simulations on the TACC Stampede2 Skylake and Knights Landing nodes without being burdened by the details of remote access, the job scheduler, and filesystem configuration. In addition to simplifying the simulation execution process, the gateway creates a searchable archive of past jobs that can be shared with other users to support reproducibility and increase productivity. Our poster presents the construction of the gateway with Apache Airavata, the simulation definition process, applications it currently supports, and our ongoing efforts to expand functionality, the user base, and the community. © 2018 Copyright held by the owner/author(s).","Science Gateways Research Center, apache airavata, CFD, Paralllel Unstructured Mesh, Pervasive Technology Institute, science gateways",1,0,0,1
10.1145/3219104.3229244,A new science gateway to provide decision support on carbon capture and storage technologies,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"Carbon dioxide capture and storage (CCS) is a promising technology for mitigating climate change, and its implementation is considered critical to meeting threshold targets for global warming in the 21st century. We have developed a new science gateway application for the successful modeling software known as SimCCS that is used for evaluating complex, integrated CCS infrastructure. Using the Apache Airavata middleware and high-performance computing resources made available by the Extreme Science and Engineering Discovery Environment, we built the SimCCS Gateway to expand the tool's scalability for decision support and risk assessment. Case studies developed for evaluating a proposed CCS technology at Duke Energy's Gibson Station coal-fired power plant in southwest Indiana demonstrate its improved ability in data analysis as well as risk assessment at various uncertainty levels. Further work is continuing to expand the functionality of both web and desktop clients, and to develop an active user group community in research and industry via the SimCCS Gateway interface. © 2018 Copyright is held by the owner/author(s).","Carbon capture, science gateways",1,0,0,1
10.1145/3219104.3229245,The CSBG - LSU Gateway: Web based hosted gateway for computational system biology application tools from Louisiana state university,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"Science gateways are identified as an effective way to publish and distribute software for research communities without the burden of learning HPC (High Performance Computer) systems. In the past, researchers were expected to have in-depth knowledge about using HPC systems for computations along with their respective science field in order to do effective research. Science gateways eliminate the need to learn HPC systems and allows the research communities to focus more on their science and let the gateway handle communicating with HPCs. In this poster we are presenting the science gateway project of CSBG (Computational System Biology Group - www.brylinski.org) of Department of Biological Sciences with Center for Computation & Technology at LSU (Louisiana State University). The gateway project was initiated in order to provide CSBG software tools as a service through a science gateway. © 2018 Copyright held by the owner/author(s).","apache airavata, bioinformatics, Computational System Biology, science gateways",1,0,0,1
10.1145/3219104.3229252,Simplifying access to campus resources at Southern Illinois University with a science gateway,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"Not all the researchers are comfortable in using High Performance Computing (HPC) Systems. Southern Illinois University's Office of Information Technology (OIT) Research Computing assists our researchers to get on these systems and use them for their research activities. One such potential use case at SIU involves the group of researchers from Life Sciences who were trying to use MaSuRCA [3], a genome-sequencing tool for their research. Although the leaders of this research are well versed in using BigDog [4](SIU's HPC Cluster), other fellow researchers did have issues in using the cluster for their work. It was time to look for efficient ways of enabling them to use the cluster. We examined using Science Gateways which can help our researchers to use the computational cluster without logging on to a Linux-based HPC system. OIT is currently collaborating with the Science Gateways Research Center at Indiana University (IU) on the use of Apache Airavata [1] as a Science Gateway framework for the MaSuRCA user community at SIU. The IU team members provide hosting and operations for Apache Airavata middleware as part of the SciGaP.org project. IU collaborators also provide a basic science gateway user interface, the PGA. The SIU gateway, although hosted off campus, is integrated with SIU's BigDog cluster. © 2018 Copyright is held by the owner/authors(s).","apache airavata, MaSuRCA, science gateways",1,0,0,1
10.1145/3219104.3229265,Science gateway implementation at the University of South Dakota: Applications in research and education,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"Science Gateways are virtual environments that accelerate scientific discovery by enabling scientific communities to more easily and effectively utilize distributed computing and data resources. Successful Science Gateways provide access to sophisticated and powerful resources, while shielding their users from the underlying complexities. Here we present work completed by the University of South Dakota (USD) Research Computing Group in conjunction with the Science Gateways Community Institute (SGCI) [1] and Indiana University on setting up a Science Gateway to access USD's high-performance computing resources. These resources are now available to both faculty and students and allow ease of access and use of USD's distributed computing and data resources. The implementation of this gateway project has been multifaceted and has included placement of federated user login, user facilitation and outreach, and integration of USD's cyberinfrastructure resources. We present this project as an example for other research computing groups so that they may learn from our successes and the challenges that we have overcome in providing this user resource. Additionally, this project serves to exemplify the importance of creating a broad user base of research computing infrastructure through the development of alternative user interfaces such as Science Gateways. © 2018 Copyright held by the owner/author(s).","apache airavata, gateways, Keycloak, SciGaP",1,0,0,1
10.1145/3219104.3229270,Evaluating NextCloud as a file storage for apache airavata,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"Science gateways enable researchers from broad communities to access advanced computing and storage resources. The researchers analyze large amounts of data using the compute resources and the generated results, usually files are saved in the storage. Consider a scenario where a researcher has large output data files of historically run experiments on an external server. If the researcher wants to move the data to the gateway storage, then the only way to do it is through data transfer. This task would be cumbersome and time consuming. The paper discusses an approach through which historic or any data existing on a different server or in a cloud storage (Google Drive) or in an object storage (Amazon S3) can be ingested into the existing gateway without actually transferring it to the server. We discuss about a software called NextCloud and how it can be used as a gateway storage by integrating it with Apache Airavata. Airavata currently uses local file storage to store user related data files. On the client side, Airavata clients use different protocols like HTTP and SFTP for file transfer. NextCloud is an open source file share and communication platform that provides a common file access layer through its universal file access to different data sources. Integrating NextCloud with Airavata could solve the problem of providing unified file transfer API across all the Airavata clients. As NextCloud supports various external storages, its integration with Airavata would also enable the data ingestion and importing large data from different storage sources to Airavata. © 2018 Copyright is held by the owner/author(s).","apache airavata, File Storage, File Transfer, NextCloud, WebDAV",1,0,0,1
10.1145/3219104.3229278,Searching the sequence read archive using Jetstream and Wrangler,Practice and Experience in Advanced Research Computing,2018,Conference Paper,"The Sequence Read Archive (SRA), the world's largest database of sequences, hosts approximately 10 petabases (1016 bp) of sequence data and is growing at the alarming rate of 10 TB per day. Yet this rich trove of data is inaccessible to most researchers: searching through the SRA requires large storage and computing facilities that are beyond the capacity of most laboratories. Enabling scientists to analyze existing sequence data will provide insight into ecology, medicine, and industrial applications. In this project we specifically focus on metagenomic sequences (whole community data sets from different environments). We are developing a set of tools to enable biologists to mine the metagenomes in the SRA using the NSF-funded cloud computing resources, Jetstream and Wrangler. We have developed a proof-of-principle pipeline to demonstrate the feasibility of the approach. We are leveraging our existing infrastructure to enable all scientists to access the SRA metagenomes regardless of their computational ability and are working to create a stable pipeline with a science gateway portal that is accessible to all researchers. © 2018 Copyright held by the owner/author(s).","apache airavata, Bacteriophage, Credential Store, Jetstream, metagenomics, Metagenomics Discovery Challenge, SciGaP, Search SRA, Sequence Read Archive, SRA, SRA Gateway, Wrangler",1,0,0,1
10.1145/3311790.3396621,PEGR: A management platform for ChIP-based next generation sequencing pipelines,Practice and Experience in Advanced Research Computing,2020,Conference Paper,"There has been a rapid development in genome sequencing, including high-throughput next generation sequencing (NGS) technologies, automation in biological experiments, new bioinformatics tools and utilization of high-performance computing and cloud computing. ChIP-based NGS technologies, e.g. ChIP-seq and ChIP-exo, are widely used to detect the binding sites of DNA-interacting proteins in the genome and help us to have a deeper mechanistic understanding of genomic regulation. As sequencing data is generated at an unprecedented pace from the ChIP-based NGS pipelines, there is an urgent need for a metadata management system. To meet this need, we developed the Platform for Eukaryotic Genomic Regulation (PEGR), a web service platform that logs metadata for samples and sequencing experiments, manages the data processing workflows, and provides reporting and visualization. PEGR links together people, samples, protocols, DNA sequencers and bioinformatics computation. With the help of PEGR, scientists can have a more integrated understanding of the sequencing data and better understand the scientific mechanisms of genomic regulation. In this paper, we present the architecture and the major functionalities of PEGR. We also share our experience in developing this application and discuss the future directions. © 2020 ACM.","next generation sequencing pipeline, science gateways, web application",1,0,0,1
10.1145/3311790.3396628,Building Science Gateways for Humanities,Practice and Experience in Advanced Research Computing,2020,Conference Paper,"Building science gateways for humanities content poses new challenges to the science gateway community. Compared with science gateways devoted to scientific content, humanities-related projects usually require 1) processing data in various formats, such as text, image, video, etc., 2) constant public access from a broad audience, and therefore 3) reliable security, ideally with low maintenance. Many traditional science gateways are monolithic in design, which makes them easier to write, but they can be computationally inefficient when integrated with numerous scientific packages for data capture and pipeline processing. Since these packages tend to be single-threaded or nonmodular, they can create traffic bottlenecks when processing large numbers of requests. Moreover, these science gateways are usually challenging to resume development on due to long gaps between funding periods and the aging of the integrated scientific packages. In this paper, we study the problem of building science gateways for humanities projects by developing a service-based architecture, and present two such science gateways: the Moving Image Research Collections (MIRC) - a science gateway focusing on image analysis for digital surrogates of historical motion picture film, and SnowVision - a science gateway for studying pottery fragments in southeastern North America. For each science gateway, we present an overview of the background of the projects, and some unique challenges in their design and implementation. These two science gateways are deployed on XSEDE's Jetstream academic clouding computing resource and are accessed through web interfaces. Apache Airavata middleware is used to manage the interactions between the web interface and the deep-learning-based (DL) backend service running on the Bridges graphics processing unit (GPU) cluster. © 2020 ACM.","Angular, Deep-Learning, humanities, Java Play platform, science gateways",1,0,0,1
10.1145/3311790.3396631,GeoEDF: An Extensible Geospatial Data Framework for FAIR Science,Practice and Experience in Advanced Research Computing,2020,Conference Paper,"Collaborative scientific research is now increasingly conducted online in web-based research platforms termed ""science gateways"". Most science gateways provide common capabilities including data management and sharing, scientific code development, high performance computing (HPC) integration, and scientific workflow execution of varying automation. Despite the availability of scientific workflow frameworks such as Pegasus and workflow definition languages such as the Common Workflow Language (CWL), in practice typical workflows on science gateways still involve a mix of non-reusable code, desktop tools, and intermediate data wrangling. With the growing emphasis on FAIR (Findable, Accessible, Interoperable, Reusable) science, such mixed workflows present a significant challenge to ensuring compliance to these principles. These challenges are further compounded in the earth sciences where researchers spend inordinate amounts of time manually acquiring, wrangling, and processing earth observation data from repositories managed by organizations such as NASA, USGS, etc. Our extensible geospatial data framework, GeoEDF is designed to address these challenges, making remote datasets directly usable in computational code and facilitating earth science workflows that execute entirely in a science gateway. In this paper we describe the design of GeoEDF, current implementation status, and future work. © 2020 ACM.","data framework, FAIR science, geospatial, scientific workflows",1,0,0,1
10.1145/3311790.3396634,Building an Interactive Workbench Environment for Single Cell Genomics Applications,Practice and Experience in Advanced Research Computing,2020,Conference Paper,"We discuss the procedure to build an interactive workbench environment for single cell genomics applications with the Open OnDemand (OOD) science gateway. In our approach, an end-user submits a complex single cell RNA sequencing (scRNA) pipeline, checks the status of the job, and visualizes the output results. All of these tasks are accomplished through a web browser, relieving the users from the complexities involved in developing and handling a large-scale workflow. Our approach helped researchers in processing several input data sets of scRNA in the campus HPC cluster. Although the current work is focused on scRNA analysis, the same approach can be extended for any workflow. © 2020 ACM.","Computational Workbench, science gateways, Single Cell Genomics, user interfaces, Workflow Management Systems",1,0,0,1
10.1145/3311790.3396635,Custos: Security Middleware for Science Gateways,Practice and Experience in Advanced Research Computing,2020,Conference Paper,"Science gateways represent potential targets for cybersecurity threats to users, scientific research, and scientific resources. In this paper, we introduce Custos, a software framework that provides common security operations for science gateways, including user identity and access management, gateway tenant profile management, resource secrets management, and groups and sharing management. The goals of the Custos project are to provide these services to a wide range of science gateway frameworks, providing the community with an open source, transparent, and reviewed code base for common security operations; and to operate trustworthy security services for the science gateway community using this software base. To accomplish these goals, we implement Custos using a scalable microservice architecture that can provide highly available, fault tolerant operations. Custos exposes these services through a language-independent Application Programming Interface that encapsulates science gateway usage scenarios. © 2020 ACM.","apache airavata, custos, cybersecurity, microservices, science gateways, service mesh",1,0,0,1
10.1145/3311790.3396650,An extensible Django-based web portal for Apache Airavata,Practice and Experience in Advanced Research Computing,2020,Conference Paper,"The Apache Airavata science gateway middleware project has developed a new web frontend for the middleware's API based on the Django web framework and the Vue.js JavaScript framework. This new frontend has been designed to be a framework, called the Airavata Django Portal Framework (ADPF) that science gateway developers can use to customize and extend the user interface to add domain specific UI metaphors and to add gateway-specific user workflows. There are three main modes of extensibility: 1) custom scientific application execution configuration, 2) custom application results analysis, and 3) wholly custom user workflows. These modes of extensibility come out of the project's experience working with science gateways over the years. This new framework has been put into production for the 30+ science gateways hosted by the Science Gateways as a Platform (SciGaP) project at Indiana University and several gateways have already made extensions using ADPF. © 2020 ACM.","Django, Python, science gateways, user interfaces, web portals",1,0,0,1
10.1145/3311790.3396651,FutureWater Indiana: A science gateway for spatio-temporal modeling of water in Wabash basin with a focus on climate change,Practice and Experience in Advanced Research Computing,2020,Conference Paper,"In this manuscript, we describe the FutureWater Science Gateway, which simulates regional watersheds spatially and temporally to derive hydrological changes due to changes in critical effectors such as climate, land use and management, and soil conditions. We also discuss the gateway design, creation, and production deployment and how the resulting data is organized and explored. The FutureWater gateway is built based on the Apache Airavata gateway middleware framework and hosted under the SciGaP project at Indiana University. The gateway provides an integrated infrastructure for simulations based on parallelized Soil and Water Assessment Tool (SWAT) and SWAT-MODFLOW software execution on Extreme Science and Engineering Discovery Environment (XSEDE) and Indiana University's (IU's) HPC resources. It organizes data in optimized relational databases and enables intuitive simulation result data exploration. The visualization involves geographical map integration and dynamic data provisioning using the R-Shiny application deployed in the gateway. The gateway provides simple, intuitive user interfaces for providing simulation input data and combines available model data; it makes it possible to set up and execute the simulation on HPC systems and ingest the results into the databases. The portal addresses the needs of diverse stakeholder communities for education, research, exploration, and planning in academic, governmental, and non-governmental organizations. © 2020 ACM.","FutureWater Science Gateway, River basins climate interaction.",1,0,0,1
10.1145/3311790.3396654,A Science Gateway for Simulating the Economics of Carbon Sequestration Technologies: SimCCS2.0,Practice and Experience in Advanced Research Computing,2020,Conference Paper,"The SimCCS2.0 Gateway provides a science gateway for optimizing CO2 capture, transport, and storage infrastructure. We describe the design, creation, and production deployment of this platform, which is based on an Apache Airavata gateway middleware framework. This gateway provides an integrated infrastructure for data, modeling, simulation, and visualization of carbon sequestration technologies and their economics. It does so through simple user interfaces to map and select input data, build models, and set up and execute simulations on high performance computing systems. Also featured are community case studies to use as reference sets for verifying reproducibility of published models and reusing their respective data for modified simulations. The portal addresses the needs of diverse international stakeholders and provides a platform for integrating novel and complex models for carbon sequestration technologies moving into the future. © 2020 ACM.","Carbon Sequestration, SimCCS2.0 Science Gateway",1,0,0,1
10.1145/3311790.3396656,Frontera: The Evolution of Leadership Computing at the National Science Foundation,Practice and Experience in Advanced Research Computing,2020,Conference Paper,"As part of the NSF's cyberinfrastructure vision for a robust mix of high capability and capacity HPC systems, Frontera represents the most recent evolution of trans-petascale resources available to all open science research projects in the U.S. Debuting as the fifth largest supercomputer in the world, Frontera represents a robust and well-balanced HPC system designed to enable large-scale, productive science on day one of operations. The system provides a primary compute capability of nearly 39PF, delivered completely via more than 8,000 dual-socket servers with conventional Intel 8280 (""Cascade Lake"") processors. A unique configuration of both desktop GPUs and advanced floating units from NVIDIA enables both machine learning and scientific workloads, and the system delivers nearly 2TB/s of total filesystem bandwidth with 55 PB of usable Lustre disk-based storage and 3PB of all flash Lustre storage. A Mellanox InfiniBand (IB) interconnect provides very low latency with 100Gbps to each node, and 200Gbps between switches in a fat tree topology with minimal oversubscription for efficient communication, even in jobs that use the full system with complex communication patterns. The system hardware is complemented by a robust set of software services, including Application Programmer Interfaces (APIs) to support an evolving user base that increasingly demands productive access via science gateways and automated workflows, as well as a first-of-its-kind partnership with the three major cloud service providers to create a bridge between ""traditional"" HPC and the cloud infrastructure upon which research increasingly depends. © 2020 ACM.","cyberinfrastructures, HPC, supercomputer, system design",1,0,0,1
10.1145/3311790.3396661,Scientific Data Annotation and Dissemination: Using the 'Ike Wai Gateway to Manage Research Data,Practice and Experience in Advanced Research Computing,2020,Conference Paper,"Granting agencies invest millions of dollars on the generation and analysis of data, making these products extremely valuable. However, without sufficient annotation of the methods used to collect and analyze the data, the ability to reproduce and reuse those products suffers. This lack of assurance of the quality and credibility of the data at the different stages in the research process essentially wastes much of the investment of time and funding and fails to drive research forward to the level of potential possible if everything was effectively annotated and disseminated to the wider research community. In order to address this issue for the Hawai'i Established Program to Stimulate Competitive Research (EPSCoR) project, a water science gateway was developed at the University of Hawaiĝ€i (UH), called the ĝ€ike Wai Gateway. In Hawaiian, ĝ€ike means knowledge and Wai means water. The gateway supports research in hydrology and water management by providing tools to address questions of water sustainability in Hawaiĝ€i. The gateway provides a framework for data acquisition, analysis, model integration, and display of data products. The gateway is intended to complement and integrate with the capabilities of the Consortium of Universities for the Advancement of Hydrologic Science's (CUAHSI) Hydroshare by providing sound data and metadata management capabilities for multi-domain field observations, analytical lab actions, and modeling outputs. Functionality provided by the gateway is supported by a subset of the CUAHSI's Observations Data Model (ODM) delivered as centralized web based user interfaces and APIs supporting multi-domain data management, computation, analysis, and visualization tools to support reproducible science, modeling, data discovery, and decision support for the Hawai'i EPSCoR ĝ€ike Wai research team and wider Hawaiĝ€i hydrology community. By leveraging the Tapis platform, UH has constructed a gateway that ties data and advanced computing resources together to support diverse research domains including microbiology, geochemistry, geophysics, economics, and humanities, coupled with computational and modeling workflows delivered in a user friendly web interface with workflows for effectively annotating the project data and products. Disseminating results for the ĝ€ike Wai project through the ĝ€ike Wai data gateway and Hydroshare makes the research products accessible and reusable. © 2020 Owner/Author.","annotation, data, datasets, discovery, dissemination, FAIR",1,0,0,1
10.1145/3311790.3397342,Atomic and Molecular Scattering Applications in an Apache Airavata Science Gateway,Practice and Experience in Advanced Research Computing,2020,Conference Paper,"We document recent progress made in the development and deployment of a science gateway for atomic and molecular physics (AMP) [10]. The molecular scattering applications supported in the gateway and the early phase of the project were described in a preliminary report [33]. Here, we present recent advances in both the platform's capabilities and in its adoption for additional software suites and new possibilities for further development. The past year has seen substantial progress, with the addition of two new software suites and additional authors. A very successful workshop, supported by the MOLSSI, NSF, and NIST, was held at NIST from Dec 11-13, 2019. The agenda contained discussions of the science as well as demonstrations of the codes both in production and learning modes. More than 30 scientists participated in the workshop. Over the past few months, the number of registered gateway users has grown to over 60. The applications being deployed provide users with a number of state-of-the-art computational techniques to treat electron scattering from atomic and molecular targets, as well as the interaction of radiation with such systems. One may view all of these approaches as generalized close-coupling methods, where the inclusion of electron correlation is accomplished via the addition of generalized pseudostates. A number of the methods can also be employed to compute high-quality bound-state wave functions by closing the channels and imposing exponentially decaying boundary conditions. The application software suites are deployed on a number of NSF and DoE supercomputing systems. These deployments are brought to the user community through the science gateway with user interfaces, post-processing, and visualization tools. Below we outline our efforts in deploying the Django web framework for the AMPGateway using the Apache Airavata gateway middleware, discuss the new advanced capabilities available, and provide an outlook for future directions for the gateway and the AMP community. © 2020 ACM.","Atomic and Molecular Physics, Light-Matter Interaction, science gateways",1,0,0,1
10.1145/3311790.3399617,Online Single-cell RNA-seq Data Denoising with Transfer Learning,Practice and Experience in Advanced Research Computing,2020,Conference Paper,"Single-cell RNA sequencing (scRNA-seq) technology brings in unprecedented opportunities to new findings in fields including immunology, neuroscience and cancer research. However, the data is still very noisy and suffers from low capture rates. We develop an open-to-public gateway where users can perform online data denoising to improve the quality of their single-cell RNA sequencing datasets. Our gateway can provide a free, convenient, fast and reliable parallel computation platform to handle more than 50K cells at one time. The gateway is based on SAVER-X, a computational and statistical tool that combines deep autoencoder with Bayesian inference for scRNA-seq denoising, and features transfer learning from relevant public datasets. It allows general users and clinicians to improve their data quality without seeking additional computational resources or statistical training, thus would benefit researchers with a wide range of backgrounds. © 2020 ACM.","Bayesian analysis, neural networks, science gateways, single-cell transcriptomics",1,0,0,1
10.1145/3311790.3399623,Secure XSEDE Information APIs,Practice and Experience in Advanced Research Computing,2020,Conference Paper,"Modern research increasingly relies on network accessible data, execution, security, and information access digital services. These services often provide web based user interfaces and Application Programming Interfaces (APIs). By invoking APIs software developers can create increasingly advanced research enhancing digital services. For example, researchers can access Science Gateways and Portals using a web browser to do analysis, simulations, machine learning, and visualizations that seamlessly combines gateway functionality with remote API accessible digital services. XSEDE's Mission is to ""Substantially enhance the productivity of a growing community of scholars, researchers, and engineers through access to advanced digital services that support open research; and coordinate and add significant value to the leading cyberinfrastructure resources funded by the NSF and other agencies."". The XSEDE Cyberinfrastructure Integration (XCI) team's mission is to ""integrate, adapt, and disseminate software tools and related services across the national CI community... and to enable the creation of an integrated national cyberinfrastructure."" XCI introduces two new secure XSEDE information access APIs and propose that the OAuth 2.0 API security they use can accelerate development of powerful research enhancing digital services by breaking down services-to-service interactions barriers. © 2020 ACM.","globus auth, oauth, secure api, XSEDE",1,0,0,1
10.1145/3311790.3399625,Neuroscience Gateway Enabling Large Scale Modeling and Data Processing in Neuroscience Research,Practice and Experience in Advanced Research Computing,2020,Conference Paper,"The Neuroscience Gateway (NSG) has been serving the computational neuroscience community over seven years since its inception in early 2013. It has fulfilled its original goal of catalyzing progress in computational neuroscience by reducing technical and administrative barriers that neuroscientists face in accessing and using high performance computing (HPC) resources needed for large scale neuronal modeling projects involving tools and software which require and run efficiently on HPC resources of XSEDE (Extreme Science and Engineering Discovery Environment). In recent years, in addition to computational neuroscientists, growing numbers of experimentalists such as cognitive neuroscientists, psychologists, biomedical researchers, physicists and electrical engineers are increasingly interested in using NSG for their neuroscience data processing and analysis needs. We also notice an expanding use of machine/deep learning approaches in neuroscience research. To accommodate the needs of these types of data processing and machine/deep learning workloads NSG is adding new cyberinfrastructure (CI) capabilities, features and resources. Large scale computational workloads that are focused on processing and analysis of brain image data and machine learning require high throughput computing (HTC) resources than HPC, utilize commercial cloud and GPUs, and use various data functionalities, such as ability to transfer/store large data to/on NSG, validate the data, process same data by multiple users on NSG provided compute resources, publish final data products, visualize the data, search the data etc. Until now, NSG has primarily been a resource for neuroscience users who use NSG for their computational neuroscience work and, more recently, data processing workloads. But recently there is a demand from the neuroscience community to make NSG an environment where neuroscience tool developers can test, benchmark, and scale their newly developed tools and eventually disseminate their tools via the NSG for neuroscience users. In this short poster-paper we will show (i) how NSG has been successfully serving primarily the computational neuroscience community, as well as some data processing focused neuroscience researchers, until now, (ii) how we plan NSG to be a tool developers environment in addition to it already successfully being a science gateway for the neuroscience community and (iii) how NSG is transforming to accommodate more data processing and machine learning oriented neuroscience users. © 2020 ACM.","clouds, data processing, HPC, HTC, Neuroscience, science gateways",1,0,0,1
10.1145/3311790.3400853,TopPIC Gateway: A Web Gateway for Top-Down Mass Spectrometry Data Interpretation,Practice and Experience in Advanced Research Computing,2020,Conference Paper,"Top-down mass spectrometry-based proteomics has become the method of choice for identifying and quantifying intact proteoforms in biological samples. We present a web-based gateway for TopPIC suite, a widely used software suite consisting of four software tools for top-down mass spectrometry data interpretation: TopFD, TopPIC, TopMG, and TopDiff. The gateway enables the community to use heterogeneous collection of computing resources that includes high performance computing clusters at Indiana University and virtual clusters on XSEDE's Jetstream Cloud resource for top-down mass spectral data analysis using TopPIC suite. The gateway will be a useful resource for proteomics researchers and students who have limited access to high-performance computing resources or who are not familiar with interacting with server-side supercomputers. © 2020 ACM.","apache airavata, Proteomics, science gateways, SciGaP, Top-down mass spectrometry, XSEDE",1,0,0,1
10.1145/3311790.3401777,SLATE: Monitoring Distributed Kubernetes Clusters,Practice and Experience in Advanced Research Computing,2020,Conference Paper,"The SLATE (Services Layer at the Edge) accelerates collaborative scientific computing through a secure container orchestration framework focused on the Science DMZ, enabling creation of advanced multi-institution platforms and novel science gateways. The goal of the SLATE project is to provide a secure federation platform to simplify deployment and operation of complex and often specialized services required by multi-institution scientific collaborations, utilizing where applicable open source, cloud native tooling such as Kubernetes. This paper outlines the design and operation of a monitoring infrastructure suitable for application developers and resource providers which gives visibility to resource utilization and service deployments across a network of independently managed Kubernetes clusters. © 2020 ACM.","Containerization, distributed computing, Distributed Monitoring, Edge computing",1,0,0,1
10.1145/3332186.3332191,"GenApp, containers and ABACO",Practice and Experience in Advanced Research Computing,2019,Conference Paper,"GenApp is an NSF-funded framework for rapid generation of applications including feature rich science gateways. GenApp is being successfully used to produce science gateways wrapping scientific programs. Its organization is designed to simplify the process of adding new features and capabilities to generated applications. A limited set of definition files define application generation. To bring a new executable into GenApp, one creates a single “module” definition file. The executable must run on some compute resource accessible by the generated application. Installations of the executable on target resources may be complex. To simplify portability of execution, we introduce automatic containerization of defined modules and integration of container execution. Abaco is an NSF-funded web service and distributed computing platform providing functions-as-a-service (FaaS) to the research computing community. Abaco implements functions using the Actor Model of concurrent computation. We introduce GenApp integration of execution with Abaco as a resource. © 2019 Association for Computing Machinery.","Actor, containers, science gateways",1,0,0,1
10.1145/3332186.3332221,Web of trust tool for gateway user vetting,Practice and Experience in Advanced Research Computing,2019,Conference Paper,"The Neuroscience Gateway (NSG) is a science gateway that provides neuroscience researchers with tools on National Science Foundation high performance computing (HPC) platforms. The capability of NSG to accept not just static data for processing, but also user code to be compiled and executed, requires a user vetting process. In order to provide an automated and distributed mechanism for this process, a web of trust tool, consisting of GNU Privacy Guard (GPG) and helper scripts in newLISP and Expect were developed. © 2019 Association for Computing Machinery.","Neuroscience, science gateways, Web of trust",1,0,0,1
10.1145/3332186.3332230,Leveraging elasticsearch to improve data discoverability in science gateways,Practice and Experience in Advanced Research Computing,2019,Conference Paper,"Data discoverability is a challenge in science gateway architectures. As the volume of data managed and shared through a science gateway grows, it is imperative to expose a search functionality which enables users to quickly navigate to files within their own data sets as well as to identify relevant files in shared or public data sets. Desirable qualities in a file search feature include scalability to arbitrary data sizes, rapid and responsive indexing triggered by user activity, and easy maintainability by development teams without specialist knowledge of search algorithms. We describe a search architecture built around Elasticsearch that meets each of these criteria, and which has been successfully implemented at the Texas Advanced Computing Center to enhance data discoverability in several science gateway projects. © 2019 Association for Computing Machinery.","Elasticsearch, science gateways",1,0,0,1
10.1145/3332186.3332238,Hubzero®: Novel concepts applied to established computing infrastructures to address communities’ needs,Practice and Experience in Advanced Research Computing,2019,Conference Paper,"The science gateway framework HUBzero® has been enhanced and further developed since its initial vision in 1996 – always driven by requirements of the diverse communities applying HUBzero® for their research. HUBzero® is part of a computational landscape that has never evolved as fast as in the last decade. Novel frameworks and concepts on the user interface side such as Javascript libraries and Jupyter notebooks support communities in their working environment with easy-to-use user interfaces while novel technologies and concepts in the backend allow for effective and efficient modeling, simulations and processing research tools and data. HUBzero®’s enhancements include extensions for BOINC and XSEDE infrastructures on the backend while offering interactive computations and analytical tools via Jupyter Notebooks, RStudio, and other web applications as publishing environments. The paper goes into detail for novel developments for the three use cases Purdue University Research Repository (PURR), nanoHUB and MyGeoHub. First, PURR has been extended to utilize the enhanced data storage service Data Depot and high-speed networks of the Purdue local campus infrastructure. Second, nanoHUB offers over 500 simulation tools and it has been enhanced with a novel caching system to explore the input parameter space for already computed results via BOINC. The third extension is concerned with builtin features for geospatial data and modeling in MyGeoHub that offers to execute compute-intensive tasks on XSEDE. The diverse extensions can be reused in various hubs developed with HUBzero® requiring such diverse features and accessing different distributed computing infrastructures. © 2019 Copyright is held by the owner/author(s). Publication rights licensed to ACM.","BOINC, HUBzero, Jupyter, MyGeoHub, NanoHUB, PURR, science gateways, XSEDE",1,0,0,1
10.1145/3332186.3332252,Enabling real-time user interaction for decision support: Experiences extending a local agave platform metadata service,Practice and Experience in Advanced Research Computing,2019,Conference Paper,"The University of Hawai‘i Information Technology Services Cyberinfrastructure team in partnership with the United States Geological Survey developed the Hawai‘i groundwater recharge tool, a decision support tool, as part of the ‘Ike Wai Gateway to support water sustainability research for the state of Hawai‘i. To enable the development of the tool within the existing University of Hawai‘i Agave platform that the ‘Ike Wai Gateway is built on, the Metadata application programmatic interface (API) and Agave infrastructure needed to be extended to store and retrieve spatial data and handle a larger number of requests. The development team successfully added the functionality to the local University of Hawai‘i Agave platform instance to support the storage of deserialized vector data and metadata that can be spatially queried across hundreds of thousands of records to enable decision support applications within a science gateway. © 2019 Association for Computing Machinery.","Agave, Decision support, gateways, Spatial",1,0,0,1
10.1145/3332186.3333050,Serverless Science Gateway Development for Ca2<sup>+</sup> binding site prediction on Amazon Web Services: Case study,Practice and Experience in Advanced Research Computing,2019,Conference Paper,"In this paper we discuss the development of a science gateway; identifying Ca2+ binding sites in proteins using a java application developed by Dr. Jenny Yang at the Chemistry department, Georgia State University. Starting with a Protein Data Bank (PDB) X-ray or NMR structure file, MUGC application predicts calcium binding sites using a graph theory-based algorithm [1]. The project creates a science gateway to provide access to the MUGC algorithm using tools provided by Amazon Web Services. The full-stack solution uses S3 storage, AWS Lambda functions, and API gateway to relay the PDB files to the back-end computing in EC2. Architecture for a full stack serverless processing pipeline is implemented which allows users to access the application. The design is optimized for scalability, reliability, security, performance, and cost. © 2019 Association for Computing Machinery.","Ca+ binding cite Prediction, cloud computing, science gateways",1,0,0,1
10.1145/3332186.3333052,Reproducible hydrological modeling with CyberGIS-Jupyter: A case study on summa,Practice and Experience in Advanced Research Computing,2019,Conference Paper,"CyberGIS-Jupyter is a cyberGIS framework for achieving data-intensive, reproducible, and scalable geospatial analytics using Jupyter Notebook based on advanced cyberinfrastructure. As a cutting-edge hydrological modeling framework, the Structure for Unifying Multiple Modeling Alternative (SUMMA) functions as a unified approach to process‐based modeling. The purpose of this research is to investigate the feasibility of coupling CyberGIS-Jupyter with SUMMA to realize reproducible hydrological modeling. CyberGIS-Jupyter is employed to systematically integrate advanced cyberinfrastructure, including two high-performance computers – Virtual ROGER and XSEDE Comet, data management, and execution and visualization of SUMMA-based modeling. By taking advantage of CyberGIS-Jupyter, users can easily tune different parameters for a SUMMA model and submit computational jobs for executing the model on HPC resources without having to possess in-depth technical knowledge about cyberGIS or cyberinfrastructure. Computational experiments demonstrate that the integration of CyberGIS-Jupyter and SUMMA achieves a high-performance and easy-to-use implementation for reproducible SUMMA-based hydrological modeling. © 2019 Association for Computing Machinery.","CyberGIS-Jupyter, Geographic Information Science and Systems (GIS), high-performance computing, Hydrological Modeling, science gateways",1,0,0,1
10.1145/3332186.3333157,A lightweight framework for research data management,Practice and Experience in Advanced Research Computing,2019,Conference Paper,"We describe a framework for managing live research data involving two major components. First, a system for the scalable scheduling and execution of automated policies for moving, organizing, and archiving data. Second, a system for managing metadata to facilitate curation and discovery with minimal change to existing workflows. Our approach is guided by four main principles: 1) to be non-invasive and to allow for easy integration into existing workflows and computing environments; 2) to be built on established, cloud-aware, open-source tools; 3) to be easily extensible and configurable, and thus, adaptable to different academic disciplines; and 4) to integrate with and take advantage of infrastructure and services available on academic campuses and research computing environments. These principles give our solution a well-defined place along the spectrum of research data management software such as sophisticated electronic lab notebooks and science gateways. Our lightweight and flexible data management framework provides for curation and preservation of research data within a lab, department or university cyberinfrastructure. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Data curation, data management, Data policies, metadata management",1,0,0,1
10.1145/3332186.3333253,Interactwel science gateway for adaptation planning in food-energy-water sectors of local communities,Practice and Experience in Advanced Research Computing,2019,Conference Paper,"Since their inception in mid 2000s, adoption of Science Gateways as interfaces and conduits for digital infrastructure needed in science and engineering research and education has significantly increased. This trend has also driven changes in the types of services and resources that are now being expected from the Science Gateways by a growing group of diverse end users. In this poster, we present a novel Science Gateway, InterACTWEL (Interactive Adaptation and Collaboration Tool for managing Water, Energy and Land), which serves as a research cyberinfrastructure as well as an applied decision support system for adaptive natural resources management in interdependent food, energy, and water sectors. End users of this gateway include not only interdisciplinary technical and social science researchers, but also public and private sectoral stakeholders. The gateway is a collaboration between Oregon State University and Science Gateways Research Center, Pervasive Technology Institute at Indiana University, and is addressing challenges and solutions related to computational services, visualization techniques, advanced software applications, collaboration capabilities, cyber security and privacy, and data repositories unique to food-energy-water sectors and their stakeholders. © 2019 Copyright is held by the owner/author(s). ACM","Adaptation Planning, apache airavata, Food-Energy-Water Nexus, InterACTWEL, SciGaP",1,0,0,1
10.1145/3332186.3333254,The USD science gateway: A bridge between research and advanced computing,Practice and Experience in Advanced Research Computing,2019,Conference Paper,"Science Gateways are virtual environments that accelerate scientific discovery by enabling scientific communities to more easily and effectively utilize distributed computing and data resources. Successful Science Gateways provide access to sophisticated and powerful resources, while shielding their users from the underlying complexities. Here we present updated work completed by the University of South Dakota (USD) Research Computing Group in conjunction with the Science Gateways Community Institute (SGCI) [1] and Science Gateways Research Center at Indiana University to set up a Science Gateway to access USD’s high-performance computing resources. We also introduce improvements to the system since the previous presentation of our work. These resources are now available to both faculty and students and allow ease of access and use of USD’s distributed computing and data resources. The implementation of this gateway project has been multifaceted and has included placement of federated user login, user facilitation and outreach, and integration of USD’s cyberinfrastructure resources. We present this project as an example for other research computing groups so that they may learn from our successes and the challenges that we have overcome in providing this user resource. Additionally, this project serves to exemplify the importance of creating a broad user base of research computing infrastructure through the development of alternative user interfaces such as Science Gateways. © 2019 Copyright is held by the owner/author(s). Publication rights licensed to ACM.","apache airavata, gateways, Keycloak, SciGaP",1,0,0,1
10.1145/3332186.3333259,LSU computational system biology gateway for education,Practice and Experience in Advanced Research Computing,2019,Conference Paper,"Science gateways are a mechanism for delivering scientific software as a service, especially when the software requires high performance computing (HPC) resources to run effectively. The existence of a science gateway eliminates the user’s need to learn to work with HPC systems and to manage software installations and updates. With well-designed user interfaces, users can more quickly become effective users of scientific applications and can manage information needed for replicating, modifying, and sharing results. All of these efficiency gains enable users to focus more on their research. In addition, science gateways are being identified as an effective educational tool, a tool to be used in classroom environments as a method to get students quickly into research on domain specific questions. In the absence of a science gateway, students are likely to need a considerable time to learn to work with HPC systems, and any time spent on such will reduce their time on the actual science. This poster presents how the Louisiana State University (LSU) gateway for the Computational System Biology Group (CSBG) - (www.brylinski.org) was updated and improved to be a classroom teaching tool. This work makes extensive use of Apache Airavata’s group management capabilities. © 2019 Copyright held by the owner/author(s).","apache airavata, bioinformatics, education, science gateways",1,0,0,1
10.1145/3332186.3333260,The distant reader - Tool for reading,Practice and Experience in Advanced Research Computing,2019,Conference Paper,"The Distant Reader science gateway can be used to automatically create and analyze text corpora at a scale of thousands of user-supplied documents. These processing steps are deployed on a dynamic virtual cluster deployed on XSEDE’s Jetstream academic cloud computing resource and are accessed through a Web interface. The science gateway uses Apache Airavata middleware to manage the interactions between the Web interface and the virtual clusters. The gateway leverages the Science Gateway Platform as a service (SciGaP) infrastructure at Indiana University, which provides user authentication, authorization, and identity management as well as access to the Distant Reader tools. The Distant Reader is designed to assist in the process of using & understanding corpora – reading. © 2019 Association for Computing Machinery.","apache airavata, cloud computing, Distant Reader, education, Library, science gateways, SciGaP, Study Carrels, text analysis, URL, Virtual Clusters, XSEDE",1,0,0,1
10.1145/3437359.3465576,Common Resource Descriptions for Interoperable Gateway Cyberinfrastructure,ACM International Conference Proceeding Series,2021,Conference Paper,"Science gateway projects face challenges utilizing the vast and heterogeneous landscape of powerful cyberinfrastructure available today, and interoperability across technologies remains poor. This interoperability issue leads to myriad problems: inability to bring multiple heterogeneous specialized resources together to solve problems where different resources are optimized for different facets of the problem; inability to choose from multiple resources on-the-fly as needed based on characteristics and available capacity; and ultimately a less than optimal application of nationally-funded resources toward advancing science. This paper presents version 1.0 of the Science Gateways Community Institute (SGCI) Resource Description Specification - a schema providing a common language for describing storage and computing resources utilized by science gateway technologies - as well as an Inventory API and software development kits for incorporating resource definitions into gateway projects. We discuss multiple gateway integration design options, with trade offs regarding robustness and availability. We detail the adoption to date of the SGCI Resource Specification by several prominent projects, including Apache Airavata, HUBzero®, Open OnDemand, Tapis, and XSEDE the XSEDE adoption is worth highlighting explicitly as it has led to a new API within the XSEDE Information Services architecture which provides SGCI resource descriptions of all active XSEDE resources. Additionally, we show how the use of the SGCI Resource Specification provides interoperability across resource providers and projects that adopt it. Finally, as a proof of concept, we present a multi-step analysis that runs Quantum ESPRESSO and visualizes the energy band structures of a Gallium Arsenide (GaAs) crystal across multiple resource providers including the Halstead cluster at Purdue University and the Stampede2 supercomputer at TACC. © 2021 ACM.","cyberinfrastructures, interoperability, resource description, science gateways community institute",1,0,0,1
10.1145/3437359.3465579,A Vision for Science Gateways: Bridging the Gap and Broadening the Outreach,ACM International Conference Proceeding Series,2021,Conference Paper,"The future for science gateways warrants exploration as we consider the possibilities that extend well beyond 'science' and high-performance computing into new interfaces, applications and user communities. In this paper, we look retrospectively at the successes of representative gateways thus far. This serves to highlight existing gaps gateways need to overcome in areas such as accessibility, usability and interoperability, and in the need for broader outreach by drawing insights from technology adoption research. We explore two particularly promising opportunities for gateways - computational social sciences and virtual reality - and make the case for the gateway community to be more intentional in engaging with users to encourage adoption and implementation, especially in the area of educational usage. We conclude with a call for focused attention on legal hurdles in order to realize the full future potential of science gateways. This paper serves as a roadmap for a vision of science gateways in the next ten years. © 2021 Owner/Author.","impact, interoperability, science gateways, usability, user community, vision",1,0,0,1
10.1145/3437359.3465595,"The LROSE Science Gateway: One-Stop Shop for Weather Data, Analysis, and Expert Advice",ACM International Conference Proceeding Series,2021,Conference Paper,"Nexrad data along with software to convert between binary formats, perform quality control, analyze, and visualize the data are all public and open for access and download. What is missing is the knowledge of how to use the available components with reproducible results. A science gateway provides a web-based platform to bring all the components together. Where a novice can learn from experts, and where expert researchers can customize software tools for atmospheric science. © 2021 ACM.","apache airavata, atmospheric science, cloud computing, LiDAR, Nexrad, radar, science gateways, software-as-a-service",1,0,0,1
10.1145/3437359.3465609,DELTA-Topology: A Science Gateway for Experimental and Computational Chemical Data Analysis using Topological Models,ACM International Conference Proceeding Series,2021,Conference Paper,"Chemical data are diverse and complex, spanning point cloud data and manifolds, and occurring with potentially large dimensions they are obtained from experimental and computational modeling, and may encode complex correlations of particle/molecular configurations and dynamic motion. It is a significant challenge to identify such correlations, reduce dimensionality, and identify the shapes and topologies of both point cloud data and chemistry-derived surfaces (e.g., energy landscapes of chemical transformation). Chemical graph theory and computational topology offer powerful new tools for the chemistry community, however, dissemination and implementation of the tools' associated algorithms and methods has been hampered by a lack of supporting infrastructure. In this manuscript, we describe the DELTA Science Gateway, which integrates several types of mathematical and topological analysis software for chemical data analysis the focus is on energy landscape data derived from experimental and computational modeling techniques in order to understand the principles involved in structure and function the DELTA gateway is hosted under the SciGaP project at Indiana University and is powered by Apache Airavata gateway middleware framework the gateway provides an integrated infrastructure for simulations and analysis on XSEDE resources, as well as interactive access through a VNC client and a JupyterHub deployed on the Jetstream cloud using virtual clusters. © 2021 ACM.","Dimensionality reduction, Harnessing Chemical Data, Interactive visualization, science gateways",1,0,0,1
10.1145/3459637.3481898,CADRE: A Cloud-Based Data Service for Big Bibliographic Data,ACM International Conference on Information & Knowledge Management,2021,Conference Paper,"Large bibliographic data sets hold the promise of revolutionizing the scientific enterprise when combined with state-of-the-science computational capabilities. Providing high-quality data services for large network datasets such as the Microsoft Academic Graph, which contains more than two billion citation links, poses significant difficulties for universities. Data systems based on the property graph model are capable of delivering efficient graph query services for large networks. However, real-life queries often combine multiple types of data models. To satisfy the needs of different user groups, we developed and deployed a cloud-based data system consisting of scalable graph and text-indexed query engines. For non-expert users, the property graph model also presents a technological barrier. To alleviate the steep learning curve, we designed an intuitive graphical user interface for query-building. For advanced users, a scalable notebook service in our platform provides a more flexible computing environments where the query results can be further analyzed. These systems form the data-backbone of the Collaborative Archive and Data Research Environment (CADRE), which provides efficient and high-quality bibliographic data services to eleven large public universities in North America. © 2021 ACM.","cloud platform, computational reproducibility, data sharing, graph database, science gateways",1,0,0,1
10.1186/1471-2105-14-S9-S3,PoPLAR: Portal for petascale lifescience applications and research,BMC Bioinformatics,2013,Article,"Background: We are focusing specifically on fast data analysis and retrieval in bioinformatics that will have a direct impact on the quality of human health and the environment. The exponential growth of data generated in biology research, from small atoms to big ecosystems, necessitates an increasingly large computational component to perform analyses. Novel DNA sequencing technologies and complementary high-throughput approaches--such as proteomics, genomics, metabolomics, and meta-genomics--drive data-intensive bioinformatics. While individual research centers or universities could once provide for these applications, this is no longer the case. Today, only specialized national centers can deliver the level of computing resources required to meet the challenges posed by rapid data growth and the resulting computational demand. Consequently, we are developing massively parallel applications to analyze the growing flood of biological data and contribute to the rapid discovery of novel knowledge.Methods: The efforts of previous National Science Foundation (NSF) projects provided for the generation of parallel modules for widely used bioinformatics applications on the Kraken supercomputer. We have profiled and optimized the code of some of the scientific community's most widely used desktop and small-cluster-based applications, including BLAST from the National Center for Biotechnology Information (NCBI), HMMER, and MUSCLE; scaled them to tens of thousands of cores on high-performance computing (HPC) architectures; made them robust and portable to next-generation architectures; and incorporated these parallel applications in science gateways with a web-based portal.Results: This paper will discuss the various developmental stages, challenges, and solutions involved in taking bioinformatics applications from the desktop to petascale with a front-end portal for very-large-scale data analysis in the life sciences.Conclusions: This research will help to bridge the gap between the rate of data generation and the speed at which scientists can study this data. The ability to rapidly analyze data at such a large scale is having a significant, direct impact on science achieved by collaborators who are currently using these tools on supercomputers. © 2013 Rekapalli et al.; licensee BioMed Central Ltd.","file system, Parallel Application, Master Node, science gateways, Domain Match",1,0,0,1
10.1186/s40064-016-2914-x,Developing science gateways for drug discovery in a grid environment,SpringerPlus,2016,Article,"Background: Methods for in silico screening of large databases of molecules increasingly complement and replace experimental techniques to discover novel compounds to combat diseases. As these techniques become more complex and computationally costly we are faced with an increasing problem to provide the research community of life sciences with a convenient tool for high-throughput virtual screening on distributed computing resources. Results: To this end, we recently integrated the biophysics-based drug-screening program FlexScreen into a service, applicable for large-scale parallel screening and reusable in the context of scientific workflows. Conclusions: Our implementation is based on Pipeline Pilot and Simple Object Access Protocol and provides an easy-to-use graphical user interface to construct complex workflows, which can be executed on distributed computing resources, thus accelerating the throughput by several orders of magnitude. © 2016, The Author(s).","drug discovery, FlexScreen, high-performance computing, science gateways, virtual screening",1,0,0,1
10.1515/jib-2017-0075,MIRATE: MIps RATional dEsign Science Gateway,Journal of Integrative Bioinformatics,2018,Article,"Molecularly imprinted polymers (MIPs) are high affinity robust synthetic receptors, which can be optimally synthesized and manufactured more economically than their biological equivalents (i.e. antibody). In MIPs production, rational design based on molecular modeling is a commonly employed technique. This mostly aids in (i) virtual screening of functional monomers (FMs), (ii) optimization of monomer-template ratio, and (iii) selectivity analysis. We present MIRATE, an integrated science gateway for the intelligent design of MIPs. By combining and adapting multiple state-of-the-art bioinformatics tools into automated and innovative pipelines, MIRATE guides the user through the entire process of MIPs' design. The platform allows the user to fully customize each stage involved in the MIPs' design, with the main goal to support the synthesis in the wet-laboratory. Availability: MIRATE is freely accessible with no login requirement at http://mirate.di.univr.it/. All major browsers are supported.","docking, molecularly imprinted polymers, science gateways",1,0,0,1
10.1587/transinf.E97.D.1953,EDISON Science gateway: A cyber-environment for domain-neutral scientific computing,IEICE Transactions on Information and Systems,2014,Conference Paper,"We discuss a new high performance computing service (HPCS) platform that has been developed to provide domain-neutral computing service under the governmental support from ""EDucation-research Integration through Simulation On the Net"" (EDISON) project. With a first focus on technical features, we not only present in-depth explanations of the implementation details, but also describe the strengths of the EDISON platform against the successful nanoHUB.org gateway. To validate the performance and utility of the platform, we provide benchmarking results for the resource virtualization framework, and prove the stability and promptness of the EDISON platform in processing simulation requests by analyzing several statistical datasets obtained from a three-month trial service in the initiative area of computational nanoelectronics. We firmly believe that this work provides a good opportunity for understanding the science gateway project ongoing for the first time in Republic of Korea, and that the technical details presented here can be served as an useful guideline for any potential designs of HPCS platforms. Copyright © 2014 The Institute of Electronics, Information and Communication Engineers.","computational science, High performance computing service (HPCS), science gateways, Technology computer-aided design (TCAD) simulations",1,0,0,1
10.22323/1.153.0039,A data engine for science gateways: Enabling easy data transfer and sharing,The International Symposium on Grids and Clouds,2012,Conference Paper,"Grid infrastructures allow users to access and use computational and storage facilities distributed in different locations around the world. Science Gateways (SG) are recently emerging as high-level web environments that ease Grid access and use. However, although SGs simplify job management, providing a web interface by which jobs can be submitted with a few ""clicks"", their capabilities to do an effective and intuitive data management are still at an early stage. Actually, Grid storage elements use dedicated protocols not supported by common applications such as web browsers. This makes a smooth integration of data management services in a Science Gateway quite difficult. In this work we show the Data Engine, a new SG component providing users with the ability to move data to storage elements and share them in an easy and clever way. The component operates between the Grid storage and the user, providing a file-system-like experience. © Copyright owned by the author(s) under the terms of the Creative Commons Attribution-NonCommercial-ShareAlike License.","Data transmission, World Wide Web, computer science",1,0,0,1
10.22323/1.162.0050,A science gateway getting ready for serving the international molecular simulation community,EGI Community Forum / EMI Technical Conference,2012,Conference Paper,"The project MoSGrid (Molecular Simulation Grid) has been developing a web-based science gateway supporting the community with various services for quantum chemistry, molecular modeling, and docking. Users gain access to distributed computing infrastructures (DCIs) via intuitive user interfaces for sophisticated tools, specialized workflows, and distributed repositories. Currently, the MoSGrid community consists of about 120 users from a number of fields related to chemistry and bioinformatics located in Germany. However, the underlying security infrastructure is generally applicable and can be deployed in arbitrary projects. MoSGrid intends to address the international community by participating in the EU-projects SCI-BUS (Scientific gateway Based User Support) and ER-flow (Building an European Research Community through Interoperable Workflows and Data), and collaborating with the EU-project EDGI (European Desktop Grid Initiative). © Copyright owned by the author(s) under the terms of the Creative Commons Attribution-NonCommercial-ShareAlike Licence.","computer science, Library science, Engineering ethics, science gateways, molecular simulation",1,0,0,1
10.2481/dsj.GRDI-013,Virtual research environments: An overview and a research agenda,Data Science Journal,2013,Article,"Virtual Research Environments are innovative, web-based, community-oriented, comprehensive, flexible, and secure working environments conceived to serve the needs of modern science. We overview the existing initiatives developing these environments by highlighting the major distinguishing features. We envisage a future where regardless of geographical location, scientists will be able to use their Web browsers to seamlessly access data, software, and processing resources that are managed by diverse systems in separate administration domains via Virtual Research Environments. We identify and discuss the major challenges that should be resolved to fully achieve the proposed vision, i.e., large-scale integration and interoperability, sustainability, and adoption.","data infrastructure, digital library, scientific gateways, virtual research environments",1,0,1,2
10.3233/978-1-61499-054-3-119,Science gateways for semantic-web-based life science applications,HealthGrid Applications and Technologies Meet Science Gateways for Life Sciences,2012,Conference Paper,In this paper we present the architecture of a framework for building Science Gateways supporting official standards both for user authentication and authorization and for middleware-independent job and data management. Two use cases of the customization of the Science Gateway framework for Semantic-Web-based life science applications are also described. © 2012 The authors and IOS Press. All rights reserved.,"COGITO-MED, grid computing, Identity Federation, KLIOS, science gateways, semantic web",1,0,0,1
10.3233/978-1-61499-054-3-152,Application repository and science gateway for running molecular docking and dynamics simulations,Volume 175: HealthGrid Applications and Technologies Meet Science Gateways for Life Sciences,2012,Conference Paper,"Molecular docking and dynamics studies are of considerable importance in a range of disciplines including molecular biology, drug design, environmental studies, psychology, etc. Using in silico tools to support or even to substitute wet laboratory work could help better focusing the laboratory experiments resulting not only in considerable saving of resources but also increasing the number of molecules and scenarios investigated. There are several software packages that support in silico modeling. However, these tools require lot of compute resources and special technical knowledge. As a result, many bio-scientists cannot use them. The paper describes a science gateway based solution which provides access to Distributed Computing Infrastructures such as clouds, desktop and service grids. This environment enables bio-scientists to execute simple molecular modeling scenarios or build more complex use-cases from existing building blocks while hiding the technical details of the infrastructure. Four scenarios have been defined and deconstructed in order to identify common building blocks supporting a large number of complex use-cases. A reference implementation for the first scenario regarding the impact on indicator species of pharmaceuticals released into water courses has been implemented on the EDGI infrastructure, demonstrating the feasibility of the approach. © 2012 The authors and IOS Press. All rights reserved.","desktop grid, distributed computing infrastructures, life sciences, Molecular docking, science gateways",1,0,0,1
10.3233/978-1-61499-054-3-162,Structure simulation with calculated NMR parameters-integrating COSMOS into the CCPN framework,Volume 175: HealthGrid Applications and Technologies Meet Science Gateways for Life Sciences,2012,Conference Paper,"The Collaborative Computing Project for NMR (CCPN) has build a software framework consisting of the CCPN data model (with APIs) for NMR related data, the CcpNmr Analysis program and additional tools like CcpNmr FormatConverter. The open architecture allows for the integration of external software to extend the abilities of the CCPN framework with additional calculation methods. Recently, we have carried out the first steps for integrating our software Computer Simulation of Molecular Structures (COSMOS) into the CCPN framework. The COSMOS-NMR force field unites quantum chemical routines for the calculation of molecular properties with a molecular mechanics force field yielding the relative molecular energies. COSMOS-NMR allows introducing NMR parameters as constraints into molecular mechanics calculations. The resulting infrastructure will be made available for the NMR community. As a first application we have tested the evaluation of calculated protein structures using COSMOS-derived 13C Cα and Cβ chemical shifts. In this paper we give an overview of the methodology and a roadmap for future developments and applications. © 2012 The authors and IOS Press. All rights reserved.","Bond orbital, Bond polarization energy, Chemical shift, Computational biomolecular structure determination, Data exchange interfaces, data models, Nuclear magnetic resonance, science gateways",1,0,0,1
10.3233/978-1-61499-054-3-173,Web-based interactive visualization in a Grid-enabled neuroimaging application using HTML5,Studies in Health Technology and Informatics,2012,Conference Paper,"Interactive visualization and correction of intermediate results are required in many medical image analysis pipelines. To allow certain interaction in the remote execution of compute- and data-intensive applications, new features of HTML5 are used. They allow for transparent integration of user interaction into Grid- or Cloud-enabled scientific workflows. Both 2D and 3D visualization and data manipulation can be performed through a scientific gateway without the need to install specific software or web browser plugins. The possibilities of web-based visualization are presented along the FreeSurfer-pipeline, a popular compute- and data-intensive software tool for quantitative neuroimaging. © 2012 The authors and IOS Press. All rights reserved.","Freesurfer, HealthGrid, HTML5, Medical imaging, visualization, web-based",1,0,0,1
10.3233/978-1-61499-054-3-182,The Einstein Genome Gateway using WASP - A high throughput multi-layered life sciences portal for XSEDE,Volume 175: HealthGrid Applications and Technologies Meet Science Gateways for Life Sciences,2012,Conference Paper,"Massively-parallel sequencing (MPS) technologies and their diverse applications in genomics and epigenomics research have yielded enormous new insights into the physiology and pathophysiology of the human genome. The biggest hurdle remains the magnitude and diversity of the datasets generated, compromising our ability to manage, organize, process and ultimately analyse data. The Wiki-based Automated Sequence Processor (WASP), developed at the Albert Einstein College of Medicine (hereafter Einstein), uniquely manages to tightly couple the sequencing platform, the sequencing assay, sample metadata and the automated workflows deployed on a heterogeneous high performance computing cluster infrastructure that yield sequenced, quality-controlled and 'mapped' sequence data, all within the one operating environment accessible by a web-based GUI interface.WASP at Einstein processes 4-6 TB of data per week and since its production cycle commenced it has processed ∼ 1 PB of data overall and has revolutionized user interactivity with these new genomic technologies, who remain blissfully unaware of the data storage, management and most importantly processing services they request. The abstraction of such computational complexity for the user in effect makes WASP an ideal middleware solution, and an appropriate basis for the development of a grid-enabled resource - the Einstein Genome Gateway - as part of the Extreme Science and Engineering Discovery Environment (XSEDE) program. In this paper we discuss the existing WASP system, its proposed middleware role, and its planned interaction with XSEDE to form the Einstein Genome Gateway. © 2012 The authors and IOS Press. All rights reserved.","Genomics, grid computing, Integrative Analysis, Life Science Gateways, Massively Parallel Sequencing, XSEDE",1,0,0,1
10.3233/978-1-61499-583-8-101,Architectural implications for exascale based on big data workflow requirements,Big Data and High Performance Computing,2015,Article,"The sheer volume of data accumulated in many scientific disciplines as well as in industry is a critical point that requires immediate attention. The handling of large data sets will become a limiting factor-even for data intensive applications running on future Exascale systems. Nowadays, Big Data can be more a collection of challenges for data processing at large scale and less a tool box of solutions used to improve applications, scale well, and handle the constantly growing data sets. There is an urgent need for intelligent mechanisms to acquire, process, and analyze data, which have to run and scale efficiently on current and future computing architectures. The complexity of Big Data applications will highly profit from flexible workflow systems that consider the full data life cycle, from data acquisition to long-term storage and towards the curation of knowledge. To maximize the applicability of HPC systems for Big Data workflows, several changes in the system architecture and its software need to be considered. First, in order to exploit all available I/O capacities an adaptable monitoring system needs to collect information about I/O patterns of application and workflows as well as provide information to model the I/O subsystem. The goal is to collect long term performance data, to evaluate this data, and finally to show how and why resources cannot be used to their full potential. Second, as the complexity of systems is continuously increasing, the level of abstraction that is presented to the user needs to increase with at least the same rate in order to ensure that the current usability is at least maintained. This is accomplished by employing science gateways as well as workflow and metadata technologies. © 2015 The authors and IOS Press. All rights reserved.","big data, HPC, I/O Monitoring, usability, workflows",1,0,0,1
10.3390/data5020039,An on-demand service for managing and analyzing arctic sea ice high spatial resolution imagery,Data,2020,Article,"Sea ice acts as both an indicator and an amplifier of climate change. High spatial resolution (HSR) imagery is an important data source in Arctic sea ice research for extracting sea ice physical parameters, and calibrating/validating climate models. HSR images are difficult to process and manage due to their large data volume, heterogeneous data sources, and complex spatiotemporal distributions. In this paper, an Arctic Cyberinfrastructure (ArcCI) module is developed that allows a reliable and efficient on-demand image batch processing on the web. For this module, available associated datasets are collected and presented through an open data portal. The ArcCI module offers an architecture based on cloud computing and big data components for HSR sea ice images, including functionalities of (1) data acquisition through File Transfer Protocol (FTP) transfer, front-end uploading, and physical transfer; (2) data storage based on Hadoop distributed file system and matured operational relational database; (3) distributed image processing including object-based image classification and parameter extraction of sea ice features; (4) 3D visualization of dynamic spatiotemporal distribution of extracted parameters with flexible statistical charts. Arctic researchers can search and find arctic sea ice HSR image and relevant metadata in the open data portal, obtain extracted ice parameters, and conduct visual analytics interactively. Users with large number of images can leverage the service to process their image in high performance manner on cloud, and manage, analyze results in one place. The ArcCI module will assist domain scientists on investigating polar sea ice, and can be easily transferred to other HSR image processing research projects. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Big spatiotemporal data, cloud computing, Earth science gateway, Sea ice classification",1,0,0,1
10.4137/EBO.S21501,A RESTful API for access to phylogenetic tools via the CIPRES science gateway,Evolutionary Bioinformatics,2015,Article,"The CIPRES Science Gateway is a community web application that provides public access to a set of parallel tree inference and multiple sequence alignment codes run on large computational resources. These resources are made available at no charge to users by the NSF Extreme Science and Engineering Discovery Environment (XSEDE) project. Here we describe the CIPRES RESTful application programmer interface (CRA), a web service that provides programmatic access to all resources and services currently offered by the CIPRES Science Gateway. Software developers can use the CRA to extend their web or desktop applications to include the ability to run MrBayes, BEAST, RAxML, MAFFT, and other computationally intensive algorithms on XSEDE. The CRA also makes it possible for individuals with modest scripting skills to access the same tools from the command line using curl, or through any scripting language. This report describes the CRA and its use in three web applications (Influenza Research Database – www.fludb. org, Virus Pathogen Resource – www.viprbrc.org, and MorphoBank – www.morphobank.org). The CRA is freely accessible to registered users at ht t ps:// cipresrest.sdsc.edu/cipresrest/v1; supporting documentation and registration tools are available at https://www.phylo.org/restusers.Z © the authors.","BEAST, CIPRES, Computational biology, JMODELTEST2, MAFFT, MrBayes, phylogenetics, RAxML, RESTful API, science gateways, web portal",1,0,0,1
10.1007/978-3-319-16462-5_37,Provenance Support for Medical Research,Provenance and Annotation of Data and Processes,2015,Conference Paper,"This poster paper introduces a system known as CRISTAL [1] and the experience using it for medical research, primarily in the neuGRID [2] and neuGridforUsers (N4U) projects. These projects aim to provide detailed traceability for research analysis processes in the study of biomarkers for Alzheimer’s disease. They have faced major challenges in managing data volumes and algorithm complexity leading to problems associated with information tracking, analysis reproducibility and scientific data verification. We present a working system that supports provenance data management for medical researchers.","Process Instance, virtual laboratory, data provenance, Analysis Definition, science gateways",1,1,0,2
